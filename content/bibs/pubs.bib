%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This bib file is created and processed by bibReader-0.0.8.12
% Date: 2023-02-13
% Webpage: https://github.com/jshinm/bibReader/
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{j12019,
	title = {Clustering Multi-Modal Connectomes},
	author = {Chung, Jaewon and Pedigo, Benjamin D. and Priebe, Carey E. and Vogelstein, Joshua T.},
	author+an = {1=trainee;2=trainee;4=highlight},
	year = {2019},
	keywords = {abspos},
	url = {https://figshare.com/articles/Clustering_Multi-Modal_Connectomes/8309672},
	month = {6},
	address = {OHBM, Rome Italy}
},

@inproceedings{Airan2013,
	title = {Reproducible differentiation of individual of individual subjects with minimal acquisition time via resting state fMRI},
	author = {D, Raag and Vogelstein, Airan A. and Caffo, Joshua A. and Pekar, Brian A. and I, James J. A. H. and Sair, Sair},
	author+an = {2=highlight},
	year = {2013},
	keywords = {abspos},
	url = {http://dx.doi.org/10.6084/m9.figshare.1284146},
	month = {4},
	address = {Proc ISMRM, Salt Lake City, UT, USA},
	pages = {1932}
},

@inproceedings{Allen2015synaptome,
	title = {The Open Synaptome Project: Toward a Microscopy-Based Platform for Single-synapse Analysis of Diverse Populations of CNS Synapses},
	author = {Smith, Stephen J. and Burns, Randal and Chevillet, Mark and Lein, Ed and Sapiro, Guillermo and Seeley, William and Trimmer, James and Vogelstein, Joshua T and Weinberg, Richard},
	author+an = {8=highlight},
	year = {2015},
	keywords = {abspos},
	url = {https://figshare.com/articles/Open_Synaptome_Project/1585165},
	month = {10},
	address = {Society for Neuroscience, Chicago, IL, USA}
},

@inproceedings{XBrain2015,
	title = {X-Brain: Quantifying Mesoscale Neuroanatomy Using X-ray Microtomography},
	author = {Deyer, Eva L. and Fernandes, Hugo L. and Roncal, Will Gray and Gursoy, Doga and Vogelstein, Joshua T and Xiao, Xianghui and Jacobsen, Chris and Kording, Konrad P. and Kasthuri, Narayanan},
	author+an = {5=highlight;3=trainee},
	year = {2015},
	keywords = {abspos},
	url = {https://figshare.com/articles/X_Brain_Quantifying_Mesoscale_Neuroanatomy_Using_X_Ray_Microtomography/1585163},
	address = {Figshare}
},

@inproceedings{Design2015,
	title = {Optimal Design for Discovery Science: Applications in Neuroimaging},
	author = {Wang, Shangsi and Yang, Zhi and Zuo, Xi-Nian and Milham, Michael and Craddock, Cameron and Priebe, Carey E. and Vogelstein, Joshua T.},
	author+an = {1=trainee;7=highlight},
	year = {2015},
	keywords = {abspos},
	url = {https://figshare.com/articles/Optimal_Design_for_Discovery_Science_Applications_in_Neuroimaging/1515021},
	address = {Figshare}
},

@inproceedings{Sparse2015,
	title = {A Sparse High Dimensional State-Space Model with an Application to Neuroimaging Data},
	author = {Chen, Shaojie and Liu, Kai and Yuguang, Yang and Seonjoo, Lee and Lindquist, Martin and Caffo, Brian and Vogelstein, Joshua T},
	author+an = {1=trainee;7=highlight},
	year = {2015},
	keywords = {abspos},
	url = {https://figshare.com/articles/A_Sparse_High_Dimensional_State_Space_Model_with_an_Application_to_Neuroimaging_Data/1515020},
	address = {Figshare}
},

@inproceedings{Vogelstein2002,
	title = {Up-down asymmetry in memory guided saccadic eye movements are independent of head orientation in space},
	author = {Vogelstein, Joshua T and Snyder, LH and Warchol, M and Angelaki, DE},
	author+an = {1=highlight},
	year = {2002},
	keywords = {abspos},
	address = {Society for Neuroscience, Orlando, FL, USA}
},

@inproceedings{pedigo_naisys_2022,
	title = {Generative network modeling reveals a first quantitative definition of bilateral symmetry exhibited by a whole insect brain connectome},
	author = {Pedigo, Benjamin D and Powell, Mike and Bridgeford, Eric W and Winding, Michael and Priebe, Carey E and Vogelstein, Joshua T},
	author+an = {1=trainee; 2=trainee; 3=trainee; 6=highlight},
	year = {2022},
	keywords = {abspos},
	url = {https://figshare.com/articles/poster/Generative_network_modeling_reveals_a_quantitative_definition_of_bilateral_symmetry_exhibited_by_a_whole_insect_brain_connectome/19610013},
	month = {3},
	address = {From Neuroscience to Artificially Intelligent Systems (NAISys), Cold Spring Harbor Laboratory, NY, USA}
},

@inproceedings{jong_naisys_2022,
	title = {Measure of human-likelihood in tree-based ensemble model and artificial neural networks},
	author = {Shin, Jong M and Isik, Leyla and Vogelstein, Joshua T},
	author+an = {1=trainee; 3=highlight},
	year = {2022},
	keywords = {abspos},
	url = {https://figshare.com/articles/poster/2022_NAISys_conference_poster_presentation/20070515},
	month = {3},
	address = {From Neuroscience to Artificially Intelligent Systems (NAISys), Cold Spring Harbor Laboratory, NY, USA}
},

@inproceedings{jayanta_naisys_2022,
	title = {Out-of-distribution Detection Using Kernel Density Polytopes},
	author = {Dey, Jayanta and LeVine, Will and De Silva, Laknath A and Geisa, Ali and Vogelstein, Joshua T},
	author+an = {1=trainee;2=trainee;3=trainee;4=trainee;5=highlight},
	year = {2022},
	keywords = {abspos},
	url = {https://figshare.com/articles/poster/jayanta-NAISys2022_pdf/20070512},
	month = {3},
	address = {From Neuroscience to Artificially Intelligent Systems (NAISys), Cold Spring Harbor Laboratory, NY, USA}
},

@inproceedings{javier_naisys_2022,
	title = {Transfer learning in larval zebrafish (Danio rerio)},
	author = {How, Javier J and Schuhknecht, Gregor and Ahrens, Misha B and Engert, Florian and Vogelstein, Joshua T},
	author+an = {1=trainee; 5=highlight},
	year = {2022},
	keywords = {abspos},
	url = {https://figshare.com/articles/poster/javier-NAISys2022_pdf/20070509},
	month = {3},
	address = {From Neuroscience to Artificially Intelligent Systems (NAISys), Cold Spring Harbor Laboratory, NY, USA}
},

@inproceedings{ashwin_naisys_2022,
	title = {Kernel density networks},
	author = {De Silva, Laknath A and Vogelstein, Joshua T},
	author+an = {1=trainee; 2=highlight},
	year = {2022},
	keywords = {abspos},
	month = {3},
	address = {From Neuroscience to Artificially Intelligent Systems (NAISys), Cold Spring Harbor Laboratory, NY, USA}
},

@inproceedings{hao_naisys_2022,
	title = {Simplest streaming trees},
	author = {Xu, Haoyin and Vogelstein, Joshua T},
	author+an = {1=trainee; 2=highlight},
	year = {2022},
	keywords = {abspos},
	month = {3},
	address = {From Neuroscience to Artificially Intelligent Systems (NAISys), Cold Spring Harbor Laboratory, NY, USA}
},

@inproceedings{Gray2012b,
	title = {Towards a Fully Automatic Pipeline for Connectome Estimation from High-Resolution EM Data},
	author = {Gray, Gray and Kleissas, William R. A. and Burck, Dean M. A. and Vogelstein, James M. A. and Perlman, Joshua T. A. and Burlina, Eric A. and Burns, Philippe M. A. and Jacob, Randal A. V. R.},
	author+an = {4=highlight;1=trainee},
	year = {2012},
	keywords = {abspos},
	url = {http://dx.doi.org/10.6084/m9.figshare.1284176},
	address = {Cold Spring Harbor Laboratory, Neuronal Circuits, Cold Spring Harbor, NY, USA}
},

@inproceedings{Vogelstein2007a,
	title = {Maximum Likelihood Inference of Neural Dynamics under Noisy and Intermittent Observations using Sequential Monnte Carlo EM Algorithms},
	author = {Vogelstein, Joshua T and Zhang, K and Jedynak, B and Paninski, L},
	author+an = {1=highlight},
	year = {2007},
	keywords = {abspos},
	url = {http://dx.doi.org/10.6084/m9.figshare.1285828},
	month = {2},
	address = {COSYNE, Salt Lake City, UT, USA}
},

@inproceedings{Vogelstein2012a,
	title = {Statistical Connectomics},
	author = {Vogelstein, Vogelstein and Bock, Joshua T. A. and Gray, Davi A. and Sussman, William A. and Burns, Daniel A. and Kleissas, Randal A. and Marchette, Dean A. and Fishkind, David A. and Tang, Donniell E. A. and Hager, Minh A. and Vogelstein, Greg A. and E., R. J. A. P. C.},
	author+an = {1=highlight;3=trainee},
	year = {2012},
	keywords = {abspos},
	url = {http://dx.doi.org/10.6084/m9.figshare.1284174},
	month = {5},
	address = {Janelia Farm conference, Statistical Inference and Neuroscience, Loudoun County, VA, USA}
},

@inproceedings{Vogelstein2015sfn,
	title = {Open Connectome Project NeuroData: Enabling Data-Driven Neuroscience at Scale},
	author = {Vogelstein, Vogelstein and T, Joshua},
	author+an = {1=highlight},
	year = {2015},
	keywords = {abspos},
	url = {https://figshare.com/articles/NeuroData_amp_The_Open_Connectome_Project_Enabling_Big_Data_Neuroscience_at_Scale/1585167},
	month = {10},
	address = {Society for Neuroscience, Chicago, IL, USA}
},

@inproceedings{Vogelstein2008c,
	title = {Model-Based Optimal Inference of Spike-Times and Calcium Dynamics given Noisy and Intermittent Calcium-Fluorescence Imaging},
	author = {Vogelstein, Joshua T and Babadi, B and Paninski, L},
	author+an = {1=highlight},
	year = {2008},
	keywords = {abspos},
	url = {http://dx.doi.org/10.6084/m9.figshare.1285826},
	month = {2},
	address = {COSYNE, Salt Lake City, UT, USA}
},

@inproceedings{Gray2013,
	title = {Towards a Fully Automatic Pipeline for Connectome Estimation from High-Resolution EM Data},
	author = {Roncal, Gray and Kleissas, William A. and Burck, Dean M. A. and Manavalan, James M. A. and Vogelstein, Priya A. and Perlman, Joshua T. A. and Burns, Eric A. and Vogelstein, Randal A. and Jacob, R.},
	author+an = {1=trainee;5=highlight},
	year = {2013},
	keywords = {abspos},
	url = {http://dx.doi.org/10.6084/m9.figshare.1284151},
	month = {6},
	address = {OHBM, Seattle, WA, USA}
},

@inproceedings{Vogelstein2008b,
	title = {Inferring Spike Trains, Learning Tuning Curves, and Estimating Connectivity from Calcium Imaging},
	author = {Vogelstein, Joshua T and Paninski, L},
	author+an = {1=highlight},
	year = {2008},
	keywords = {abspos},
	url = {http://dx.doi.org/10.6084/m9.figshare.1285827},
	address = {Integrative Approaches to Brain Complexity}
},

@inproceedings{Vogelstein2010d,
	title = {Measuring and reconstructing the brain at the synaptic scale: towards a biofidelic human brain in silico},
	author = {Vogelstein, Joshua T and Priebe, Carey E and Burns, R and Vogelstein, R Jacob and Lichtman, J},
	author+an = {1=highlight},
	year = {2010},
	keywords = {abspos},
	url = {http://dx.doi.org/10.6084/m9.figshare.1285813},
	month = {11},
	address = {DARPA Neural Engineeering, Science and Technology Forum, San Diego, CA, USA}
},

@inproceedings{Vogelstein2009b,
	title = {Towards Confirming Neural Circuits from Population Calcium Imaging},
	author = {Vogelstein, Joshua T and Mishchchenko, Y and Packer, A M and Machado, T A and Yuste, R and Paninski, L},
	author+an = {1=highlight},
	year = {2009},
	keywords = {abspos},
	url = {http://dx.doi.org/10.6084/m9.figshare.1285822},
	month = {12},
	address = {NIPS Workshop on Connectivity Inference in Neuroimaging, Whistler, BC, Canada}
},

@inproceedings{Vogelstein2010a,
	title = {Towards Confirming Neural Circuit Inference from Population Calcium Imaging},
	author = {Vogelstein, Joshua T and Mishchenki, Y and Packer, AM and Machado, TA and Yuste, R and Paninski, L},
	author+an = {1=highlight},
	year = {2010},
	keywords = {abspos},
	url = {http://dx.doi.org/10.6084/m9.figshare.1284693},
	month = {2},
	address = {COSYNE, Salt Lake City, UT, USA}
},

@inproceedings{Vogelstein2010b,
	title = {A Neurocognitive Graph-Theoretical Approach to Understanding the Relationship Between Minds and Brains},
	author = {Vogelstein, Joshua T and Vogelstein, RJ and Priebe, Carey E},
	author+an = {1=highlight},
	year = {2010},
	keywords = {abspos},
	url = {http://dx.doi.org/10.6084/m9.figshare.1284694},
	month = {3},
	address = {CSHL conference on Neural Circuits, Cold Shore Harbor, NY, USA}
},

@inproceedings{Vogelstein2010c,
	title = {Graph-Theoretical Methods for Statistical Inference on MR Connectome Data},
	author = {Vogelstein, Joshua T and Bogovic, J and Carass, A and Gray, WR and Prince, JL and Landman, B and Pham, D and Ferrucci, L and Resnick, SM and Priebe, Carey E and Vogelstein, RJ},
	author+an = {1=highlight;4=trainee},
	year = {2010},
	keywords = {abspos},
	url = {http://dx.doi.org/10.6084/m9.figshare.1285813},
	month = {6},
	address = {Organization for Human Brain Mapping, Barcelona, Spain}
},

@inproceedings{Gray2011,
	title = {Magnetic resonance connectome automated pipeline and repeatability analysis},
	author = {Gray, William R and Bogovic, J A and Vogelstein, Joshua T and Ye, C and Landman, B A and Prince, J L and Vogelstein, R Jacob},
	author+an = {3=highlight;1=trainee},
	year = {2011},
	keywords = {abspos},
	url = {http://dx.doi.org/10.6084/m9.figshare.1284177},
	month = {10},
	address = {Society for Neuroscience, Washington DC, USA}
},

@inproceedings{Vogelstein2011f,
	title = {Dot product embedding in large (errorfully observed) graphs with applications in statistical connectomics},
	author = {Vogelstein, Joshua T and Sussman, D L and Tang, M and Fishkind, D E and Priebe, Carey E},
	author+an = {1=highlight},
	year = {2011},
	keywords = {abspos},
	month = {10},
	address = {IMA conference on Large Graphs, University of Minnesota, Minneapolis, MN, USA}
},

@inproceedings{Vogelstein2008a,
	title = {From Calcium Sensitive Fluorescence Movies to Spike Trains},
	author = {Vogelstein, Joshua T and Babadi, B and Watson, BO and Yuste, R and Paninski, L},
	author+an = {1=highlight},
	year = {2008},
	keywords = {abspos},
	url = {http://dx.doi.org/10.6084/m9.figshare.1285824},
	month = {11},
	address = {Society for Neuroscience, Washington DC, USA}
},

@inproceedings{Vogelstein2011d,
	title = {Connectome Classification using statistical graph theory and machine learning},
	author = {Vogelstein, Joshua T and Gray, W and Martin, J G and Coppersmith, G C and Dredze, M and Bogovic, J and Prince, J L and Resnick, S M and Priebe, Carey E and Vogelstein, R J},
	author+an = {1=highlight;2=trainee},
	year = {2011},
	keywords = {abspos},
	url = {http://dx.doi.org/10.6084/m9.figshare.1284178},
	month = {10},
	address = {Society for Neuroscience, Washington DC, USA}
},

@article{Vogelstein2011e,
	title = {Open Connectome Project: collectively reverse engineering the brain one synapse at a time},
	author = {Vogelstein, Joshua T and Perlman, E and Bock, D and Lee, W C and Chang, M and Kasthuri, B and Kazhdan, M and Reid, C and Lichtman, J and Burns, R and Vogelstein, R Jacob},
	author+an = {1=highlight},
	year = {2011},
	keywords = {abspos},
	url = {http://dx.doi.org/10.6084/m9.figshare.1284181},
	month = {9},
	journal = {Neuroinformatics, Boston, MA, USA}
},

@inproceedings{Vogelstein2011h,
	title = {Connectome Classification: Statistical Graph Theoretic Methods for Analysis of MR-Connectome Data},
	author = {Vogelstein, Joshua T and Gray, William R and Vogelstein, R Jacob and Bogovic, J and Resnick, S and Prince, J and Priebe, Carey E},
	author+an = {1=highlight;2=trainee},
	year = {2011},
	keywords = {abspos},
	url = {http://dx.doi.org/10.6084/m9.figshare.1284179},
	month = {6},
	address = {Organization for Human Brain Mapping, Quebec City, Canada}
},

@inproceedings{Vogelstein2007b,
	title = {Inferring Spike Trains, Neural Filters, and Network Circuits from in vivo Calcium Imaging},
	author = {Vogelstein, Joshua T and Jedynak, B and Zhang, K and Paninski, L},
	author+an = {1=highlight},
	year = {2007},
	keywords = {abspos},
	url = {http://dx.doi.org/10.6084/m9.figshare.1285846},
	month = {11},
	address = {Society for Neuroscience, San Diego, CA, USA}
},

@inproceedings{Vogelstein2011g,
	title = {Large graph classification: theory and statistical connectomics applications},
	author = {Vogelstein, J T and Fishkind, D E and Sussman, D L and Priebe, C E},
	author+an = {1=highlight},
	year = {2011},
	keywords = {abspos},
	url = {http://dx.doi.org/10.6084/m9.figshare.1284184},
	month = {10},
	address = {IMA conference on Large Graphs, University of Minnesota, Minneapolis, MN, USA}
},

@inproceedings{Vogelstein2012,
	title = {BRAINSTORM towards clinically and scientifically useful neuroimaging analytics},
	author = {Vogelstein, Vogelstein and Sikka, J. A. and Cheung, S. A. and Khanuja, B. A. and Li, R. A. and C, Q. A. Y. and Priebe, .G. A. and Calhoun, C. A. and Vogelstein, V. A. and Milham, R. J. A. and Burns, M. A. and R., R.},
	author+an = {1=highlight},
	year = {2012},
	keywords = {abspos},
	url = {http://dx.doi.org/10.6084/m9.figshare.1284173},
	month = {9},
	address = {Neuroinformatics, Munich, Germany}
},

@inproceedings{Vogelstein2009c,
	title = {Towards Inferring Neural Circuit Inference from Population Calcium Imaging},
	author = {Vogelstein, Joshua T and Mishchenki, Y and Packer, AM and Machado, TA and Yuste, R and Paninski, L},
	author+an = {1=highlight},
	year = {2009},
	keywords = {abspos},
	url = {http://dx.doi.org/10.6084/m9.figshare.1285821},
	month = {2},
	address = {COSYNE, Salt Lake City, UT, USA}
},

@inproceedings{Vogelstein2004,
	title = {A novel theory for simultaneous representation of multiple dynamic states in hippocampus},
	author = {Vogelstein, Joshua T and Zhang, K},
	author+an = {1=highlight},
	year = {2004},
	keywords = {abspos},
	address = {Society for Neuroscience, San Diego, CA, USA}
},

@inproceedings{hecheng_rest,
	title = {Assessing functional connectivity beyond Pearson's correlation},
	author = {Hecheng, Jin and Ramirez, Julian S.B. and Vogelstein, Joshua T. and Milham, Michael P. and Xu, Ting},
	author+an = {3=highlight},
	year = {2020},
	keywords = {abspos},
	month = {9},
	address = {Fairmont, Dallas, TX, USA}
},

@inproceedings{Vogelstein2010e,
	title = {Towards Inferring Neural Circuit Inference from Population Calcium Imaging},
	author = {Vogelstein, Joshua T and Mishchenki, Y and Packer, AM and Machado, TA and Yuste, R and Paninski, L},
	author+an = {1=highlight},
	year = {2010},
	keywords = {abspos},
	url = {http://dx.doi.org/10.6084/m9.figshare.1285819},
	month = {2},
	address = {COSYNE, Salt Lake City, UT, USA}
},

@inproceedings{Sussman2013,
	title = {Massive Diffusion MRI Graph Structure Preserves Spatial Information},
	author = {Sussman, Daniel L and Mhembere, Disa and Ryman, Sephira and Jung, Rex and Vogelstein, R. Jacob and Burns, Randal and Vogelstein, Joshua T and Priebe, Carey E},
	author+an = {2=trainee;7=highlight},
	year = {2013},
	keywords = {abspos},
	url = {http://dx.doi.org/10.6084/m9.figshare.1284155},
	month = {6},
	address = {OHBM, Seattle, WA, USA}
},

@inproceedings{Vogelstein2013c,
	title = {Anomaly Screening and Clustering of Multi-OBject Movies via Multiscale Structure Learning},
	author = {Vogelstein, Joshua T and others},
	author+an = {1=highlight},
	year = {2013},
	keywords = {abspos},
	address = {DARPA XDATA Colloquium}
},

@inproceedings{Sismanis2013,
	title = {Feature Clustering from a Brain Graph for Voxel-to-Region Classification},
	author = {Sismanis, Sismanis and Sussman, N. A. and Vogelstein, D. L. A. and Gray, J. T. A. and Vogelstein, W. A. and Perlman, R. J. A. and Mhembere, E. A. and Ryman, D. A. and Jung, S. A. and Burns, R. A. and Priebe, R. A. and Pitsianis, C. E. A. and Sun, N. A. and X., X.},
	author+an = {3=highlight;4=trainee;7=trainee},
	year = {2013},
	keywords = {abspos},
	url = {http://dx.doi.org/10.6084/m9.figshare.1284143},
	month = {4},
	address = {5th Panhellic Conference on Biomedical Technology, Athens, Greece}
},

@inproceedings{Mhembere2013a,
	title = {Multivariate Invariants from Massive Brain-Graphs},
	author = {Mhembere, Mhembere and Burns, Disa A. and Vogelstein, Randal A. and Vogelstein, Joshua T. A. and Sussman, R. J. A. and Preibe, Daniel A. and Jung, Carey A. and Rex, Rex and Ryman, AND and Sephira, Sephira},
	author+an = {1=trainee;2=highlight},
	year = {2013},
	keywords = {abspos},
	url = {http://dx.doi.org/10.6084/m9.figshare.1284154},
	month = {6},
	address = {OHBM, Seattle, WA, USA}
},

@inproceedings{_Nonparametric_2013,
	title = {Nonparametric Two-Sample Testing on Graph-Valued Data.},
	author = {Vogelstein, Joshua T and Priebe, Carey E},
	author+an = {1=highlight},
	year = {2013},
	keywords = {abspos},
	month = {7},
	address = {Duke Workshop on Sensing and Analysis of HighDimensional Data, Durham, NC, USA}
},

@inproceedings{Vogelstein2015a,
	title = {High Dimensional State Space Model with L-1 and L-2 Penalties},
	author = {Chen, Shaojie and Vogelstein, Joshua T and Lee, Seonjoo and Lindquist, Martin and Caffo, Brian},
	author+an = {1=trainee;2=highlight},
	year = {2015},
	keywords = {abspos},
	url = {http://www.enar.org/abstracts/2015_Program_Abstracts_03-02-15.pdf},
	month = {3},
	address = {ENAR 2015, Miami, FL, USA}
},

@inproceedings{koutra2013all,
	title = {Are All Brains Wired Equally?},
	author = {Koutra, Danai and Gong, Yu and Ryman, Sephira and Jung, Rex and Vogelstein, Joshua T. and Faloutsos, Christos},
	author+an = {5=highlight},
	year = {2013},
	keywords = {abspos},
	url = {http://dx.doi.org/10.6084/m9.figshare.1284149},
	month = {6},
	address = {Proceedings of the 19th Annual Meeting of the Organization for Human Brain Mapping (OHBM), Seattle, WA, USA},
	volume = {1},
	pages = {3},
	number = {4.2}
},

@inproceedings{sikka2014towards,
	title = {Towards automated analysis of connectomes: The configurable pipeline for the analysis of connectomes (c-pac)},
	author = {Sikka, Sikka and Cheung, Sharad A. and Khanuja, Brian A. and Ghosh, Ranjit A. and Yan, Satra A. and Li, Chao-gan A. and Vogelstein, Qingyang A. and Burns, Joshua A. and Colcombe, Randal A. and Craddock, Stanley A. and Mennes, Cameron A. and Kelly, Maarten A. and Dimartino, Clare A. and Castellanos, Adriana A. and Milham, Francisco A. and Michael, Michael},
	author+an = {7=highlight},
	year = {2014},
	keywords = {abspos},
	url = {https://www.frontiersin.org/10.3389/conf.fninf.2014.08.00117/event_abstract},
	month = {8},
	address = {5th INCF Congress of Neuroinformatics, Munich, Germany},
	volume = {10}
},

@inproceedings{chun2019struct,
	title = {Human Structural Connectomes are Heritable},
	author = {Chung, Jaewon and Pedigo, Benjamin D. and Priebe, Carey E. and Vogelstein, Joshua T.},
	author+an = {1=trainee;2=trainee;4=highlight},
	year = {2019},
	keywords = {abspos},
	url = {https://figshare.com/articles/Structural_Connectomes_are_Heritable/7800587},
	month = {6},
	address = {OHBM, Rome Italy}
},

@inproceedings{pedigo2019,
	title = {GraSPy: an Open Source Python Package for Statistical Connectomics},
	author = {Pedigo, Benjamin D. and Chung, Jaewon and Bridgeford, Eric W. and Varjavand, Bijan and Priebe, Carey E. and Vogelstein, Joshua T.},
	author+an = {1=trainee;2=trainee;3=trainee;4=trainee;6=highlight},
	year = {2019},
	keywords = {abspos},
	url = {https://figshare.com/articles/GraSPy_an_Open_Source_Python_Package_for_Statistical_Connectomics/7982888},
	month = {4},
	address = {Max Planck /HHMI Connectomics Meeting Berlin, Germany}
},

@inproceedings{browneposter2019,
	title = {Forest Packing: Fast Parallel Decision Forests},
	author = {Browne, James and Mhembere, Disa and Tomita, Tyler M. and Vogelstein, Joshua T. and Burns, Randal},
	author+an = {1=trainee;2=trainee;3=trainee;4=highlight},
	year = {2019},
	keywords = {abspos},
	url = {https://figshare.com/articles/Forest_Packing_Fast_Parallel_Decision_Forests/8194142},
	month = {5},
	address = {SIAM International Conference on Data Mining, Calgary, Alberta, Canada}
},

@inproceedings{falk_open_data2019,
	title = {NeuroData's Open Data Cloud Ecosystem},
	author = {Falk, Benjamin and Vogelstein, Joshua T.},
	author+an = {2=highlight},
	year = {2019},
	keywords = {abspos},
	url = {https://neurodata.io/talks/25_NeuroDatas_Open_Data_Ecosystem.pdf},
	month = {7},
	address = {Harvard University, Cambridge, MA, USA}
},

@inproceedings{berlin_2017,
	title = {Processing and Analyzing Terascale Conjugate Array Tomography Data},
	author = {Baden, Alex and Perlman, Eric and Collman, Forrest and Smith, Stephen and Vogelstein, Joshua T. and Burns, Randal},
	author+an = {1=trainee;5=highlight},
	year = {2017},
	keywords = {abspos},
	url = {https://neurodata.io/talks/berlin_2017.pdf},
	address = {Berlin, Germany}
},

@inproceedings{hayden_naisys_2020,
	title = {A Biological Implementation of Lifelong Learning in the Pursuit of Artificial General Intelligence},
	author = {Vogelstein, Joshua T. and Helm, Hayden and Pedigo, Benjamin D. and Mehta, Ronak and Priebe, Carey E. and White, Chris},
	author+an = {2=trainee;3=trainee;4=trainee;1=highlight},
	year = {2020},
	keywords = {abspos},
	month = {11},
	address = {NAIsys, Cold Spring Harbor, NY, USA}
},

@inproceedings{Gray2010,
	title = {Graph-Theoretical Methods for Statistical Inference on MR Connectome Data},
	author = {Gray, William R and Vogelstein, Joshua T and Bogovic, J and Carass, A and Prince, J L and Landman, B and Pham, D and Ferrucci, L and Resnick, S M and Priebe, Carey E and Vogelstein, R Jacob},
	author+an = {2=highlight;1=trainee},
	year = {2010},
	keywords = {abspos},
	url = {http://dx.doi.org/10.6084/m9.figshare.1285815},
	month = {11},
	address = {DARPA Neural Engineering, Science and Technology Forum, San Diego, CA, USA}
},

@inproceedings{pedigo_naisys_2020,
	title = {A quantitative comparison of a complete connectome to artificial intelligence architectures},
	author = {Pedigo, Benjamin D and Winding, Michael and Orujlu, Turan and Zlatic, Marta and Cardona,Albert and Priebe, Carey E and Vogelstein, Joshua T},
	author+an = {1=trainee; 7=highlight},
	year = {2020},
	keywords = {abspos},
	month = {11},
	address = {NAIsys, Cold Spring Harbor, NY, USA}
},

@inproceedings{Eric_OHBM2020,
	title = {Optimal Experimental Design for Big Data: Applications in Brain Imaging},
	author = {Bridgeford, Eric and Vogelstein, Joshua T.},
	author+an = {1=trainee; 2=highlight},
	year = {2020},
	keywords = {abspos},
	month = {6},
	address = {OHBM}
},

@inproceedings{Qin2013a,
	title = {Robust Clustering of Adjacency Spectral Embeddings of Brain Graph Data via Lq-Likelihood},
	author = {Qin, Yichen and Mhembere, Disa and Ryman, Sephira and Jung, Rex and Vogelstein, R. Jacob and Burns, Randal and Vogelstein, Joshua and Priebe, Carey},
	author+an = {2=trainee;5=highlight},
	year = {2013},
	keywords = {abspos},
	url = {http://dx.doi.org/10.6084/m9.figshare.1284153},
	month = {6},
	address = {OHBM, Seattle, WA, USA}
},

@inproceedings{Ronan_OHBM2020,
	title = {Identifying Differences Between Expert and Novice Meditator Brain Scans via Multiview Embedding},
	author = {Perry, Ronan and Vogelstein, Joshua T.},
	author+an = {1=trainee; 2=highlight},
	year = {2020},
	keywords = {abspos},
	month = {6},
	address = {OHBM}
},

@inproceedings{Li_rest,
	title = {Improving brain-behavior prediction using individual-specific components from connectivity-based shared response model},
	author = {Li, X and Cho, J.W. and Milham, Michael P. and Xu, Ting},
	year = {2020},
	keywords = {abspos},
	month = {9},
	address = {Resting State, Fairmont, Dallas, TX, USA}
},

@inproceedings{Cho_rest4,
	title = {Developing a gradient flow framework to guide the optimization of reliability for the study of individual differences},
	author = {Cho, J.W. and Korchmaros, A. and Vogelstein, Joshua T. and Milham, Michael P. and Xu, Ting},
	author+an = {3=highlight},
	year = {2020},
	keywords = {abspos},
	month = {9},
	address = {OHBM and Resting State, Fairmont, Dallas, TX, USA}
},

@inproceedings{perlman_kndi_2017,
	title = {NEURODATA: ENABLING BIG DATA NEUROSCIENCE},
	author = {Perlman, Perlman and Eric, Eric},
	year = {2017},
	keywords = {abspos},
	url = {https://neurodata.io/talks/perlman_kndi_2017.pdf},
	address = {Kavli, Baltimore, MD, USA}
},

@inproceedings{Cho_rest2,
	title = {Impact of Concatenating fMRI Data on reliability for Functional Connectomics},
	author = {Cho, J.W. and Korchmaros, A. and Vogelstein, Joshua T. and Milham, Michael P. and Xu, Ting},
	author+an = {3=highlight},
	year = {2020},
	keywords = {abspos},
	month = {9},
	address = {OHBM and Resting State, Fairmont, Dallas, TX, USA}
},

@inproceedings{Cho_rest,
	title = {Impact of Concatenating fMRI Data on reliability for Functional Connectomics},
	author = {Cho, J.W. and Korchmaros, A. and Vogelstein, Joshua T. and Milham, Michael P. and Xu, Ting},
	author+an = {3=highlight},
	year = {2020},
	keywords = {abspos},
	month = {6},
	address = {OHBM and Resting State, Fairmont, Dallas, TX, USA}
},

@inproceedings{VivekNeuro2020,
	title = {Statistical Methods for Multiscale Comparative Connectomics},
	author = {Gopalakrishnan, Vivek and Chung, Jaewon and Bridgeford, Eric and Arroyo, Jesus and Pedigo, Benjamin D. and Priebe, Carey E. and Vogelstein, Joshua T.},
	author+an = {1=trainee; 2=trainee; 3=trainee; 4=trainee; 5=trainee; 7=highlight},
	year = {2020},
	keywords = {abspos},
	month = {11},
	address = {Neuromatch 3}
},

@inproceedings{Pnevmatikakis2013,
	title = {Rank-penalized nonnegative spatiotemporal deconvolution and demixing of calcium inaging data},
	author = {Pnevmatikakis, Pnevmatikakis and Machado, Eftychios A. A. and Grosenick, Tim A. and Poole, Logan A. and Vogelstein, Ben A. and Liam, Joshua T. A. P.},
	author+an = {5=highlight},
	year = {2013},
	keywords = {abspos},
	url = {http://dx.doi.org/10.6084/m9.figshare.1284170},
	month = {3},
	address = {COSYNE, Salt Lake City, UT, USA}
},

@inproceedings{PedigoNeuro2020,
	title = {Statistical tools for nanoscale connectomics: clustering neurons in Drosophila larva brain and other applications},
	author = {Pedigo, Benjamin D. and Winding, Michael and Saad-Eldin, Ali and Liu, Tingshan and Cardona, Albert and Zlatic, Marta and Priebe, Carey E. and Vogelstein, Joshua T.},
	author+an = {1=trainee; 3=trainee; 8=highlight},
	year = {2020},
	keywords = {abspos},
	month = {11},
	address = {Neuromatch 3}
},

@inproceedings{J1Neuro2020,
	title = {Human Structural Connectomes are Heritable},
	author = {Chung, Jaewon and Dey, Jayanta and Kiar, Gregory and Priebe, Carey E. and Vogelstein, Joshua T.},
	author+an = {1=trainee; 2=trainee; 3=trainee; 5=highlight},
	year = {2020},
	keywords = {abspos},
	month = {11},
	address = {Neuromatch 3}
},

@inproceedings{SaadNeuro2020,
	title = {NeuroGraphMatch},
	author = {Saad-Eldin, Ali and Pedigo, Benjamin D. and Park, Youngser and Priebe, Carey E. and Vogelstein, Joshua T.},
	author+an = {1=trainee; 2=trainee; 3=trainee; 5=highlight},
	year = {2020},
	keywords = {abspos},
	month = {11},
	address = {Neuromatch 3}
},

@inproceedings{BridgefordNeuro2020,
	title = {Batch Effects are Causal Effects: Applications in Human Functional Connectomes},
	author = {Bridgeford, Eric W. and Powell, Michael and Alyakin, Anton and Caffo, Brian and Vogelstein, Joshua T.},
	author+an = {1=trainee; 2=trainee; 3=trainee; 5=highlight},
	year = {2020},
	keywords = {abspos},
	month = {11},
	address = {Neuromatch 3}
},

@inproceedings{Cho_rest3,
	title = {Developing a gradient flow framework to guide the optimization of reliability for the study of individual differences},
	author = {Cho, J.W. and Korchmaros, A. and Vogelstein, Joshua T. and Milham, Michael P. and Xu, Ting},
	author+an = {3=highlight},
	year = {2020},
	keywords = {abspos},
	month = {6},
	address = {OHBM and Resting State, Fairmont, Dallas, TX, USA}
},

@inproceedings{RonanNeuro2020,
	title = {Permutation-corrected independence testing for high-dimensional fMRI data},
	author = {Perry, Ronan and Zorn, Jelle and Czajko, Sebastien and Margulies, Daniel S. and Vogelstein, Joshua T.},
	author+an = {1=trainee; 5=highlight},
	year = {2020},
	keywords = {abspos},
	month = {11},
	address = {Neuromatch 3}
},

@inproceedings{Vogelstein2010b_2,
	title = {A Neurocognitive Graph-Theoretical Approach to Understanding the Relationship Between Minds and Brains},
	author = {Vogelstein, Joshua T and Vogelstein, RJ and Priebe, Carey E},
	author+an = {1=highlight},
	year = {2010},
	keywords = {book},
	booktitle = {CSHL conference on Neural Circuits}
},

@article{Mhembere2013,
	title = {Computing scalable multivariate glocal invariants of large (brain-) graphs},
	author = {Mhembere, Disa and Gray Roncal, William and Sussman, Daniel and Priebe, Carey E. and Jung, Rex and Ryman, Sephira and Vogelstein, R. Jacob and Vogelstein, Joshua T. and Burns, Randal},
	author+an = {1=trainee;2=trainee;8=highlight},
	year = {2013},
	keywords = {conference},
	url = {http://dx.doi.org/10.1109/GlobalSIP.2013.6736874},
	month = {12},
	pages = {297–300},
	journal = {2013 IEEE Global Conference on Signal and Information Processing, GlobalSIP 2013 - Proceedings},
	doi = {10.1109/GlobalSIP.2013.6736874},
	isbn = {9781479902484},
	abstract = {Graphs are quickly emerging as a leading abstraction for the representation of data. One important application domain originates from an emerging discipline called 'connectomics'. Connectomics studies the brain as a graph; vertices correspond to neurons (or collections thereof) and edges correspond to structural or functional connections between them. To explore the variability of connectomes - to address both basic science questions regarding the structure of the brain, and medical health questions about psychiatry and neurology - one can study the topological properties of these brain-graphs. We define multivariate glocal graph invariants: these are features of the graph that capture various local and global topological properties of the graphs. We show that the collection of features can collectively be computed via a combination of daisy-chaining, sparse matrix representation and computations, and efficient approximations. Our custom open-source Python package serves as a back-end to a Web-service that we have created to enable researchers to upload graphs, and download the corresponding invariants in a number of different formats. Moreover, we built this package to support distributed processing on multicore machines. This is therefore an enabling technology for network science, lowering the barrier of entry by providing tools to biologists and analysts who otherwise lack these capabilities. As a demonstration, we run our code on 120 brain-graphs, each with approximately 16M vertices and up to 90M edges. © 2013 IEEE.}
},

@article{Nikolaidis343392,
	title = {Bagging Improves Reproducibility of Functional Parcellation of the Human Brain},
	author = {Nikolaidis, Aki and Heinsfeld, Anibal Solon and Xu, Ting and Bellec, Pierre and Vogelstein, Joshua and Milham, Michael},
	author+an = {5=highlight},
	year = {2019},
	keywords = {conference},
	url = {https://doi.org/10.1101/343392},
	month = {6},
	pages = {343-392},
	journal = {bioRxiv},
	doi = {10.1101/343392},
	abstract = {Increasing the reproducibility of neuroimaging measurement addresses a central impediment to the clinical impact of human neuroscience. Recent efforts demonstrating variance in functional brain organization within and between individuals shows a need for improving reproducibility of functional parcellations without long scan times. We apply bootstrap aggregation, or bagging, to the problem of improving reproducibility in functional parcellation. We use two large datasets to demonstrate that compared to a standard clustering framework, bagging improves the reproducibility and test-retest reliability of both cortical and subcortical functional parcellations across a range of sites, scanners, samples, scan lengths, and clustering parameters. With as little as six minutes of scan time bagging creates more reproducible parcellations than standard approaches with twice as much data. This suggests bagging may be a key method for improving functional parcellation and bringing functional neuroimaging-based measurement closer to clinical impact.},
	publisher = {Cold Spring Harbor Laboratory}
},

@article{Petralia2013,
	title = {Multiscale Dictionary Learning for Estimating Conditional Distributions},
	author = {Petralia, Francesca and Vogelstein, Joshua and Dunson, David B},
	author+an = {2=highlight},
	year = {2013},
	keywords = {conference},
	url = {https://papers.nips.cc/paper/4944-multiscale-dictionary-learning-for-estimating-conditional-distributions},
	journal = {Advances in Neural Information Processing Systems},
	isbn = {10.1186/2042-1001-1-16},
	abstract = {Nonparametric estimation of the conditional distribution of a response given high- dimensional features is a challenging problem. It is important to allownot only the mean but also the variance and shape of the response density to change flexibly with features, which are massive-dimensional. We propose a multiscale dictio- nary learning model, which expresses the conditional response density as a convex combination of dictionary densities, with the densities used and their weights de- pendent on the path through a tree decomposition of the feature space. Afast graph partitioning algorithm is applied to obtain the tree decomposition, with Bayesian methods then used to adaptively prune and average over different sub-trees in a soft probabilistic manner. The algorithm scales efficiently to approximately one million features. State of the art predictive performance is demonstrated for toy examples and two neuroscience applications including up to a million features. 1},
	issn = {10495258},
	pmid = {25233306}
},

@inproceedings{mhembere2017knor,
	title = {knor : A NUMA-Optimized In-Memory , Distributed and Semi-External-Memory k-means Library},
	author = {Mhembere, Disa and Priebe, Carey E and Vogelstein, Joshua T and Burns, Randal},
	author+an = {1=trainee;3=highlight},
	year = {2017},
	keywords = {conference},
	url = {https://arxiv.org/abs/1606.08905},
	address = {Proceedings of the 26th International Symposium on High-Performance Parallel and Distributed Computing},
	booktitle = {Proceedings of the 26th International Symposium on High-Performance Parallel and Distributed Computing},
	isbn = {9781450346993},
	organization = {ACM}
},

@inproceedings{Zheng2015,
	title = {FlashGraph: Processing Billion-Node Graphs on an Array of Commodity SSDs},
	author = {Zheng, Da and Mhembere, Disa and Burns, Randal and Vogelstein, Joshua T and Priebe, Carey E and Szalay, Alexander S},
	author+an = {1=trainee;2=trainee;4=highlight},
	year = {2015},
	keywords = {conference},
	url = {http://arxiv.org/abs/1408.0500},
	booktitle = {USENIX Conference on File and Storage Technologies},
	doi = {10.1109/ICDE.2012.28},
	isbn = {9781931971201},
	issn = {10844627},
	eprint = {1408.0500}
},

@article{Lillaney2018,
	title = {Building NDStore through hierarchical storage management and microservice processing},
	author = {Lillaney, Kunal and Kleissas, Dean and Eusman, Alexander and Perlman, Eric and Gray Roncal, William and Vogelstein, Joshua T. and Burns, Randal},
	author+an = {1=trainee;6=highlight},
	year = {2018},
	keywords = {conference},
	url = {https://ieeexplore.ieee.org/abstract/document/8588656},
	pages = {223–233},
	journal = {Proceedings - IEEE 14th International Conference on eScience, e-Science},
	doi = {10.1109/eScience.2018.00037},
	isbn = {9781538691564},
	abstract = {We describe NDStore, a scalable multi-hierarchical data storage deployment for spatial analysis of neuroscience data on the AWS cloud. The system design is inspired by the requirement to maintain high I/O throughput for workloads that build neural connectivity maps of the brain from peta-scale imaging data using computer vision algorithms. We store all our data on the AWS object store S3 to limit our deployment costs. S3 serves as our base-tier of storage. Redis, an in-memory key-value engine, is used as our caching tier. The data is dynamically moved between the different storage tiers based on user access. All programming interfaces to this system are RESTful web-services. We include a performance evaluation that shows that our production system provides good performance for a variety of workloads by combining the assets of multiple cloud services.}
},

@inproceedings{Blockset21,
	title = {BLOCKSET (Block-Aligned Serialized Trees): Reducing Inference Latency for Tree Ensemble Deployment},
	author = {Madhyastha, Meghana and Lillaney, Kunal and Browne, James and Vogelstein, Joshua T. and Burns, Randal},
	author+an = {1=trainee;4=highlight},
	year = {2021},
	keywords = {conference},
	url = {https://doi.org/10.1145/3447548.3467368},
	address = {New York, NY, USA},
	pages = {1170–1179},
	booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
	doi = {10.1145/3447548.3467368},
	isbn = {9781450383325},
	abstract = {We present methods to serialize and deserialize gradient-boosted trees and randomforests that optimize inference latency when models are not loaded into memory. Thisarises when models are larger than memory, but also systematically when models aredeployed on low-resource devices in the Internet of Things or run as cloud microserviceswhere resources are allocated on demand. Block-Aligned Serialized Trees (BLOCKSET)introduce the concept of selective access for random forests and gradient boostedtrees in which only the parts of the model needed for inference are deserialized andloaded into memory. BLOCKSET combines concepts from external memory algorithms anddata-parallel layouts of random forests that maximize I/O-density for in-memory models.Using principles from external memory algorithms, we block-align the serializationformat in order to minimize the number of I/Os. For gradient boosted trees, this resultsin a more than five time reduction in inference latency over layouts that do not performselective access and a 2 times latency reduction over techniques that are selective,but do not encode I/O block boundaries in the layout.},
	publisher = {Association for Computing Machinery},
	numpages = {10},
	location = {Virtual Event, Singapore},
	series = {KDD '21}
},

@inproceedings{tomita2017roflmao,
	title = {ROFLMAO: Robust oblique forests with linear MAtrix operations},
	author = {Tomita, Tyler M. and Maggioni, Mauro and Vogelstein, Joshua T.},
	author+an = {1=trainee;3=highlight},
	year = {2017},
	keywords = {conference},
	url = {https://doi.org/10.1137/1.9781611974973.56},
	pages = {498–506},
	booktitle = {Proceedings of the 17th SIAM International Conference on Data Mining, SDM 2017},
	doi = {10.1137/1.9781611974973.56},
	isbn = {9781611974874},
	abstract = {Random Forest (RF) remains one of the most widely used general purpose classification methods. Two recent largescale empirical studies demonstrated it to be the best overall classification method among a variety of methods evaluated. One of its main limitations, however, is that it is restricted to only axis-aligned recursive partitions of the feature space. Consequently, RF is particularly sensitive to the orientation of the data. Several studies have proposed "oblique" decision forest methods to address this limitation. However, these methods either have a time and space complexity significantly greater than RF, are sensitive to unit and scale, or empirically do not perform as well as RF on real data. One promising oblique method that was proposed alongside the canonical RF method, called Forest-RC (F-RC), has not received as much attention by the community. Despite it being just as old as RF, virtually no studies exist investigating its theoretical or empirical performance. In this work, we demonstrate that F-RC empirically outperforms RF and another recently proposed oblique method called Random Rotation Random Forest, while approximately maintaining the same computational complexity. Furthermore, a variant of F-RC which rank transforms the data prior to learning is especially invariant to affine transformations and robust to data corruption. Open source code is available.},
	organization = {SIAM}
},

@article{Kutten2016b,
	title = {A large deformation diffeomorphic approach to registration of CLARITY images via mutual information},
	author = {Kutten, Kwame S. and Charon, Nicolas and Miller, Michael I. and Ratnanather, J. Tilak and Matelsky, Jordan and Baden, Alexander D. and Lillaney, Kunal and Deisseroth, Karl and Ye, Li and Vogelstein, Joshua T.},
	author+an = {1=trainee;5=trainee;6=trainee;7=trainee;10=highlight},
	year = {2017},
	keywords = {conference},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-66182-7_32},
	pages = {275–282},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	booktitle = {Medical Image Computing and Computer Assisted Intervention − MICCAI 2017},
	doi = {10.1007/978-3-319-66182-7_32},
	isbn = {9783319661810},
	abstract = {CLARITY is a method for converting biological tissues into translucent and porous hydrogel-tissue hybrids. This facilitates interrogation with light sheet microscopy and penetration of molecular probes while avoiding physical slicing. In this work, we develop a pipeline for registering CLARIfied mouse brains to an annotated brain atlas. Due to the novelty of this microscopy technique it is impractical to use absolute intensity values to align these images to existing standard atlases. Thus we adopt a large deformation diffeomorphic approach for registering images via mutual information matching. Furthermore we show how a cascaded multi-resolution approach can improve registration quality while reducing algorithm run time. As acquired image volumes were over a terabyte in size, they were far too large for work on personal computers. Therefore the NeuroData computational infrastructure was deployed for multi-resolution storage and visualization of these images and aligned annotations on the web.},
	issn = {16113349},
	eprint = {1612.00356},
	archiveprefix = {arXiv},
	arxivid = {1613.00356},
	editor = {Descoteaux, Maxime and Maier-Hein, Lena and Franz, Alfred and Jannin, Pierre and Collins, D. Louis and Duchesne, Simon}
},

@article{Kutten2016,
	title = {Deformably registering and annotating whole CLARITY brains to an atlas via masked LDDMM},
	author = {Kutten, Kwame S. and Vogelstein, Joshua T. and Charon, Nicolas and Ye, Li and Deisseroth, Karl and Miller, Michael I.},
	author+an = {1=trainee;2=highlight},
	year = {2016},
	keywords = {conference},
	url = {https://doi.org/10.1117/12.2227444},
	volume = {9896},
	pages = {989616},
	journal = {Optics, Photonics and Digital Technologies for Imaging Applications IV},
	doi = {10.1117/12.2227444},
	isbn = {9781510601413},
	abstract = {The CLARITY method renders brains optically transparent to enable high-resolution imaging in the structurally intact brain. Anatomically annotating CLARITY brains is necessary for discovering which regions contain signals of interest. Manually annotating whole-brain, terabyte CLARITY images is difficult, time-consuming, subjective, and error-prone. Automatically registering CLARITY images to a pre-annotated brain atlas offers a solution, but is difficult for several reasons. Removal of the brain from the skull and subsequent storage and processing cause variable non-rigid deformations, thus compounding inter-subject anatomical variability. Additionally, the signal in CLARITY images arises from various biochemical contrast agents which only sparsely label brain structures. This sparse labeling challenges the most commonly used registration algorithms that need to match image histogram statistics to the more densely labeled histological brain atlases. The standard method is a multiscale Mutual Information B-spline algorithm that dynamically generates an average template as an intermediate registration target. We determined that this method performs poorly when registering CLARITY brains to the Allen Institute's Mouse Reference Atlas (ARA), because the image histogram statistics are poorly matched. Therefore, we developed a method (Mask-LDDMM) for registering CLARITY images, that automatically find the brain boundary and learns the optimal deformation between the brain and atlas masks. Using Mask-LDDMM without an average template provided better results than the standard approach when registering CLARITY brains to the ARA. The LDDMM pipelines developed here provide a fast automated way to anatomically annotate CLARITY images. Our code is available as open source software at http://NeuroData.io.},
	issn = {1996756X},
	eprint = {1605.02060},
	archiveprefix = {arXiv},
	arxivid = {1605.02060}
},

@article{zheng2016flashr,
	title = {FlashR: R-Programmed Parallel and Scalable Machine Learning using SSDs},
	author = {Zheng, Da and Mhembere, Disa and Vogelstein, Joshua T. and Priebe, Carey E. and Burns, Randal},
	author+an = {1=trainee;2=trainee;3=highlight},
	year = {2017},
	keywords = {conference},
	url = {http://arxiv.org/abs/1604.06414},
	month = {5},
	journal = {PPoPP},
	abstract = {R is one of the most popular programming languages for statistics and machine learning, but the R framework is relatively slow and unable to scale to large datasets. The general approach for speeding up an implementation in R is to implement the algorithms in C or FORTRAN and provide an R wrapper. FlashR takes a different approach: it executes R code in parallel and scales the code beyond memory capacity by utilizing solid-state drives (SSDs) automatically. It provides a small number of generalized operations (GenOps) upon which we reimplement a large number of matrix functions in the R base package. As such, FlashR parallelizes and scales existing R code with little/no modification. To reduce data movement between CPU and SSDs, FlashR evaluates matrix operations lazily, fuses operations at runtime, and uses cache-aware, two-level matrix partitioning. We evaluate FlashR on a variety of machine learning and statistics algorithms on inputs of up to four billion data points. FlashR out-of-core tracks closely the performance of FlashR in-memory. The R code for machine learning algorithms executed in FlashR outperforms the in-memory execution of H2O and Spark MLlib by a factor of 2-10 and outperforms Revolution R Open by more than an order of magnitude.},
	eprint = {1604.06414},
	archiveprefix = {arXiv},
	arxivid = {1604.06414}
},

@inproceedings{Kulkarni2013,
	title = {Sex differences in the human connectome},
	author = {Kulkarni, Vivek and Pudipeddi, Jagat Sastry and Akoglu, Leman and Vogelstein, Joshua T and Vogelstein, R Jacob and Ryman, Sephira and Jung, Rex E},
	author+an = {4=highlight},
	year = {2013},
	keywords = {conference},
	url = {https://pdfs.semanticscholar.org/98da/eeccc6d3cc80b789de30ecf8790c56950739.pdf},
	volume = {8211 LNAI},
	pages = {82–91},
	booktitle = {Brain and Health Informatics},
	doi = {10.1007/978-3-319-02753-1_9},
	isbn = {9783319027524},
	abstract = {The human brain and the neuronal networks comprising it are of immense interest to the scientific community. In this work, we focus on the structural connectivity of human brains, investigating sex differences across male and female connectomes (brain-graphs) for the knowledge discovery problem "Which brain regions exert differences in connectivity across the two sexes?". One of our main findings discloses the statistical difference at the pars orbitalis of the connectome between sexes, which has been shown to function in language production. Moreover, we use these discriminative regions for the related learning problem "Can we classify a given human connectome to belong to one of the sexes just by analyzing its connectivity structure?". We show that we can learn decision tree as well as support vector machine classification models for this task. We show that our models achieve up to 79},
	issn = {03029743},
	organization = {Springer}
},

@inproceedings{burns2013open,
	title = {The Open Connectome Project Data Cluster: Scalable Analysis and Vision for High-Throughput Neuroscience},
	author = {Burns, Randal and Roncal, William Gray and Kleissas, Dean and Lillaney, Kunal and Manavalan, Priya and Perlman, Eric and Berger, Daniel R. and Bock, Davi D. and Chung, Kwanghun and Grosenick, Logan and Kasthuri, Narayanan and Weiler, Nicholas C. and Deisseroth, Karl and Kazhdan, Michael and Lichtman, Jeff and Reid, R. Clay and Smith, Stephen J. and Szalay, Alexander S. and Vogelstein, Joshua T. and Vogelstein, R. Jacob},
	author+an = {2=trainee;4=trainee;19=highlight},
	year = {2013},
	keywords = {conference},
	url = {http://arxiv.org/abs/1306.3543},
	booktitle = {ACM International Conference Proceeding Series},
	doi = {10.1145/2484838.2484870},
	isbn = {978-1-4503-1921-8},
	abstract = {We describe a scalable database cluster for the spatial analysis and annotation of high-throughput brain imaging data, initially for 3-d electron microscopy image stacks, but for time-series and multi-channel data as well. The system was designed primarily for workloads that build connectomes—neural connectivity maps of the brain—using the parallel execution of computer vision algorithms on high-performance compute clusters. These services and open-science data sets are publicly available at http://openconnecto.me. The system design inherits much from NoSQL scale-out and data-intensive computing architectures. We distribute data to cluster nodes by partitioning a spatial index. We direct I/O to different systems—reads to parallel disk arrays and writes to solid-state storage—to avoid I/O interference and maximize throughput. All programming interfaces are RESTful Web services, which are simple and stateless, improving scalability and usability. We include a performance evaluation of the production system, highlighting the effectiveness of spatial data organization.},
	issn = {15378276},
	eprint = {1306.3543},
	archiveprefix = {arXiv},
	arxivid = {1306.3543},
	pmid = {24401992},
	organization = {ACM}
},

@article{Koutra2013,
	title = {DELTACON: A principled massive-graph similarity function},
	author = {Koutra, Danai and Vogelstein, Joshua T. and Faloutsos, Christos},
	author+an = {2=highlight},
	year = {2013},
	keywords = {conference},
	url = {http://arxiv.org/abs/1304.4657},
	pages = {162–170},
	journal = {Proceedings of the 2013 SIAM International Conference on Data Mining, SDM 2013},
	doi = {10.1137/1.9781611972832.18},
	isbn = {9781611972627},
	abstract = {How much did a network change since yesterday? How different is the wiring between Bob's brain (a left-handed male) and Alice's brain (a right-handed female)? Graph similarity with known node correspondence, i.e. the detection of changes in the connectivity of graphs, arises in numerous settings. In this work, we formally state the axioms and desired properties of the graph similarity functions, and evaluate when state-of-the-art methods fail to detect crucial connectivity changes in graphs. We propose DeltaCon, a principled, intuitive, and scalable algorithm that assesses the similarity between two graphs on the same nodes (e.g. employees of a company, customers of a mobile carrier). Experiments on various synthetic and real graphs showcase the advantages of our method over existing similarity measures. Finally, we employ DeltaCon to real applications: (a) we classify people to groups of high and low creativity based on their brain connectivity graphs, and (b) do temporal anomaly detection in the who-emails-whom Enron graph.},
	issn = {1095-712X},
	eprint = {1304.4657},
	archiveprefix = {arXiv},
	arxivid = {1304.4657},
	chapter = {17}
},

@inproceedings{GrayRoncal2013,
	title = {MIGRAINE: MRI graph reliability analysis and inference for connectomics},
	author = {Roncal, William Gray and Koterba, Zachary H. and Mhembere, Disa and Kleissas, Dean M. and Vogelstein, Joshua T. and Burns, Randal and Bowles, Anita R. and Donavos, Dimitrios K. and Ryman, Sephira and Jung, Rex E. and Wu, Lei and Calhoun, Vince and Vogelstein, R. Jacob},
	author+an = {1=trainee;3=trainee;5=highlight},
	year = {2013},
	keywords = {conference},
	url = {http://ieeexplore.ieee.org/document/6736878/},
	month = {12},
	pages = {313-316},
	booktitle = {2013 IEEE Global Conference on Signal and Information Processing},
	doi = {10.1109/GlobalSIP.2013.6736878},
	isbn = {9781479902484},
	abstract = {Currently, connectomes (e.g., functional or structural brain graphs) can be estimated in humans at ≈ 1 mm3 scale using a combination of diffusion weighted magnetic resonance imaging, functional magnetic resonance imaging and structural magnetic resonance imaging scans. This manuscript summarizes a novel, scalable implementation of open-source algorithms to rapidly estimate magnetic resonance connectomes, using both anatomical regions of interest (ROIs) and voxel-size vertices. To assess the reliability of our pipeline, we develop a novel non-parametric non-Euclidean reliability metric. Here we provide an overview of the methods used, demonstrate our implementation, and discuss available user extensions. We conclude with results showing the efficacy and reliability of the pipeline over previous state-of-the-art.},
	eprint = {1312.4875},
	publisher = {IEEE}
},

@article{Huys2009,
	title = {Psychiatry: Insights into depression through normative decision-making models},
	author = {Huys, Quentin J and Vogelstein, Joshua and Dayan, Peter},
	author+an = {2=highlight},
	year = {2008},
	keywords = {conference},
	url = {http://papers.nips.cc/paper/3563-psychiatry-insights-into-depression-through-normative-decision-making-models.pdf},
	journal = {Advances in Neural Information Processing Systems}
},

@inproceedings{GrayRoncal2015a,
	title = {VESICLE: Volumetric Evaluation of Synaptic Inferfaces using Computer Vision at Large Scale},
	author = {Roncal, William Gray and Pekala, Michael and Kaynig-Fittkau, Verena and Kleissas, Dean M and Vogelstein, Joshua T and Pfister, Hanspeter and Burns, Randal and Vogelstein, R Jacob and Chevillet, Mark A and Hager, Gregory D},
	author+an = {1=trainee;5=highlight},
	year = {2015},
	keywords = {conference},
	url = {http://arxiv.org/abs/1403.3724},
	pages = {81.1–81.13},
	booktitle = {British Machine Vision Conference},
	doi = {10.5244/c.29.81},
	abstract = {An open challenge problem at the forefront of modern neuroscience is to obtain a comprehensive mapping of the neural pathways that underlie human brain function; an enhanced understanding of the wiring diagram of the brain promises to lead to new breakthroughs in diagnosing and treating neurological disorders. Inferring brain structure from image data, such as that obtained via electron microscopy (EM), entails solving the problem of identifying biological structures in large data volumes. Synapses, which are a key communication structure in the brain, are particularly difficult to detect due to their small size and limited contrast. Prior work in automated synapse detection has relied upon time-intensive biological preparations (post-staining, isotropic slice thicknesses) in order to simplify the problem. This paper presents VESICLE, the first known approach designed for mammalian synapse detection in anisotropic, non-post-stained data. Our methods explicitly leverage biological context, and the results exceed existing synapse detection methods in terms of accuracy and scalability. We provide two different approaches - one a deep learning classifier (VESICLE-CNN) and one a lightweight Random Forest approach (VESICLE-RF) to offer alternatives in the performance-scalability space. Addressing this synapse detection challenge enables the analysis of high-throughput imaging data soon expected to reach petabytes of data, and provide tools for more rapid estimation of brain-graphs. Finally, to facilitate community efforts, we developed tools for large-scale object detection, and demonstrated this framework to find 50,000 synapses in 60,000 m 3 (220 GB on disk) of electron microscopy data.},
	eprint = {1403.3724},
	archiveprefix = {arXiv},
	arxivid = {1403.3724}
},

@article{Browne2018,
	title = {Forest packing: Fast Parallel, Decision Forests},
	author = {Browne, James and Mhembere, Disa and Tomita, Tyler M. and Vogelstein, Joshua T. and Burns, Randal},
	author+an = {1=trainee;2=trainee;3=trainee;4=highlight},
	year = {2018},
	keywords = {conference},
	url = {https://arxiv.org/abs/1806.07300},
	month = {6},
	pages = {46–54},
	journal = {SIAM International Conference on Data Mining, SDM},
	doi = {10.1137/1.9781611975673.6},
	isbn = {9781611975673},
	abstract = {Decision Forests are popular machine learning techniques that assist scientists to extract knowledge from massive data sets. This class of tool remains popular because of their interpretability and ease of use, unlike other modern machine learning methods, such as kernel machines and deep learning. Decision forests also scale well for use with large data because training and run time operations are trivially parallelizable allowing for high inference throughputs. A negative aspect of these forests, and an untenable property for many real time applications, is their high inference latency caused by the combination of large model sizes with random memory access patterns. We present memory packing techniques and a novel tree traversal method to overcome this deficiency. The result of our system is a grouping of trees into a hierarchical structure. At low levels, we pack the nodes of multiple trees into contiguous memory blocks so that each memory access fetches data for multiple trees. At higher levels, we use leaf cardinality to identify the most popular paths through a tree and collocate those paths in contiguous cache lines. We extend this layout with a re-ordering of the tree traversal algorithm to take advantage of the increased memory throughput provided by out-of-order execution and cache-line prefetching. Together, these optimizations increase the performance and parallel scalability of classification in ensembles by a factor of ten over an optimized C++ implementation and a popular R-language implementation.},
	eprint = {1806.07300},
	archiveprefix = {arXiv},
	arxivid = {1806.07300}
},

@article{Fiori2013,
	title = {Robust Multimodal Graph Matching: Sparse Coding Meets Graph Matching},
	author = {Fiori, Marcelo and Sprechmann, Pablo and Vogelstein, Joshua and Muse, Pablo and Sapiro, Guillermo},
	author+an = {3=highlight},
	year = {2013},
	keywords = {conference},
	url = {http://papers.nips.cc/paper/4925-robust-multimodal-graph-matching-sparse-coding-meets-graph-matching},
	journal = {Advances in Neural Information Processing Systems},
	isbn = {10.1186/2042-1001-1-16},
	abstract = {Graph matching is a challenging problem with very important applications in a wide range of fields, from image and video analysis to biological and biomedical problems. We propose a robust graph matching algorithm inspired in sparsity-related techniques. We cast the problem, resembling group or collaborative sparsity formulations, as a non-smooth convex optimization problem that can be efficiently solved using augmented Lagrangian techniques. The method can deal with weighted or unweighted graphs, as well as multimodal data, where different graphs represent different types of data. The proposed approach is also naturally integrated with collaborative graph inference techniques, solving general network inference problems where the observed variables, possibly coming from different modalities, are not in correspondence. The algorithm is tested and compared with state-of-the-art graph matching techniques in both synthetic and real graphs. We also present results on multimodal graphs and applications to collaborative inference of brain connectivity from alignment-free functional magnetic resonance imaging (fMRI) data. The code is publicly available.},
	issn = {10495258},
	eprint = {arXiv},
	pmid = {25233306},
	annote = {(spotlight)}
},

@article{Cornelis2013,
	title = {Bayesian crack detection in ultra high resolution multimodal images of paintings},
	author = {Cornelis, Bruno and Yang, Yun and Vogelstein, Joshua T. and Dooms, Ann and Daubechies, Ingrid and Dunson, David},
	author+an = {3=highlight},
	year = {2013},
	keywords = {conference},
	url = {http://arxiv.org/abs/1304.5894},
	journal = {18th International Conference on Digital Signal Processing},
	doi = {10.1109/ICDSP.2013.6622710},
	isbn = {9781467358057},
	abstract = {The preservation of our cultural heritage is of paramount importance. Thanks to recent developments in digital acquisition techniques, powerful image analysis algorithms are developed which can be useful non-invasive tools to assist in the restoration and preservation of art. In this paper we propose a semi-supervised crack detection method that can be used for high-dimensional acquisitions of paintings coming from different modalities. Our dataset consists of a recently acquired collection of images of the Ghent Altarpiece (1432), one of Northern Europe's most important art masterpieces. Our goal is to build a classifier that is able to discern crack pixels from the background consisting of non-crack pixels, making optimal use of the information that is provided by each modality. To accomplish this we employ a recently developed non-parametric Bayesian classifier, that uses tensor factorizations to characterize any conditional probability. A prior is placed on the parameters of the factorization such that every possible interaction between predictors is allowed while still identifying a sparse subset among these predictors. The proposed Bayesian classifier, which we will refer to as conditional Bayesian tensor factorization or CBTF, is assessed by visually comparing classification results with the Random Forest (RF) algorithm. © 2013 IEEE.},
	eprint = {1304.5894}
},

@inproceedings{GeoForests2,
	title = {Geodesic Forests},
	author = {Madhyastha, Meghana and Li, Gongkai and Strnadová-Neeley, Veronika and Browne, James and Vogelstein, Joshua T. and Burns, Randal and Priebe, Carey E.},
	author+an = {1=trainee;5=highlight},
	year = {2020},
	keywords = {conference},
	url = {https://doi.org/10.1145/3394486.3403094},
	month = {10},
	address = {New York, NY, USA},
	pages = {513–523},
	booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	doi = {10.1145/3394486.3403094},
	isbn = {9781450379984},
	abstract = {Together with the curse of dimensionality, nonlinear dependencies in large data sets persist as major challenges in data mining tasks. A reliable way to accurately preserve nonlinear structure is to compute geodesic distances between data points. Manifold learning methods, such as Isomap, aim to preserve geodesic distances in a Riemannian manifold. However, as manifold learning algorithms operate on the ambient dimensionality of the data, the essential step of geodesic distance computation is sensitive to high-dimensional noise. Therefore, a direct application of these algorithms to high-dimensional, noisy data often yields unsatisfactory results and does not accurately capture nonlinear structure.We propose an unsupervised random forest approach called geodesic forests (GF) to geodesic distance estimation in linear and nonlinear manifolds with noise. GF operates on low-dimensional sparse linear combinations of features, rather than the full observed dimensionality. To choose the optimal split in a computationally efficient fashion, we developed Fast-BIC, a fast Bayesian Information Criterion statistic for Gaussian mixture models.We additionally propose geodesic precision and geodesic recall as novel evaluation metrics that quantify how well the geodesic distances of a latent manifold are preserved. Empirical results on simulated and real data demonstrate that GF is robust to high-dimensional noise, whereas other methods, such as Isomap, UMAP, and FLANN, quickly deteriorate in such settings. Notably, GF is able to estimate geodesic distances better than other approaches on a real connectome dataset.},
	publisher = {Association for Computing Machinery},
	numpages = {11},
	location = {Virtual Event, CA, USA},
	series = {KDD '20}
},

@article{Carlson2013a,
	title = {Real-Time Inference for a Gamma Process Model of Neural Spiking},
	author = {Carlson, David E and Rao, Vinayak and Vogelstein, Joshua T and Carin, Lawrence},
	author+an = {3=highlight},
	year = {2013},
	keywords = {conference},
	url = {http://papers.nips.cc/paper/5061-real-time-inference-for-a-gamma-process-model-of-neural-spiking.pdf},
	journal = {Advances in Neural Information Processing Systems 26},
	abstract = {With simultaneous measurements from ever increasing populations of neurons, there is a growing need for sophisticated tools to recover signals from individual neurons. In electrophysiology experiments, this classically proceeds in a two-step process: (i) threshold the waveforms to detect putative spikes and (ii) cluster the waveforms into single units (neurons). We extend previous Bayesian nonparametric models of neural spiking to jointly detect and cluster neurons using a Gamma process model. Importantly, we develop an online approximate inference scheme enabling real-time analysis, with performance exceeding the previous state-of-the-art. Via exploratory data analysis-using data with partial ground truth as well as two novel data sets-we find several features of our model collectively contribute to our improved performance including: (i) accounting for colored noise, (ii) detecting overlapping spikes, (iii) tracking waveform dynamics, and (iv) using multiple channels. We hope to enable novel experiments simultaneously measuring many thousands of neurons and possibly adapting stimuli dynamically to probe ever deeper into the mysteries of the brain.},
	issn = {10495258}
},

@inproceedings{kutten2017large,
	title = {A Large Deformation Diffeomorphic Approach to Registration of CLARITY Images via Mutual Information},
	author = {Kutten, Kwame S and Charon, Nicolas and Miller, Michael I and Ratnanather, J Tilak and Matelsky, Jordan and Baden, Alexander D and Lillaney, Kunal and Deisseroth, Karl and Ye, Li and Vogelstein, Joshua T},
	year = {2017},
	keywords = {converence},
	url = {https://link.springer.com/content/pdf/10.1007},
	month = {9},
	booktitle = {International Conference on Medical Image Computing and Computer-Assisted Intervention},
	abstract = {CLARITY is a method for converting biological tissues into translucent and porous hydrogel-tissue hybrids. This facilitates interro-gation with light sheet microscopy and penetration of molecular probes while avoiding physical slicing. In this work, we develop a pipeline for registering CLARIfied mouse brains to an annotated brain atlas. Due to the novelty of this microscopy technique it is impractical to use absolute intensity values to align these images to existing standard atlases. Thus we adopt a large deformation diffeomorphic approach for registering images via mutual information matching. Furthermore we show how a cascaded multi-resolution approach can improve registration quality while reducing algorithm run time. As acquired image volumes were over a terabyte in size, they were far too large for work on personal computers. Therefore the NeuroData computational infrastructure was deployed for multi-resolution storage and visualization of these images and aligned annotations on the web.},
	organization = {Springer}
},

@article{gopalakrishnan2020multiscale,
	title = {Multiscale Comparative Connectomics},
	author = {Gopalakrishnan, Vivek and Chung, Jaewon and Bridgeford, Eric and Pedigo, Benjamin D. and Arroyo, Jesús and Upchurch, Lucy and Johnsom, G. Allan and Wang, Nian and Park, Youngser and Priebe, Carey E. and Vogelstein, Joshua T.},
	author+an = {1=trainee; 2=trainee; 3=trainee; 4=trainee; 5=trainee; 11=highlight},
	year = {2020},
	keywords = {in-review},
	url = {https://arxiv.org/abs/2011.14990},
	month = {12},
	journal = {arXiv},
	eprint = {2011.14990}
},

@article{Xu2021sdtf,
	title = {Simplest Streaming Trees},
	author = {Haoyin Xu and Jayanta Dey and Sambit Panda and Joshua T. Vogelstein},
	author+an = {1=trainee;2=trainee;3=trainee;4=highlight},
	year = {2021},
	keywords = {in-review},
	url = {https://arxiv.org/abs/2110.08483},
	month = {10},
	journal = {arXiv},
	eprint = {2110.08483},
	arxivid = {2110.08483},
	archivePrefix = {arXiv},
	primaryClass = {cs.LG}
},

@article{shen2020high,
	title = {High-dimensional independence testing and maximum marginal correlation},
	author = {Shen, Shen and Cencheng, Cencheng},
	year = {2020},
	keywords = {in-review},
	url = {https://arxiv.org/abs/2001.01095},
	journal = {arXiv}
},

@article{pedigo2022bisected,
	title = {Bisected graph matching improves automated pairing of bilaterally homologous neurons from connectomes},
	author = {Pedigo, Benjamin D. and Winding, Michael and Priebe, Carey E. and Vogelstein, Joshua T.},
	author+an = {1=trainee; 4=highlight},
	year = {2022},
	keywords = {peer-reviewed},
	url = {https://www.biorxiv.org/content/10.1101/2022.05.19.492713},
	month = {05},
	journal = {Network Neuroscience},
	eprint = {2022.05.19.492713},
	archivePrefix = {bioRxiv}
},

@article{pedigo2023connectome,
	title={The connectome of an insect brain},
	author={Michael Winding and Benjamin D Pedigo and Christopher L Barnes and Heather G Patsolic and Youngser Park and Tom Kazimiers and Akira Fushiki and Ingrid V Andrade and Avinash Khandelwal and Javier Valdes-Aleman and Feng Li and Nadine Randel and Elizabeth Barsotti and Ana Correia and Richard D Fetter and Volker Hartenstein and Carey E Priebe and Joshua T Vogelstein and Albert Cardona and Marta Zlatic},
	author+an = {2=trainee;18=highlight},
	year={2023},
	keywords = {peer-reviewed},
	url = {https://www.science.org/doi/abs/10.1126/science.add9330},
	abstract = {Brains contain networks of interconnected neurons and so knowing the network architecture is essential for understanding
	brain function. We therefore mapped the synaptic-resolution connectome of an entire insect brain (Drosophila larva) with rich behavior,
	including learning, value computation, and action selection, comprising 3016 neurons and 548,000 synapses. We characterized neuron types,
	hubs, feedforward and feedback pathways, as well as cross-hemisphere and brain-nerve cord interactions. We found pervasive multisensory
	and interhemispheric integration, highly recurrent architecture, abundant feedback from descending neurons, and multiple novel circuit motifs.
	The brain’s most recurrent circuits comprised the input and output neurons of the learning center. Some structural features,
	including multilayer shortcuts and nested recurrent loops, resembled state-of-the-art deep learning architectures.
	The identified brain architecture provides a basis for future experimental and theoretical studies of neural circuits.},
	month = {3},
	journal = {science}
},

@article{pedigo2023generative,
	title = {Generative network modeling reveals quantitative definitions of bilateral symmetry exhibited by a whole insect brain connectome},
	author = {Benjamin D Pedigo and Mike Powell and Eric W Bridgeford and Michael Winding and Carey E Priebe and Joshua T Vogelstein},
	author+an = {1=trainee;2-trainee;6=highlight},
	year = {2023},
	keywords = {peer-reviewed},
	url = {https://elifesciences.org/articles/83739},
	abstract = {Comparing connectomes can help explain how neural connectivity is related to genetics, disease, development, learning, and behavior. 
	However, making statistical inferences about the significance and nature of differences between two networks is an open problem, and such 
	analysis has not been extensively applied to nanoscale connectomes. Here, we investigate this problem via a case study on the bilateral 
	symmetry of a larval Drosophila brain connectome. We translate notions of ‘bilateral symmetry’ to generative models of the network structure 
	of the left and right hemispheres, allowing us to test and refine our understanding of symmetry. We find significant differences in connection 
	probabilities both across the entire left and right networks and between specific cell types. By rescaling connection probabilities or removing 
	certain edges based on weight, we also present adjusted definitions of bilateral symmetry exhibited by this connectome. This work shows 
	how statistical inferences from networks can inform the study of connectomes, facilitating future comparisons of neural structures.},
	month = {3},
	journal = {eLife Sciences Publications, Ltd},
},

@article{chen2020multiple,
	title = {Multiple Network Embedding for Anomaly Detection in Time Series of Graphs},
	author = {Guodong Chen and Jesús Arroyo and Avanti Athreya and Joshua Cape and Joshua T. Vogelstein and Youngser Park and Chris White and Jonathan Larson and Weiwei Yang and Carey E. Priebe},
	author+an = {2=trainee; 5=highlight},
	year = {2020},
	keywords = {in-review},
	url = {https://arxiv.org/abs/2008.10055},
	month = {10},
	journal = {arXiv},
	eprint = {2008.10055},
	archivePrefix = {arXiv},
	primaryClass = {stat.ME}
},

@ARTICLE{Vogelstein2022-gj,
	title = {Prospective Learning: Back to the Future},
	author = {Vogelstein, Joshua T and Verstynen, Timothy and Kording, Konrad P and Isik, Leyla and Krakauer, John W and Etienne-Cummings, Ralph and Ogburn, Elizabeth L and Priebe, Carey E and Burns, Randal and Kutten, Kwame and Knierim, James J and Potash, James B and Hartung, Thomas and Smirnova, Lena and Worley, Paul and Savonenko, Alena and Phillips, Ian and Miller, Michael I and Vidal, Rene and Sulam, Jeremias and Charles, Adam and Cowan, Noah J and Bichuch, Maxim and Venkataraman, Archana and Li, Chen and Thakor, Nitish and Kebschull, Justus M and Albert, Marilyn and Xu, Jinchong and Shuler, Marshall Hussain and Caffo, Brian and Ratnanather, Tilak and Geisa, Ali and Roh, Seung-Eon and Yezerets, Eva and Madhyastha, Meghana and How, Javier J and Tomita, Tyler M and Dey, Jayanta and Huang, Ningyuan and Shin, Jong M and Kinfu, Kaleab Alemayehu and Chaudhari, Pratik and Baker, Ben and Schapiro, Anna and Jayaraman, Dinesh and Eaton, Eric and Platt, Michael and Ungar, Lyle and Wehbe, Leila and Kepecs, Adam and Christensen, Amy and Osuagwu, Onyema and Brunton, Bing and Mensh, Brett and Muotri, Alysson R and Silva, Gabriel and Puppo, Francesca and Engert, Florian and Hillman, Elizabeth and Brown, Julia and White, Chris and Yang, Weiwei},
	author+an = {1=highlight,33=trainee;35=trainee;36=trainee;37=trainee;38=trainee;39=trainee;40=trainee;41=trainee;42=trainee},
	year = {2022},
	keywords = {peer-reviewed},
	url = {https://arxiv.org/abs/2201.07372},
	month = {1},
	journal = {arXiv [cs.LG]}
},

@article{saadeldin2021graph,
	title = {Graph Matching via Optimal Transport},
	author = {Ali Saad-Eldin and Benjamin D. Pedigo and Carey E. Priebe and Joshua T. Vogelstein},
	author+an = {1=trainee;2=trainee;4=highlight},
	year = {2021},
	keywords = {in-review},
	url = {https://arxiv.org/abs/2111.05366},
	journal = {arXiv},
	eprint = {2111.05366},
	archivePrefix = {arXiv},
	primaryClass = {stat.ML}
},

@article{tomita2020robust,
	title = {Robust Similarity and Distance Learning via Decision Forests},
	author = {Tyler M. Tomita and Joshua T. Vogelstein},
	author+an = {2=highlight},
	year = {2020},
	keywords = {in-review},
	url = {https://arxiv.org/abs/2007.13843},
	journal = {arXiv},
	eprint = {2007.13843},
	archivePrefix = {arXiv},
	primaryClass = {stat.ML}
},

@article{xu2022guide,
	title = {A Guide for Quantifying and Optimizing Measurement Reliability for the Study of Individual Differences},
	author = {Xu, Ting and Cho, JaeWook and Kiar, Gregory and Bridgeford, Eric W and Vogelstein, Joshua T and Milham, Michael P},
	author+an = {4=trainee;5=highlight},
	year = {2022},
	keywords = {in-review},
	url = {https://www.biorxiv.org/content/10.1101/2022.01.27.478100v1},
	journal = {bioRxiv},
	publisher = {Cold Spring Harbor Laboratory}
},

@article{vogelstein2020general,
	title = {Omnidirectional Transfer for Quasilinear Lifelong Learning},
	author = {Joshua T. Vogelstein and Jayanta Dey and Hayden S. Helm and Will LeVine and Ronak D. Mehta and Ali Geisa 
	and Haoyin Xu and Gido M. van de Ven and Emily Chang and Chenyu Gao and Weiwei Yang and Bryan Tower and Jonathan Larson 
	and Christopher M. White and Carey E. Priebe},
	author+an = {1=highlight; 2=trainee; 3=trainee; 4=trainee; 5=trainee; 6=trainee; 7=trainee; 9=trainee; 10=trainee},
	year = {2020},
	keywords = {in-review},
	url = {https://arxiv.org/abs/2004.12908},
	journal = {arXiv},
	eprint = {2004.12908},
	archivePrefix = {arXiv},
	primaryClass = {cs.AI}
},

@article{dey2022kernel,
	title = {Out-of-distribution Detection Using Kernel Density Polytopes},
	author = {Jayanta Dey and Ashwin De Silva and Will LeVine and Jong Shin and Haoyin Xu and Ali Geisa and Tiffany Chu and Leyla Isik and Joshua T. Vogelstein},
	author+an = {1=trainee;2=trainee;3=trainee;4=trainee;5=trainee;6=trainee;8=highlight},
	year = {2022},
	keywords = {in-review},
	url = {https://arxiv.org/abs/2201.13001},
	month = {01},
	journal = {arXiv},
	eprint = {2201.13001},
	archivePrefix = {arXiv},
	primaryClass = {cs.LG}
},

@article{geisa2021theory,
	title = {Towards a theory of out-of-distribution learning},
	author = {Ali Geisa and Ronak Mehta and Hayden S. Helm and Jayanta Dey and Eric Eaton and Jeffery Dick and Carey E. Priebe and Joshua T. Vogelstein},
	author+an = {1=trainee;2=trainee;3=trainee;4=trainee;8=highlight},
	year = {2021},
	keywords = {in-review},
	url = {https://arxiv.org/abs/2109.14501},
	journal = {arXiv},
	eprint = {2109.14501},
	archivePrefix = {arXiv},
	primaryClass = {stat.ML}
},

@article{li2021covid,
	title = {COVID-19 outcomes among hospitalized men with or without exposure to alpha-1-adrenergic receptor blocking agents},
	author = {Li, Shilong and Jun, Tomi and Wang, Zichen and Kao, Yu-Han and Schadt, Emilio and Konig, Maximilian F 
	and Bettegowda, Chetan and Vogelstein, Joshua T and Papadopoulos, Nickolas and Parsons, Ramon E and others},
	author+an = {8=highlight},
	year = {2021},
	keywords = {peer-reviewed},
	url = {https://www.medrxiv.org/content/10.1101/2021.04.08.21255148v1.full},
	month = {4},
	journal = {Frontiers in Medicine},
	publisher = {Cold Spring Harbor Laboratory Press}
},

@article{Xu2021rfdn,
	title = {When are Deep Networks really better than Decision Forests at small sample sizes, and how?},
	author = {Haoyin Xu and Kaleab A. Kinfu and Will LeVine and Sambit Panda and Jayanta Dey and Michael Ainsworth 
	and Yu-Chung Peng and Madi Kusmanov and Florian Engert and Christopher M. White and Joshua T. Vogelstein and Carey E. Priebe},
	author+an = {1=trainee;2=trainee;3=trainee;4=trainee;5=trainee;6=trainee;7=trainee;8=trainee;11=highlight},
	year = {2021},
	keywords = {in-review},
	url = {https://arxiv.org/abs/2108.13637},
	month = {8},
	journal = {arXiv},
	eprint = {2108.13637},
	archiveprefix = {arXiv},
	arxivid = {2108.13637},
	primaryClass = {cs.LG}
},

@article{Lyzinski2014,
	title = {Seeded Graph Matching Via Joint Optimization of Fidelity and Commensurability},
	author = {Patsolic, Heather and Adali, Sancar and Vogelstein, Joshua T. and Park, Youngser 
	and Priebe, Carey E. and Li, Gongki and Lyzinski, Vince},
	author+an = {3=highlight},
	year = {2019},
	keywords = {peer-reviewed},
	url = {http://arxiv.org/abs/1401.3813},
	month = {1},
	journal = {arXiv},
	abstract = {We present a novel approximate graph matching algorithm that incorporates seeded data 
	into the graph matching paradigm. Our Joint Optimization of Fidelity and Commensurability (JOFC) 
	algorithm embeds two graphs into a common Euclidean space where the matching inference task can be 
	performed. Through real and simulated data examples, we demonstrate the versatility of our algorithm 
	in matching graphs with various characteristics–weightedness, directedness, loopiness, many-to-one 
	and many-to-many matchings, and soft seedings.},
	eprint = {1401.3813}
},

@article{madhyastha2020pacset,
	title = {PACSET (Packed Serialized Trees): Reducing Inference Latency for Tree Ensemble Deployment},
	author = {Madhyastha, Meghana and Lillaney, Kunal and Browne, James and Vogelstein, Joshua and Burns, Randal},
	author+an = {1=trainee;4=highlight},
	year = {2020},
	keywords = {in-review},
	url = {https://arxiv.org/abs/2011.05383},
	journal = {arXiv}
},

@article{pandaHyppoMultivariateHypothesis2021,
	title = {hyppo: A Multivariate Hypothesis Testing Python Package},
	author = {Panda, Sambit and Palaniappan, Satish and Xiong, Junhao and Bridgeford, Eric W. and Mehta, 
	Ronak and Shen, Cencheng and Vogelstein, Joshua T.},
	year = {2021},
	author+an = {1=trainee;4=trainee;5=trainee;6=trainee;7=highlight},
	keywords = {in-review},
	url = {https://arxiv.org/abs/1907.02088},
	month = {4},
	journal = {arXiv},
	abstract = {We introduce hyppo, a unified library for performing multivariate hypothesis testing, including 
	independence, two-sample, and k-sample testing. While many multivariate independence tests have R packages available, the interfaces are inconsistent and most are not available in Python. hyppo includes many state of the art multivariate testing procedures. The package is easy-to-use and is flexible enough to enable future extensions. The documentation and all releases are available at https://hyppo.neurodata.io.},
	eprint = {1907.02088},
	archiveprefix = {arXiv},
	primaryclass = {cs, stat},
	eprinttype = {arxiv},
	copyright = {All rights reserved},
	shorttitle = {Hyppo}
},

@article{perry2019manifold,
	title = {Manifold Forests: Closing the Gap on Neural Networks},
	author = {Perry, Ronan and Tomita, Tyler M and Patsolic, Jesse and Falk, Benjamin and Vogelstein, Joshua T},
	author+an = {1=trainee;2=trainee;5=highlight},
	year = {2019},
	keywords = {peer-reviewed},
	url = {https://arxiv.org/abs/1909.11799},
	month = {9},
	journal = {arXiv}
},

@article{mehta2019,
	title = {A Consistent Independence Test for Multivariate Time-Series},
	author = {Mehta, Ronak and Shen, Cencheng and Xu, Ting and Vogelstein, Joshua T.},
	author+an = {1=trainee;4=highlight},
	year = {2019},
	keywords = {in-review},
	url = {https://arxiv.org/abs/1908.06486},
	month = {10},
	journal = {arxiv}
},

@article{2019arXiv190700325M,
	title = {Random Forests for Adaptive Nearest Neighbor Estimation of Information-Theoretic Quantities},
	author = {Ronan Perry and Ronak Mehta and Richard Guo and Eva Yezerets and Jesús Arroyo and Mike Powell 
	and Hayden Helm and Cencheng Shen and Joshua T. Vogelstein},
	author+an = {1=trainee; 2=trainee; 4=trainee; 5=trainee; 6=trainee; 7=trainee; 9=highlight},
	year = {2021},
	keywords = {in-review},
	url = {https://arxiv.org/abs/1907.00325},
	month = {6},
	pages = {arXiv:1907.00325},
	journal = {arXiv},
	eprint = {1907.00325},
	archivePrefix = {arXiv},
	primaryClass = {cs.LG},
	eid = {arXiv:1907.00325},
	adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190700325M},
	adsnote = {Provided by the SAO/NASA Astrophysics Data System}
},

@article{Branch639674,
	title = {An optimized protocol for iDISCO+ rat brain clearing, imaging, and analysis},
	author = {Branch, Audrey and Tward, Daniel and Vogelstein, Joshua T and Wu, Zhuhao and Gallagher, Michela},
	author+an = {1=trainee;3=highlight},
	year = {2019},
	keywords = {tech},
	url = {https://doi.org/10.1101/639674},
	journal = {bioRxiv},
	doi = {10.1101/639674},
	abstract = {The advent of whole brain clearing and imaging methods have extended the breadth and depth 
	at which neural populations can be studied. However, these methods have yet to be applied to larger tissues, 
	such as the brains of the common laboratory rat, despite the importance of these models in behavioral neuroscience 
	research. Here we introduce an optimized iDISCO+ based immunolabeling and clearing methodology for application 
	to adult rat brain hemispheres. We validate this methodology through the testing of common antibodies. In order 
	to extend the accessibility of this methodology for general use, we have developed an open source platform for the 
	registration of rat brain volumes to standard brain atlases for high throughput analysis.},
	eprint = {https://www.biorxiv.org/content/early/2019/05/17/639674.full.pdf},
	publisher = {Cold Spring Harbor Laboratory}
},

@article{graphindependence2019,
	title = {Graph Independence Testing},
	author = {Xiong, Junhao and Shen, Cencheng and Arroyo, Jesús and Vogelstein, Joshua T.},
	author+an = {3=trainee;4=highlight},
	year = {2019},
	keywords = {tech},
	url = {https://arxiv.org/abs/1906.03661},
	month = {6},
	journal = {arXiv}
},

@article{optimal2019,
	title = {Optimal Experimental Design for Big Data: Applications in Brain Imaging},
	author = {Bridgeford, Eric W. and Wang, Shangsi and Yang, Zhi and Wang, Zeyi and Xu, 
	Ting and Craddock, Cameron and Kiar, Gregory and Gray-Roncal, William and Priebe, Carey E. and Caffo, Brian and Milham, Michael and Zuo, Xi-Nian and (CoRR) and Vogelstein, Joshua T.},
	author+an = {1=trainee;2=trainee;7=trainee;14=highlight},
	year = {2019},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1101/802629},
	month = {10},
	journal = {bioRxiv}
},

@article {Mehta2020.06,
	title = {Neuronal Classification from Network Connectivity via Adjacency Spectral Embedding},
	author = {Mehta, Ketan and Goldin, Rebecca F. and Marchette, David and Vogelstein, Joshua T. and Priebe, Carey E. and Ascoli, Giorgio A.},
	author+an = {4=highlight},
	year = {2020},
	keywords = {peer-reviewed},
	month = {6},
	journal = {bioRxiv},
	doi = {10.1101/2020.06.18.160259},
	abstract = {This work presents a novel strategy for classifying neurons, represented by nodes of a directed graph, based on their circuitry (edge connectivity). We assume a stochastic block model (SBM) where neurons belong together if they connect to neurons of other groups according to the same probability distributions. Following adjacency spectral embedding (ASE) of the SBM graph, we derive the number of classes and assign each neuron to a class with a Gaussian mixture model-based expectation-maximization (EM) clustering algorithm. To improve accuracy, we introduce a simple variation using random hierarchical agglomerative clustering to initialize the EM algorithm and picking the best solution over multiple EM restarts. We test this procedure on a large (n   212 - 215 neurons), sparse, biologically inspired connectome with eight neuron classes. The simulation results demonstrate that the proposed approach is broadly stable to the choice of dimensional embedding and scales extremely well as the number of neurons in the network increases. Clustering accuracy is robust to variations in model parameters and highly tolerant to simulated experimental noise, achieving perfect classifications with up to 40},
	eprint = {https://www.biorxiv.org/content/early/2020/06/20/2020.06.18.160259.full.pdf},
	publisher = {Cold Spring Harbor Laboratory},
	URL = {https://www.biorxiv.org/content/early/2020/06/20/2020.06.18.160259},
	elocation-id = {2020.06.18.160259}
},

@article{vogelstein2018geometric_2,
	title = {Geometric Dimensionality Reduction for Subsequent Classification},
	author = {Vogelstein, Joshua T and Bridgeford, Eric and Tang, Minh and Zheng, Da and Burns, Randal and Maggioni, Mauro},
	author+an = {1=highlight;2=trainee},
	year = {2018},
	keywords = {peer-reviewed},
	url = {https://arxiv.org/abs/1709.01233},
	month = {11},
	volume = {1050},
	pages = {21},
	journal = {arXiv}
},

@article{Wang2018,
	title = {Signal Subgraph Estimation Via Vertex Screening},
	author = {Wang, Shangsi and Shen, Cencheng and Badea, Alexandra and Priebe, Carey E and Vogelstein, Joshua T},
	author+an = {1=trainee;2=trainee;5=highlight},
	year = {2018},
	keywords = {tech},
	url = {https://arxiv.org/abs/1801.07683},
	month = {1},
	journal = {arXiv},
	eprint = {arXiv}
},

@article{bridgeford2023learning,
	title={Learning sources of variability from high-dimensional observational studies},
	author={Eric W. Bridgeford and Jaewon Chung and Brian Gilbert and Sambit Panda and Adam Li and Cencheng Shen and Alexandra Badea and Brian Caffo and Joshua T. Vogelstein},
	author+an = {1=trainee;2=trainee;4=trainee;5=trainee;6=trainee;7=trainee;9=highlight},
	year={2023},
	keywords = {in-review},
	url = {https://arxiv.org/abs/2307.13868},
	abstract = {Causal inference studies whether the presence of a variable influences an observed outcome. 
	As measured by quantities such as the "average treatment effect," this paradigm is employed across numerous biological fields, 
	from vaccine and drug development to policy interventions. Unfortunately, the majority of these methods are often limited 
	to univariate outcomes. Our work generalizes causal estimands to outcomes with any number of dimensions or any measurable 
	space, and formulates traditional causal estimands for nominal variables as causal discrepancy tests. We propose a simple 
	technique for adjusting universally consistent conditional independence tests and prove that these tests are universally consistent 
	causal discrepancy tests. Numerical experiments illustrate that our method, Causal CDcorr, leads to improvements in both finite 
	sample validity and power when compared to existing strategies.},
	month = {1},
	journal = {arXiv},
	eprint = {arXiv}
},

@article{shenLearningInterpretableCharacteristic2020,
	title = {Learning Interpretable Characteristic Kernels via Decision Forests},
	author = {Shen, Cencheng and Panda, Sambit and Vogelstein, Joshua T.},
	author+an = {1=trainee;2=trainee;3=highlight},
	year = {2023},
	keywords = {in-review},
	url = {https://arxiv.org/abs/1812.00029},
	month = {9},
	journal = {arXiv},
	abstract = {Decision forests are widely used for classification and regression tasks. A lesser known property of tree-based methods is that one can construct a proximity matrix from the tree(s), and these proximity matrices are induced kernels. While there has been extensive research on the applications and properties of kernels, there is relatively little research on kernels induced by decision forests. We construct Kernel Mean Embedding Random Forests (KMERF), which induce kernels from random trees and/or forests using leaf-node proximity. We introduce the notion of an asymptotically characteristic kernel, and prove that KMERF kernels are asymptotically characteristic for both discrete and continuous data. Because KMERF is data-adaptive, we suspected it would outperform kernels selected a priori on finite sample data. We illustrate that KMERF nearly dominates current state-of-the-art kernel-based tests across a diverse range of high-dimensional two-sample and independence testing settings. Furthermore, our forest-based approach is interpretable, and provides feature importance metrics that readily distinguish important dimensions, unlike other high-dimensional non-parametric testing procedures. Hence, this work demonstrates the decision forest-based kernel can be more powerful and more interpretable than existing methods, flying in the face of conventional wisdom of the trade-off between the two.},
	eprint = {1812.00029},
	archiveprefix = {arXiv},
	primaryclass = {cs, stat},
	eprinttype = {arxiv},
	copyright = {All rights reserved}
},

@article{pandaNonparMANOVAIndependence2021,
	title = {Nonpar MANOVA via Independence Testing},
	author = {Panda, Sambit and Shen, Cencheng and Perry, Ronan and Zorn, Jelle and Lutz, Antoine and Priebe, Carey E. and Vogelstein, Joshua T.},
	year = {2021},
	author+an = {1=trainee;2=trainee;3=trainee;7=highlight},
	keywords = {in-review},
	url = {https://arxiv.org/abs/1910.08883},
	month = {4},
	journal = {arXiv},
	abstract = {The k-sample testing problem tests whether or not k groups of data points are sampled from the same distribution. Multivariate analysis of variance (MANOVA) is currently the gold standard for k-sample testing but makes strong, often inappropriate, parametric assumptions. Moreover, independence testing and k-sample testing are tightly related, and there are many nonparametric multivariate independence tests with strong theoretical and empirical properties, including distance correlation (Dcorr) and Hilbert-Schmidt-Independence-Criterion (Hsic). We prove that universally consistent independence tests achieve universally consistent k-sample testing and that k-sample statistics like Energy and Maximum Mean Discrepancy (MMD) are exactly equivalent to Dcorr. Empirically evaluating these tests for k-sample scenarios demonstrates that these nonparametric independence tests typically outperform MANOVA, even for Gaussian distributed settings. Finally, we extend these non-parametric k-sample testing procedures to perform multiway and multilevel tests. Thus, we illustrate the existence of many theoretically motivated and empirically performant k-sample tests. A Python package with all independence and k-sample tests called hyppo is available from https://hyppo.neurodata.io/.},
	eprint = {1910.08883},
	archiveprefix = {arXiv},
	primaryclass = {cs, stat},
	eprinttype = {arxiv},
	copyright = {All rights reserved}
},

@article{lein2007genome,
	title = {Genome-wide atlas of gene expression in the adult mouse brain},
	author = {Lein, E.S. and Hawrylycz, M.J. and Ao, N. and Ayres, M. and Bensinger, A. and Bernard, A. and Boe, A.F. and Boguski, M.S. and Brockway, K.S. and Byrnes, E.J. and Others},
	year = {2006},
	keywords = {omit},
	volume = {445},
	journal = {Nature},
	doi = {10.1038/nature05453},
	isbn = {0028-0836},
	publisher = {Nature Publishing Group}
},

@article{macnamee2016astrocytic,
	title = {Astrocytic glutamate transport regulates a Drosophila CNS synapse that lacks astrocyte ensheathment},
	author = {Macnamee, Sarah E. and Liu, Kendra E. and Gerhard, Stephan and Tran, Cathy T. and Fetter, Richard D. and Cardona, Albert and Tolbert, Leslie P. and Oland, Lynne A.},
	year = {2016},
	keywords = {omit},
	volume = {524},
	journal = {Journal of Comparative Neurology},
	doi = {10.1002/cne.24016},
	isbn = {2128248981},
	abstract = {The morphology of the telencephalon displays great diversity among different vertebrate lineages. Particularly, the everted telencephalon of ray-finned fishes shows a noticeably different morphology to the evaginated telencephalon of non-ray-finned fishes and other vertebrates. This makes the comparison between the different parts of the telencephalon of ray-finned fishes and other vertebrates difficult. Based on neuroanatomical, neurochemical and connectional data no consensus on the subdivisions of the adult telencephalon of ray-finned fishes and their relation to nuclei in the telencephalon of other vertebrates has been reached yet. For tetrapods, comparative expression pattern analysis of homologous developmental genes has been a successful approach to clarify homologies between different parts of the telencephalon. In the larval zebrafish, subdivisions of the subpallium have been proposed using conserved developmental genes expression. In this study, we investigate the subdivisions of the adult zebrafish telencephalon by analyzing the expression pattern of conserved molecular marker genes. We identify the boundary between the pallium and subpallium based on the complementary expression of dlx2a, dlx5a in the subpallium and tbr1, neurod in the pallium. Furthermore, combinatorial expression of Isl, nkx2.1b, lhx1b, tbr1, eomesa, emx1, emx2 and emx3 identifies striatal-like, pallidal-like and septal-like subdivisions within the subpallium. In contrast to previous models, we propose that the striatum and pallidum are stretched along the rostro-caudal axis of the telencephalon. Further, the septal nuclei derive from both the pallium and subpallium. On this basis, we present a new model for the subdivisions of the subpallium in teleost fish.},
	issn = {10969861},
	publisher = {Wiley Online Library},
	pmid = {21858823}
},

@unpublished{Mouse2017,
	title = {Allen Mouse Common Coordinate Framework ALLEN MOUSE COMMON COORDINATE FRAMEWORK AND REFERENCE ATLAS},
	author = {Science, Allen I. F. B.},
	year = {2017},
	keywords = {omit},
	url = {http://help.brain-map.org/download/attachments/8323525/Mouse_Common_Coordinate_Framework.pdf?version=3 modificationDate=1508178848279 api=v2},
	journal = {Technical White Paper}
},

@article{schlegel2016synaptic,
	title = {Synaptic transmission parallels neuromodulation in a central food-intake circuit},
	author = {Schlegel, Philipp and Texada, Michael J. and Miroschnikow, Anton and Schoofs, Andreas and Hückesfeld, Sebastian and Peters, Marc and Schneider-Mizell, Casey M. and Lacin, Haluk and Li, Feng and Fetter, Richard D. and Truman, James W. and Cardona, Albert and Pankratz, Michael J.},
	year = {2016},
	keywords = {omit},
	volume = {5},
	journal = {eLife},
	doi = {10.7554/eLife.16799.001},
	isbn = {2050-084X (Electronic)2050-084X (Linking)},
	abstract = {<p>NeuromedinU is a potent regulator of food intake and activity in mammals. In Drosophila, neurons producing the homologous neuropeptide hugin regulate feeding and locomotion in a similar manner. Here, we use EM-based reconstruction to generate the entire connectome of hugin-producing neurons in the Drosophila larval CNS. We demonstrate that hugin neurons use synaptic transmission in addition to peptidergic neuromodulation and identify acetylcholine as a key transmitter. Hugin neuropeptide and acetylcholine are both necessary for the regulatory effect on feeding. We further show that subtypes of hugin neurons connect chemosensory to endocrine system by combinations of synaptic and peptide-receptor connections. Targets include endocrine neurons producing DH44, a CRH-like peptide, and insulin-like peptides. Homologs of these peptides are likewise downstream of neuromedinU, revealing striking parallels in flies and mammals. We propose that hugin neurons are part of an ancient physiological control system that has been conserved at functional and molecular level.</p>},
	issn = {2050084X},
	publisher = {eLife Sciences Publications, Ltd},
	pmid = {27845623}
},

@article{fushiki2016circuit,
	title = {A circuit mechanism for the propagation of waves of muscle contraction in Drosophila},
	author = {Fushiki, Akira and Zwart, Maarten F. and Kohsaka, Hiroshi and Fetter, Richard D. and Cardona, Albert and Nose, Akinao},
	year = {2016},
	keywords = {omit},
	volume = {5},
	journal = {eLife},
	doi = {10.7554/eLife.13253},
	isbn = {2050-084x},
	abstract = {Animals move by adaptively coordinating the sequential activation of muscles. The circuit mechanisms underlying coordinated locomotion are poorly understood. Here, we report on a novel circuit for propagation of waves of muscle contraction, using the peristaltic locomotion of Drosophila larvae as a model system. We found an intersegmental chain of synaptically connected neurons, alternating excitatory and inhibitory, necessary for wave propagation and active in phase with the wave. The excitatory neurons (A27h) are premotor and necessary only for forward locomotion, and are modulated by stretch receptors and descending inputs. The inhibitory neurons (GDL) are necessary for both forward and backward locomotion, suggestive of different yet coupled central pattern generators, and its inhibition is necessary for wave propagation. The circuit structure and functional imaging indicated that the commands to contract one segment promote the relaxation of the next segment, revealing a mechanism for wave propagation in peristaltic locomotion.},
	issn = {2050084X},
	publisher = {eLife Sciences Publications, Ltd},
	pmid = {26880545}
},

@article{berck2016wiring,
	title = {The wiring diagram of a glomerular olfactory system},
	author = {Berck, Matthew E. and Khandelwal, Avinash and Claus, Lindsey and Hernandez-Nunez, Luis and Si, Guangwei and Tabone, Christopher J. and Li, Feng and Truman, James W. and Fetter, Rick D. and Louis, Matthieu and Samuel, Aravinthan D.T. and Cardona, Albert},
	year = {2016},
	keywords = {omit},
	volume = {5},
	journal = {eLife},
	doi = {10.7554/eLife.14859},
	isbn = {2050-084X (Electronic)2050-084X (Linking)},
	abstract = {The sense of smell enables animals to react to long-distance cues according to learned and innate valences. Here, we have mapped with electron microscopy the complete wiring diagram of the Drosophila larval antennal lobe, an olfactory neuropil similar to the vertebrate olfactory bulb. We found a canonical circuit with uniglomerular projection neurons (uPNs) relaying gain-controlled ORN activity to the mushroom body and the lateral horn. A second, parallel circuit with multiglomerular projection neurons (mPNs) and hierarchically connected local neurons (LNs) selectively integrates multiple ORN signals already at the first synapse. LN-LN synaptic connections putatively implement a bistable gain control mechanism that either computes odor saliency through panglomerular inhibition, or allows some glomeruli to respond to faint aversive odors in the presence of strong appetitive odors. This complete wiring diagram will support experimental and theoretical studies towards bridging the gap between circuits and behavior.},
	issn = {2050084X},
	publisher = {eLife Sciences Publications, Ltd},
	pmid = {27177418}
},

@inproceedings{kreshuk2015talking,
	title = {Who is talking to whom: Synaptic partner detection in anisotropic volumes of insect brain},
	author = {Kreshuk, Anna and Funke, Jan and Cardona, Albert and Hamprecht, Fred A.},
	year = {2015},
	keywords = {omit},
	volume = {9349},
	booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	doi = {10.1007/978-3-319-24553-9_81},
	isbn = {978-3-319-24552-2},
	issn = {16113349},
	organization = {Springer}
},

@misc{Jones2009,
	title = {The Allen Brain Atlas: 5 years and beyond.},
	author = {Jones, Allan R. and Overly, Caroline C. and Sunkin, Susan M.},
	year = {2009},
	keywords = {omit},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/19826436},
	volume = {10},
	booktitle = {Nature Reviews Neuroscience},
	doi = {10.1038/nrn2722},
	isbn = {1471-0048 (Electronic)1̊471-003X (Linking)},
	abstract = {The Allen Brain Atlas, a Web-based, genome-wide atlas of gene expression in the adult mouse brain, was an experiment on a massive scale. The development of the atlas faced a combination of great technical challenges and a non-traditional open research model, and it encountered many hurdles on the path to completion and community adoption. Having overcome these challenges, it is now a fundamental tool for neuroscientists worldwide and has set the stage for the creation of other similar open resources. Nevertheless, there are many untapped opportunities for exploration.},
	issn = {1471003X},
	pmid = {19826436}
},

@article{bumbarger2013system,
	title = {System-wide rewiring underlies behavioral differences in predatory and bacterial-feeding nematodes},
	author = {Bumbarger, Daniel J. and Riebesell, Metta and Rödelsperger, Christian and Sommer, Ralf J.},
	year = {2013},
	keywords = {omit},
	volume = {152},
	journal = {Cell},
	doi = {10.1016/j.cell.2012.12.013},
	isbn = {0092-8674},
	abstract = {The relationship between neural circuit function and patterns of synaptic connectivity is poorly understood, in part due to a lack of comparative data for larger complete systems. We compare system-wide maps of synaptic connectivity generated from serial transmission electron microscopy for the pharyngeal nervous systems of two nematodes with divergent feeding behavior: the microbivore Caenorhabditis elegans and the predatory nematode Pristionchus pacificus. We uncover a massive rewiring in a complex system of identified neurons, all of which are homologous based on neurite anatomy and cell body position. Comparative graph theoretical analysis reveals a striking pattern of neuronal wiring with increased connectional complexity in the anterior pharynx correlating with tooth-like denticles, a morphological feature in the mouth of P. pacificus. We apply focused centrality methods to identify neurons I1 and I2 as candidates for regulating predatory feeding and predict substantial divergence in the function of pharyngeal glands. © 2013 Elsevier Inc.},
	issn = {00928674},
	publisher = {Elsevier},
	pmid = {23332749}
},

@article{bloss2016structured,
	title = {Structured Dendritic Inhibition Supports Branch-Selective Integration in CA1 Pyramidal Cells},
	author = {Bloss, Erik B and Cembrowski, Mark S and Karsh, Bill and Colonell, Jennifer and Fetter, Richard D and Spruston, Nelson and Bloss, Erik B and Cembrowski, Mark S and Karsh, Bill and Colonell, Jennifer and Fetter, Richard D and Spruston, Nelson},
	year = {2016},
	keywords = {omit},
	url = {http://dx.doi.org/10.1016/j.neuron.2016.01.029},
	volume = {89},
	journal = {Neuron},
	doi = {10.1016/j.neuron.2016.01.029},
	abstract = {Neuronal circuit function is governed by precise patterns of connectivity between specialized groups of neurons. The diversity of GABAergic interneurons is a hallmark of cortical circuits, yet little is known about their targeting to individual postsynaptic dendrites. We examined synaptic connectivity between molecularly defined inhibitory interneurons and CA1 pyramidal cell dendrites using correlative light-electron microscopy and large-volume array tomography. We show that interneurons can be highly selective in their connectivity to specific dendritic branch types and, furthermore, exhibit precisely targeted connectivity to the origin or end of individual branches. Computational simulations indicate that the observed subcellular targeting enables control over the nonlinear integration of synaptic input or the initiation and backpropagation of action potentials in a branch-selective manner. Our results demonstrate that connectivity between interneurons and pyramidal cell dendrites is more precise and spatially segregated than previously appreciated, which may be a critical determinant of how inhibition shapes dendritic computation.},
	issn = {0896-6273},
	publisher = {Elsevier},
	pmid = {26898780}
},

@article{bloss2018single,
	title = {Single excitatory axons form clustered synapses onto CA1 pyramidal cell dendrites},
	author = {Bloss, Erik B. and Cembrowski, Mark S. and Karsh, Bill and Colonell, Jennifer and Fetter, Richard D. and Spruston, Nelson},
	year = {2018},
	keywords = {omit},
	volume = {21},
	journal = {Nature Neuroscience},
	doi = {10.1038/s41593-018-0084-6},
	isbn = {4159301800},
	abstract = {CA1 pyramidal neurons are a major output of the hippocampus and encode features of experience that constitute episodic memories. Feature-selective firing of these neurons results from the dendritic integration of inputs from multiple brain regions. While it is known that synchronous activation of spatially clustered inputs can contribute to firing through the generation of dendritic spikes, there is no established mechanism for spatiotemporal synaptic clustering. Here we show that single presynaptic axons form multiple, spatially clustered inputs onto the distal, but not proximal, dendrites of CA1 pyramidal neurons. These compound connections exhibit ultrastructural features indicative of strong synapses and occur much more commonly in entorhinal than in thalamic afferents. Computational simulations revealed that compound connections depolarize dendrites in a biophysically efficient manner, owing to their inherent spatiotemporal clustering. Our results suggest that distinct afferent projections use different connectivity motifs that differentially contribute to dendritic integration.},
	issn = {15461726},
	publisher = {Nature Publishing Group},
	pmid = {29459763}
},

@article{jovanic2016competitive,
	title = {Competitive Disinhibition Mediates Behavioral Choice and Sequences in Drosophila},
	author = {Jovanic, Tihana and Schneider-Mizell, Casey Martin and Shao, Mei and Masson, Jean Baptiste and Denisov, Gennady and Fetter, Richard Doty and Mensh, Brett Daren and Truman, James William and Cardona, Albert and Zlatic, Marta},
	year = {2016},
	keywords = {omit},
	volume = {167},
	journal = {Cell},
	doi = {10.1016/j.cell.2016.09.009},
	isbn = {0092-8674},
	abstract = {Even a simple sensory stimulus can elicit distinct innate behaviors and sequences. During sensorimotor decisions, competitive interactions among neurons that promote distinct behaviors must ensure the selection and maintenance of one behavior, while suppressing others. The circuit implementation of these competitive interactions is still an open question. By combining comprehensive electron microscopy reconstruction of inhibitory interneuron networks, modeling, electrophysiology, and behavioral studies, we determined the circuit mechanisms that contribute to the Drosophila larval sensorimotor decision to startle, explore, or perform a sequence of the two in response to a mechanosensory stimulus. Together, these studies reveal that, early in sensory processing, (1) reciprocally connected feedforward inhibitory interneurons implement behavioral choice, (2) local feedback disinhibition provides positive feedback that consolidates and maintains the chosen behavior, and (3) lateral disinhibition promotes sequence transitions. The combination of these interconnected circuit motifs can implement both behavior selection and the serial organization of behaviors into a sequence.},
	issn = {10974172},
	publisher = {Elsevier},
	pmid = {27720450}
},

@inproceedings{kutten2016deformably,
	title = {Deformably registering and annotating whole CLARITY brains to an atlas via masked LDDMM},
	author = {Kutten, Kwame S. and Vogelstein, Joshua T. and Charon, Nicolas and Ye, Li and Deisseroth, Karl and Miller, Michael I.},
	year = {2016},
	keywords = {omit},
	url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2227444},
	volume = {9896},
	booktitle = {Optics, Photonics and Digital Technologies for Imaging Applications IV},
	doi = {10.1117/12.2227444},
	isbn = {9781510601413},
	abstract = {The CLARITY method renders brains optically transparent to enable high-resolution imaging in the structurally intact brain. Anatomically annotating CLARITY brains is necessary for discovering which regions contain signals of interest. Manually annotating whole-brain, terabyte CLARITY images is difficult, time-consuming, subjective, and error-prone. Automatically registering CLARITY images to a pre-annotated brain atlas offers a solution, but is difficult for several reasons. Removal of the brain from the skull and subsequent storage and processing cause variable non-rigid deformations, thus compounding inter-subject anatomical variability. Additionally, the signal in CLARITY images arises from various biochemical contrast agents which only sparsely label brain structures. This sparse labeling challenges the most commonly used registration algorithms that need to match image histogram statistics to the more densely labeled histological brain atlases. The standard method is a multiscale Mutual Information B-spline algorithm that dynamically generates an average template as an intermediate registration target. We determined that this method performs poorly when registering CLARITY brains to the Allen Institute's Mouse Reference Atlas (ARA), because the image histogram statistics are poorly matched. Therefore, we developed a method (Mask-LDDMM) for registering CLARITY images, that automatically find the brain boundary and learns the optimal deformation between the brain and atlas masks. Using Mask-LDDMM without an average template provided better results than the standard approach when registering CLARITY brains to the ARA. The LDDMM pipelines developed here provide a fast automated way to anatomically annotate CLARITY images. Our code is available as open source software at http://NeuroData.io.},
	issn = {1996756X},
	eprint = {1605.02060},
	organization = {International Society for Optics and Photonics}
},

@misc{nature_video_untangling_nodate,
	title = {Untangling the brain - by Nature Video},
	author = {video, nature},
	year = {2011},
	keywords = {omit},
	url = {https://www.youtube.com/watch?v=dS_ONoUrptg},
	journal = {YouTube},
	urldate = {2018-04-18}
},

@article{bock2011network,
	title = {Network anatomy and in vivo physiology of visual cortical neurons},
	author = {Bock, Davi D. and Lee, Wei Chung Allen and Kerlin, Aaron M. and Andermann, Mark L. and Hood, Greg and Wetzel, Arthur W. and Yurgenson, Sergey and Soucy, Edward R. and Kim, Hyon Suk and Reid, R. Clay},
	year = {2011},
	keywords = {omit},
	volume = {471},
	journal = {Nature},
	doi = {10.1038/nature09802},
	isbn = {1476-4687 (Electronic)0̊028-0836 (Linking)},
	abstract = {In the cerebral cortex, local circuits consist of tens of thousands of neurons, each of which makes thousands of synaptic connections. Perhaps the biggest impediment to understanding these networks is that we have no wiring diagrams of their interconnections. Even if we had a partial or complete wiring diagram, however, understanding the network would also require information about each neuron's function. Here we show that the relationship between structure and function can be studied in the cortex with a combination of in vivo physiology and network anatomy. We used two-photon calcium imaging to characterize a functional property–the preferred stimulus orientation–of a group of neurons in the mouse primary visual cortex. Large-scale electron microscopy of serial thin sections was then used to trace a portion of these neurons' local network. Consistent with a prediction from recent physiological experiments, inhibitory interneurons received convergent anatomical input from nearby excitatory neurons with a broad range of preferred orientations, although weak biases could not be rejected.},
	issn = {00280836},
	publisher = {Nature Publishing Group},
	pmid = {21390124}
},

@article{amunts2013bigbrain,
	title = {BigBrain: an ultrahigh-resolution 3D human brain model.},
	author = {Amunts, Katrin and Lepage, Claude and Borgeat, Louis and Mohlberg, Hartmut and Dickscheid, Timo and Rousseau, Marc-Étienne and Bludau, Sebastian and Bazin, Pierre-Louis and Lewis, Lindsay B and Oros-Peusquens, Ana-Maria and Shah, Nadim J and Lippert, Thomas and Zilles, Karl and Evans, Alan C},
	year = {2013},
	keywords = {omit},
	url = {http://www.sciencemag.org/content/340/6139/1472.full},
	volume = {340},
	journal = {Science (New York, NY)},
	doi = {10.1126/science.1235381},
	isbn = {1095-9203 (Electronic)0̊036-8075 (Linking)},
	abstract = {Reference brains are indispensable tools in human brain mapping, enabling integration of multimodal data into an anatomically realistic standard space. Available reference brains, however, are restricted to the macroscopic scale and do not provide information on the functionally important microscopic dimension. We created an ultrahigh-resolution three-dimensional (3D) model of a human brain at nearly cellular resolution of 20 micrometers, based on the reconstruction of 7404 histological sections. "BigBrain" is a free, publicly available tool that provides considerable neuroanatomical insight into the human brain, thereby allowing the extraction of microscopic data for modeling and simulation. BigBrain enables testing of hypotheses on optimal path lengths between interconnected cortical regions or on spatial organization of genetic patterning, redefining the traditional neuroanatomy maps such as those of Brodmann and von Economo.},
	issn = {1095-9203},
	eprint = {NIHMS150003},
	publisher = {American Association for the Advancement of Science},
	pmid = {23788795}
},

@article{bhatla2015distinct,
	title = {Distinct neural circuits control rhythm inhibition and spitting by the myogenic pharynx of C. elegans},
	author = {Bhatla, Nikhil and Droste, Rita and Sando, Steven R and Huang, Anne and Horvitz, H Robert},
	year = {2015},
	keywords = {omit},
	url = {https://doi.org/10.1016/j.cub.2015.06.052},
	volume = {25},
	number = {16},
	journal = {Current Biology},
	publisher = {Elsevier}
},

@article{ohyama2015multilevel,
	title = {A multilevel multimodal circuit enhances action selection in Drosophila},
	author = {Ohyama, Tomoko and Schneider-Mizell, Casey M. and Fetter, Richard D. and Aleman, Javier Valdes and Franconville, Romain and Rivera-Alba, Marta and Mensh, Brett D. and Branson, Kristin M. and Simpson, Julie H. and Truman, James W. and Cardona, Albert and Zlatic, Marta},
	year = {2015},
	keywords = {omit},
	volume = {520},
	journal = {Nature},
	doi = {10.1038/nature14297},
	isbn = {1476-4687 (Electronic)0̊028-0836 (Linking)},
	abstract = {Natural events present multiple types of sensory cues, each detected by a specialized sensory modality. Combining information from several modalities is essential for the selection of appropriate actions. Key to understanding multimodal computations is determining the structural patterns of multimodal convergence and how these patterns contribute to behaviour. Modalities could converge early, late or at multiple levels in the sensory processing hierarchy. Here we show that combining mechanosensory and nociceptive cues synergistically enhances the selection of the fastest mode of escape locomotion in Drosophila larvae. In an electron microscopy volume that spans the entire insect nervous system, we reconstructed the multisensory circuit supporting the synergy, spanning multiple levels of the sensory processing hierarchy. The wiring diagram revealed a complex multilevel multimodal convergence architecture. Using behavioural and physiological studies, we identified functionally connected circuit nodes that trigger the fastest locomotor mode, and others that facilitate it, and we provide evidence that multiple levels of multimodal integration contribute to escape mode selection. We propose that the multilevel multimodal convergence architecture may be a general feature of multisensory circuits enabling complex input-output functions and selective tuning to ecologically relevant combinations of cues.},
	issn = {14764687},
	publisher = {Nature Publishing Group},
	pmid = {25896325}
},

@article{zwart2016selective,
	title = {Selective inhibition mediates the sequential recruitment of motor pools},
	author = {Zwart, Maarten F and Pulver, Stefan R and Truman, James W and Fushiki, Akira and Fetter, Richard D and Cardona, Albert and Landgraf, Matthias},
	year = {2016},
	keywords = {omit},
	volume = {91},
	number = {3},
	journal = {Neuron},
	doi = {10.1016/j.neuron.2016.06.031},
	publisher = {Elsevier}
},

@article{jarrell2012connectome,
	title = {The Connectome of a Decision-Making Neural Network},
	author = {Jarrell, Travis A. and Wang, Y. Yi and Bloniarz, Adam E. and Brittin, Christopher A. and Xu, Meng and Thomson, J. Nichol and Albertson, Donna G. and Hall, David H. and Emmons, Scott W.},
	year = {2012},
	keywords = {omit},
	url = {http://www.sciencemag.org/content/337/6093/437.abstract},
	volume = {in press},
	journal = {Science},
	doi = {10.1126/science.1221762},
	issn = {0036-8075},
	publisher = {American Association for the Advancement of Science}
},

@article{simhal2018computational,
	title = {A Computational Synaptic Antibody Characterization and Screening Framework for Array Tomography},
	author = {Simhal, Anish K and Gong, Belvin and Trimmer, James S. and Weinberg, Richard J. and Smith, Stephen J. and Sapiro, Guillermo and Micheva, Kristina D.},
	year = {2018},
	keywords = {omit},
	url = {https://www.biorxiv.org/content/early/2018/03/14/258756},
	journal = {bioRxiv},
	doi = {10.1101/258756},
	abstract = {Application-specific validation of antibodies is a critical prerequisite for their successful use. Here we introduce an automated framework for characterization and screening of antibodies against synaptic molecules for high-resolution immunofluorescence array tomography (AT). The proposed Synaptic Antibody Screening Tool (SACT), is designed to provide an automatic, robust, flexible, and efficient tool for antibody characterization at scale. By allowing the user to define the molecular composition and size of synapses expected to contain the antigen, the method detects and characterizes puncta and synapses, and outputs automatically computed characteristics such as synapse density and target specificity ratio, which reflect the sensitivity and specificity of immunolabeling with a given antibody. These measurements provide an objective way to characterize and compare the performance of different antibodies against the same target, and can be used to objectively select the antibodies best suited for AT and potentially for other immunolabeling applications.},
	publisher = {Cold Spring Harbor Laboratory}
},

@article{takemura2013visual,
	title = {A visual motion detection circuit suggested by <i>Drosophila</i> connectomics},
	author = {Takemura, Shin-ya and Bharioke, Arjun and Lu, Zhiyuan and Nern, Aljoscha and Vitaladevuni, Shiv and Rivlin, Patricia K and Katz, William T and Olbris, Donald J and Plaza, Stephen M and Winston, Philip and Zhao, Ting and Horne, Jane Anne and Fetter, Richard D and Takemura, Satoko and Blazek, Katerina and Chang, Lei-Ann and Ogundeyi, Omotara and Saunders, Mathew a and Shapiro, Victor and Sigmund, Christopher and Rubin, Gerald M and Scheffer, Louis K and Meinertzhagen, Ian a and Chklovskii, Dmitri B},
	year = {2013},
	keywords = {omit},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/23925240},
	volume = {500},
	journal = {Nature},
	doi = {10.1038/nature12450},
	isbn = {1476-4687 (Electronic)0̊028-0836 (Linking)},
	abstract = {Animal behaviour arises from computations in neuronal circuits, but our understanding of these computations has been frustrated by the lack of detailed synaptic connection maps, or connectomes. For example, despite intensive investigations over half a century, the neuronal implementation of local motion detection in the insect visual system remains elusive. Here we develop a semi-automated pipeline using electron microscopy to reconstruct a connectome, containing 379 neurons and 8,637 chemical synaptic contacts, within the Drosophila optic medulla. By matching reconstructed neurons to examples from light microscopy, we assigned neurons to cell types and assembled a connectome of the repeating module of the medulla. Within this module, we identified cell types constituting a motion detection circuit, and showed that the connections onto individual motion-sensitive neurons in this circuit were consistent with their direction selectivity. Our results identify cellular targets for future functional investigations, and demonstrate that connectomes can provide key insights into neuronal computations.},
	issn = {0028-0836},
	eprint = {9809069v1},
	publisher = {Nature Publishing Group},
	pmid = {23925240},
	primaryclass = {arXiv}
},

@article{ounkomol2018label,
	title = {Label-free prediction of three-dimensional fluorescence images from transmitted light microscopy},
	author = {Ounkomol, Chawin and Seshamani, Sharmishtaa and Maleckar, Mary M and Collman, Forrest},
	year = {2018},
	keywords = {omit},
	journal = {bioRxiv},
	doi = {10.1101/289504},
	publisher = {Cold Spring Harbor Laboratory}
},

@article{tobin2017wiring,
	title = {Wiring variations that enable and constrain neural computation in a sensory microcircuit},
	author = {Tobin, William F. and Wilson, Rachel I. and Lee, Wei Chung Allen},
	year = {2017},
	keywords = {omit},
	volume = {6},
	journal = {eLife},
	doi = {10.7554/eLife.24838},
	abstract = {Neural network function can be shaped by varying the strength of synaptic connections. One way to achieve this is to vary connection structure. To investigate how structural variation among synaptic connections might affect neural computation, we examined primary afferent connections in the Drosophila olfactory system. We used large-scale serial section electron microscopy to reconstruct all the olfactory receptor neuron (ORN) axons that target a left-right pair of glomeruli, as well as all the projection neurons (PNs) postsynaptic to these ORNs. We found three variations in ORN→PN connectivity. First, we found a systematic co-variation in synapse number and PN dendrite size, suggesting total synaptic conductance is tuned to postsynaptic excitability. Second, we discovered that PNs receive more synapses from ipsilateral than contralateral ORNs, providing a structural basis for odor lateralization behavior. Finally, we found evidence of imprecision in ORN→PN connections that can diminish network performance.},
	issn = {2050084X},
	publisher = {eLife Sciences Publications, Ltd},
	pmid = {28530904}
},

@article{vladimirov2014light,
	title = {Light-sheet functional imaging in fictively behaving zebrafish},
	author = {Vladimirov, Nikita and Mu, Yu and Kawashima, Takashi and Bennett, Davis V. and Yang, Chao Tsung and Looger, Loren L. and Keller, Philipp J. and Freeman, Jeremy and Ahrens, Misha B.},
	year = {2014},
	keywords = {omit},
	volume = {11},
	journal = {Nature Methods},
	doi = {10.1038/nmeth.3040},
	isbn = {1548-7091},
	abstract = {Nature Methods, (2014). doi:10.1038/nmeth.3040},
	issn = {15487105},
	publisher = {Nature Publishing Group},
	pmid = {25068735}
},

@article{randlett2015whole,
	title = {Whole-brain activity mapping onto a zebrafish brain atlas},
	author = {Randlett, Owen and Wee, Caroline L. and Naumann, Eva A. and Nnaemeka, Onyeka and Schoppik, David and Fitzgerald, James E. and Portugues, Ruben and Lacoste, Alix M.B. and Riegler, Clemens and Engert, Florian and Schier, Alexander F.},
	year = {2015},
	keywords = {omit},
	volume = {12},
	journal = {Nature Methods},
	doi = {10.1038/nmeth.3581},
	isbn = {1548-70911̊548-7105},
	abstract = {In order to localize the neural circuits involved in generating behaviors, it is necessary to assign activity onto anatomical maps of the nervous system. Using brain registration across hundreds of larval zebrafish, we have built an expandable open-source atlas containing molecular labels and definitions of anatomical regions, the Z-Brain. Using this platform and immunohistochemical detection of phosphorylated extracellular signal-regulated kinase (ERK) as a readout of neural activity, we have developed a system to create and contextualize whole-brain maps of stimulus- and behavior-dependent neural activity. This mitogen-activated protein kinase (MAP)-mapping assay is technically simple, and data analysis is completely automated. Because MAP-mapping is performed on freely swimming fish, it is applicable to studies of nearly any stimulus or behavior. Here we demonstrate our high-throughput approach using pharmacological, visual and noxious stimuli, as well as hunting and feeding. The resultant maps outline hundreds of areas associated with behaviors.},
	issn = {15487105},
	eprint = {15334406},
	publisher = {Nature Publishing Group},
	pmid = {26778924}
},

@article{freeman2014mapping,
	title = {Mapping brain activity at scale with cluster computing},
	author = {J, Freeman and N, Vladimirov and T, Kawashima and Y, Mu and NJ, Sofroniew and DV, Bennett and J, Rosen and CT, Yang and LL, Looger and MB, Ahrens},
	year = {2014},
	keywords = {omit},
	volume = {11},
	journal = {Nature methods},
	doi = {10.1038/nmeth.3041},
	abstract = {Understanding brain function requires monitoring and interpreting the activity of large networks of neurons during behavior. Advances in recording technology are greatly increasing the size and complexity of neural data. Analyzing such data will pose a fundamental bottleneck for neuroscience. We present a library of analytical tools called Thunder built on the open-source Apache Spark platform for large-scale distributed computing. The library implements a variety of univariate and multivariate analyses with a modular, extendable structure well-suited to interactive exploration and analysis development. We demonstrate how these analyses find structure in large-scale neural data, including whole-brain light-sheet imaging data from fictively behaving larval zebrafish, and two-photon imaging data from behaving mouse. The analyses relate neuronal responses to sensory input and behavior, run in minutes or less and can be used on a private cluster or in the cloud. Our open-source framework thus holds promise for turning brain activity mapping efforts into biological insights.},
	publisher = {Nature Publishing Group},
	pmid = {25068736}
},

@article{francca2017energy,
	title = {Energy Clustering},
	author = {França, Guilherme and Vogelstein, Joshua T.},
	author+an = {1=trainee;2=highlight},
	year = {2017},
	keywords = {omit},
	url = {http://arxiv.org/abs/1710.09859},
	journal = {arXiv},
	abstract = {Energy statistics was proposed by Székely in the 80's inspired by the Newtonian gravitational potential from classical mechanics, and it provides a hypothesis test for equality of distributions. It was further generalized from Euclidean spaces to metric spaces of strong negative type, and more recently, a connection with reproducing kernel Hilbert spaces (RKHS) was established. Here we consider the clustering problem from an energy statistics theory perspective, providing a precise mathematical formulation yielding a quadratically constrained quadratic program (QCQP) in the associated RKHS, thus establishing the connection with kernel methods. We show that this QCQP is equivalent to kernel k-means optimization problem once the kernel is fixed. These results imply a first principles derivation of kernel k-means from energy statistics. However, energy statistics fixes a family of standard kernels. Furthermore, we also consider a weighted version of energy statistics, making connection to graph partitioning problems. To find local optimizers of such QCQP we propose an iterative algorithm based on Hartigan's method, which in this case has the same computational cost as kernel k-means algorithm, based on Lloyd's heuristic, but usually with better clustering quality. We provide carefully designed numerical experiments showing the superiority of the proposed method compared to kernel k-means, spectral clustering, standard k-means, and Gaussian mixture models in a variety of settings.},
	eprint = {1710.09859}
},

@article{lee2016anatomy,
	title = {Anatomy and function of an excitatory network in the visual cortex},
	author = {Lee, Wei-Chung Allen and Bonin, Vincent and Reed, Michael and Graham, Brett J and Hood, Greg and Glattfelder, Katie and Reid, R Clay},
	year = {2016},
	keywords = {omit},
	volume = {532},
	journal = {Nature},
	doi = {10.1038/nature17192},
	publisher = {Nature Publishing Group}
},

@article{wanner2016dense,
	title = {Dense EM-based reconstruction of the interglomerular projectome in the zebrafish olfactory bulb},
	author = {Wanner, Adrian A. and Genoud, Christel and Masudi, Tafheem and Siksou, L. and Friedrich, Rainer W.},
	year = {2016},
	keywords = {omit},
	volume = {19},
	journal = {Nature Neuroscience},
	doi = {10.1038/nn.4290},
	isbn = {1546-1726 (Electronic)1̊097-6256 (Linking)},
	abstract = {The dense reconstruction of neuronal circuits from volumetric electron microscopy (EM) data has the potential to uncover fundamental structure-function relationships in the brain. To address bottlenecks in the workflow of this emerging methodology, we developed a procedure for conductive sample embedding and a pipeline for neuron reconstruction. We reconstructed ∼98},
	issn = {15461726},
	publisher = {Nature Publishing Group},
	pmid = {27089019}
},

@article{collman2015mapping,
	title = {Mapping Synapses by Conjugate Light-Electron Array Tomography},
	author = {Collman, F. and Buchanan, J. and Phend, K. D. and Micheva, K. D. and Weinberg, R. J. and Smith, S. J.},
	year = {2015},
	keywords = {omit},
	url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.4274-14.2015},
	volume = {35},
	journal = {Journal of Neuroscience},
	doi = {10.1523/JNEUROSCI.4274-14.2015},
	isbn = {1529-2401 (Electronic)0̊270-6474 (Linking)},
	abstract = {Synapses of the mammalian CNS are diverse in size, structure, molecular composition, and function. Synapses in their myriad variations are fundamental to neural circuit development, homeostasis, plasticity, and memory storage. Unfortunately, quantitative analysis and mapping of the brain's heterogeneous synapse populations has been limited by the lack of adequate single-synapse measurement methods. Electron microscopy (EM) is the definitive means to recognize and measure individual synaptic contacts, but EM has only limited abilities to measure the molecular composition of synapses. This report describes conjugate array tomography (AT), a volumetric imaging method that integrates immunofluorescence and EM imaging modalities in voxel-conjugate fashion. We illustrate the use of conjugate AT to advance the proteometric measurement of EM-validated single-synapse analysis in a study of mouse cortex.},
	issn = {0270-6474},
	publisher = {Soc Neuroscience},
	pmid = {25855189}
},

@article{ye2016wiring,
	title = {Wiring and molecular features of prefrontal ensembles representing distinct experiences},
	author = {Ye, Li and Allen, William E and Thompson, Kimberly R and Tian, Qiyuan and Hsueh, Brian and Ramakrishnan, Charu and Wang, Ai-Chi and Jennings, Joshua H and Adhikari, Avishek and Halpern, Casey H and others},
	year = {2016},
	keywords = {omit},
	url = {https://www.sciencedirect.com/science/article/pii/S009286741630558X},
	journal = {Cell},
	publisher = {Elsevier}
},

@article{chung2013structural,
	title = {Structural and molecular interrogation of intact biological systems},
	author = {Chung, Kwanghun and Wallace, Jenelle and Kim, Sung-Yon and Kalyanasundaram, Sandhiya and Andalman, Aaron S and Davidson, Thomas J and Mirzabekov, Julie J and Zalocusky, Kelly A and Mattis, Joanna and Denisin, Aleksandra K and others},
	year = {2013},
	keywords = {omit},
	url = {https://www.nature.com/articles/nature12107},
	journal = {Nature},
	publisher = {Nature Publishing Group}
},

@article{chung2013clarity,
	title = {CLARITY for mapping the nervous system},
	author = {Chung, Kwanghun and Deisseroth, Karl},
	year = {2013},
	keywords = {omit},
	url = {https://www.nature.com/articles/nmeth.2481},
	month = {5},
	journal = {Nature methods},
	publisher = {Nature Publishing Group}
},

@article{kleissas2017block,
	title = {The Block Object Storage Service (bossDB): A Cloud-Native Approach for Petascale Neuroscience Discovery},
	author = {Kleissas, Dean and Hider, Robert and Pryor, Derek and Gion, Timothy and Manavalan, Priya and Matelsky, Jordan and Baden, Alex and Lillaney, Kunal and Burns, Randal and D’Angelo, Denise and Gray Roncal, William and Wester, Brock},
	year = {2017},
	keywords = {omit},
	url = {https://www.biorxiv.org/content/early/2017/11/10/217745},
	journal = {bioRxiv},
	doi = {10.1101/217745},
	abstract = {Large volumetric neuroimaging datasets have grown in size over the past ten years from gigabytes to terabytes, with petascale data becoming available and more common over the next few years. Current approaches to store and analyze these emerging datasets are insufficient in their ability to scale in both cost-effectiveness and performance. Additionally, enabling large-scale processing and annotation is critical as these data grow too large for manual inspection. We propose a new cloud-native managed service for large and multi-modal experiments, providing support for data ingest, storage, visualization, and sharing through a RESTful Application Programming Interface (API) and web-based user interface. Our project is open source and can be easily and cost-effectively used for a variety of modalities and applications.},
	publisher = {Cold Spring Harbor Laboratory}
},

@article{templier2019magc,
	title = {MagC, magnetic collection of ultrathin sections for volumetric correlative light and electron microscopy},
	author = {Templier, Templier and Thomas, Thomas},
	year = {2019},
	keywords = {omit},
	url = {https://elifesciences.org/articles/45696},
	month = {7},
	volume = {8},
	journal = {eLife},
	doi = {10.7554/eLife.45696},
	abstract = {The non-destructive collection of ultrathin sections onto silicon wafers for post-embedding staining and volumetric correlative light and electron microscopy traditionally requires exquisite manual skills and is tedious and unreliable. In MagC introduced here, sample blocks are augmented with a magnetic resin enabling remote actuation and collection of hundreds of sections on wafer. MagC allowed the correlative visualization of neuroanatomical tracers within their ultrastructural volumetric electron microscopy context.}
},

@article{wanner20163,
	title = {3-dimensional electron microscopic imaging of the zebrafish olfactory bulb and dense reconstruction of neurons},
	author = {Wanner, Adrian A and Genoud, Christel and Friedrich, Rainer W},
	year = {2016},
	keywords = {omit},
	volume = {3},
	journal = {Scientific data},
	doi = {10.1038/sdata.2016.100},
	publisher = {Nature Publishing Group}
},

@article{burette2015knowing,
	title = {Knowing a synapse when you see one},
	author = {Burette, Alain and Collman, Forrest and Micheva, Kristina D. and Smith, Stephen J. and Weinberg, Richard J.},
	year = {2015},
	keywords = {omit},
	url = {http://journal.frontiersin.org/Article/10.3389/fnana.2015.00100/abstract},
	volume = {9},
	journal = {Frontiers in Neuroanatomy},
	doi = {10.3389/fnana.2015.00100},
	isbn = {1662-5129 (Electronic) 1662-5129 (Linking)},
	abstract = {Recent years have seen a rapidly growing recognition of the complexity and diversity of the myriad individual synaptic connections that define brain synaptic networks. It has also become increasingly apparent that the synapses themselves are a major key to understanding the development, function and adaptability of those synaptic networks. In spite of this growing appreciation, the molecular, structural and functional characteristics of individual synapses and the patterning of their diverse characteristics across functional networks have largely eluded quantitative study with available imaging technologies. Here we offer an overview of new computational imaging methods that promise to bring single-synapse analysis of synaptic networks to the fore. We focus especially on the challenges and opportunities associated with quantitative detection of individual synapses and with measuring individual synapses across network scale populations in mammalian brain.},
	issn = {1662-5129},
	publisher = {Frontiers},
	pmid = {26283929}
},

@misc{BrainWorkshop,
	title = {A New Age of Computing and the Brain: Report of the CCC Brain Workshop},
	author = {Golland, Polina and Gallant, Jack and Hager, Greg and Pfister, Hanspeter and Papadimitriou, Christos and Schaal, Stefan and Vogelstein, Joshua T},
	author+an = {7=highlight},
	year = {2014},
	keywords = {other},
	url = {https://dl.acm.org/citation.cfm?id=2837681},
	booktitle = {CCC Brain Workshop},
	publisher = {National Science Foundation}
},

@article{Vogelstein1999,
	title = {NIH Grant Application Testing the effects of genetic variations using MINIME technology},
	author = {Vogelstein, J. T. and Vogelstein, Jacob V. and Vogelstein, Bert},
	author+an = {1=highlight},
	year = {1999},
	keywords = {other},
	url = {http://www.sciencemag.org/cgi/doi/10.1126/science.286.5448.2300},
	month = {12},
	volume = {286},
	pages = {2300–2301},
	number = {5448},
	journal = {Science},
	doi = {10.1126/science.286.5448.2300},
	abstract = {Earlier this year Science asked readers to imagine what life would be like in the year 2050. In Part III of a 4-part series we present the third installment of these fictional essays.},
	issn = {00368075},
	publisher = {American Association for the Advancement of Science}
},

@article{eccv2022workshop,
	title = {The Value of Out-of-Distribution Data},
	author = {Ashwin De Silva and Rahul Ramesh and Carey E. Priebe and Pratik Chaudhari and Joshua T. Vogelstein},
	author+an = {1=trainee;5=highlight},
	year = {2022},
	keywords = {other},
	url = {https://www.cis.jhu.edu/ parky/CEP-Publications/OOD.pdf},
	booktitle = {Workshop on Out-of-Distribution Generalization in Computer Vision, European Conference on Computer Vision},
	tag = {Best Short Paper Award}
},

@article{burns2014cosmos,
	title = {From cosmos to connectomes: The evolution of data-intensive science},
	author = {Burns, Randal and Vogelstein, Joshua T. and Szalay, Alexander S.},
	author+an = {2=highlight},
	year = {2014},
	keywords = {other},
	volume = {83},
	pages = {1249–1252},
	number = {6},
	journal = {Neuron},
	doi = {10.1016/j.neuron.2014.08.045},
	isbn = {1097-4199 (Electronic)0̊896-6273 (Linking)},
	abstract = {The analysis of data requires computation: originally by hand and more recently by computers. Different models of computing are designed and optimized for different kinds of data. In data-intensive science, the scale and complexity of data exceeds the comfort zone of local data stores on scientific workstations. Thus, cloud computing emerges as the preeminent model, utilizing data centers and high-performance clusters, enabling remote users to access and query subsets of the data efficiently. We examine how data-intensive computational systems originally built for cosmology, the Sloan Digital Sky Survey (SDSS), are now being used in connectomics, at the Open Connectome Project. We list lessons learned and outline the top challenges we expect to face. Success in computational connectomics would drastically reduce the time between idea and discovery, as SDSS did in cosmology.},
	issn = {10974199},
	eprint = {1304.0542},
	publisher = {Elsevier},
	pmid = {25233306}
},

@article{Vogelstein2011c,
	title = {Q and A: What is the Open Connectome Project?},
	author = {Vogelstein, Vogelstein and T, Joshua},
	author+an = {1=highlight},
	year = {2011},
	keywords = {other},
	url = {http://neuralsystemsandcircuits.biomedcentral.com/articles/10.1186/2042-1001-1-16},
	volume = {1},
	number = {1},
	journal = {Neural Systems and Circuits},
	doi = {10.1186/2042-1001-1-16},
	isbn = {10.1186/2042-1001-1-16},
	abstract = {Although it has been over a century since neuroscientists first conjectured that networks of neurons comprise the brain, technology has limited high-throughput investigations of neural circuitry until very recently. In the last couple of decades, several experimental paradigms have arisen that are poised to finally begin studying neuroanatomy in a high-throughput fashion. In 2005, the term connectome was coined independently by Patric Hagmann and Olaf Sporns, to describe the complete set of neural connections in a brain. Interestingly, both usages seemed to be referring to using Magnetic Resonance Imaging (MRI) to study human brain networks. Shortly thereafter, Narayanan "Bobby" Kasthuri and Jeff Lichtman published an article suggesting that "connectome" should refer to connections between neurons, which one can infer using Electron Microscopy (EM) and fluorescence microscopy (e.g., brainbow animals). "Projectome", they suggested, is more appropriate for MRI based studies. Yet, the word connectome stuck, and now refers to essentially any neuroscientific investigation of the relationship between (collections of) neurons, be they functional or structural.},
	issn = {2042-1001},
	publisher = {BioMed Central Ltd},
	pmid = {22329952}
},

@MISC{Caplis2017-qk,
	title = {Glass box vs. black box},
	author = {Caplis, Jonathan and Vogelstein, Joshua T},
	author+an = {2=highlight},
	year = {2017},
	keywords = {other},
	month = {7},
	booktitle = {Pensions Investments},
	howpublished = {https://www.pionline.com/article/20170727/ONLINE/170729878/glass-box-vs-black-box}
},

@article{sfn2018chapter,
	title = {What is Connectome Coding?},
	author = {Bridgeford, Eric W and Sussman, Daniel and Lyzinski, Vince and Qin, Yichen and Park, Youngser and Caffo, Brian and Priebe, Carey E and Vogelstein, Joshua T},
	author+an = {1=trainee;8=highlight},
	year = {2018},
	keywords = {other},
	url = {https://neurodata.io/talks/sfn_2018_coursebook.pdf},
	journal = {SfN 2018 course book}
},

@article{oopsi,
	title = {Oopsi: a family of optimal optical spike inference algorithms for inferring neural connectivity from population calcium imaging},
	author = {Vogelstein, Vogelstein and T, Joshua},
	author+an = {1=highlight},
	year = {2009},
	keywords = {other},
	url = {https://www.researchgate.net/profile/Joshua_Vogelstein2/publication/45657467_OOPSI_A_family_of_optimal_optical_spike_inference_algorithms_for_inferring_neural_connectivity_from_population_calcium_imaging/links/00b7d536f73b4445c1000000.pdf},
	journal = {Learning}
},

@article{neuro2016,
	title = {To the Cloud! A Grassroots Proposal to Accelerate Brain Science Discovery},
	author = {Vogelstein, Joshua T. and Mensh, Brett and Häusser, Michael and Spruston, Nelson and Evans, Alan C. and Kording, Konrad and Amunts, Katrin and Ebell, Christoph and Muller, Jeff and Telefont, Martin and Hill, Sean and Koushika, Sandhya P. and Calì, Corrado and Valdés-Sosa, Pedro Antonio and Littlewood, Peter B. and Koch, Christof and Saalfeld, Stephan and Kepecs, Adam and Peng, Hanchuan and Halchenko, Yaroslav O. and Kiar, Gregory and Poo, Mu Ming and Poline, Jean Baptiste and Milham, Michael P. and Schaffer, Alyssa Picchini and Gidron, Rafi and Okano, Hideyuki and Calhoun, Vince D. and Chun, Miyoung and Kleissas, Dean M. and Vogelstein, R. Jacob and Perlman, Eric and Burns, Randal and Huganir, Richard and Miller, Michael I.},
	author+an = {1=highlight;21=trainee},
	year = {2016},
	keywords = {other},
	url = {http://dx.doi.org/10.1016/j.neuron.2016.10.033},
	volume = {92},
	pages = {622–627},
	number = {3},
	journal = {Neuron},
	doi = {10.1016/j.neuron.2016.10.033},
	abstract = {The revolution in neuroscientific data acquisition is creating an analysis challenge. We propose leveraging cloud-computing technologies to enable large-scale neurodata storing, exploring, analyzing, and modeling. This utility will empower scientists globally to generate and test theories of brain function and dysfunction.},
	issn = {10974199},
	publisher = {Elsevier}
},

@article{Yuste2011,
	title = {Imaging action potentials with calcium indicators},
	author = {Yuste, Rafael and MacLean, Jason and Vogelstein, Joshua and Paninski, Liam},
	author+an = {3=highlight},
	year = {2011},
	keywords = {other},
	url = {http://cshprotocols.cshlp.org/content/2011/8/pdb.prot5650.full.pdf+html},
	volume = {6},
	pages = {985–989},
	number = {8},
	journal = {Cold Spring Harbor Protocols},
	doi = {10.1101/pdb.prot5650},
	isbn = {1559-6095 (Electronic)1̊559-6095 (Linking)},
	abstract = {The understanding of neuronal circuits has been, and will continue to be, greatly advanced by the simultaneous imaging of action potentials in neuronal ensembles. This protocol describes "bulk" loading of brain slices with acetoxymethyl (AM) ester calcium indicators in order to monitor action potential activity in large populations of neurons simultaneously. The imaging of calcium influx into neurons provides an indirect, but accurate, measure of action potential generation in individual neurons. Single-cell resolution, and thus the easy identification of every active cell, is the key advantage of the technique. Copyright ?? 2009 by Cold Spring Harbor Laboratory Press.},
	issn = {15596095},
	pmid = {20150055}
},

@misc{GlobalBrain,
	title = {Grand challenges for global brain sciences},
	author = {Vogelstein, Joshua T. and Amunts, Katrin and Andreou, Andreas and Angelaki, Dora and Ascoli, Giorgio A. and Bargmann, Cori and Burns, Randal and Cali, Corrado and Chance, Frances and Church, George and Cline, Hollis and Coleman, Todd and Stephanie de La Rochefoucauld, Denk, Winfried and Elgoyhen, Ana Belén and Cummings, Ralph Etienne and Evans, Alan and Harris, Kenneth and Hausser, Michael and Hill, Sean and Inverso, Samuel and Jackson, Chad and Jain, Viren and Kass, Rob and Kasthuri, Bobby and Kepecs, Adam and Kiar, Gregory and Kording, Konrad and Koushika, Sandhya P. and Krakauer, John and Landis, Story and Layton, Jeff and Luo, Qingming and Marblestone, Adam and Markowitz, David and McArthur, Justin and Mensh, Brett and Milham, Michael P. and Mitra, Partha and Neskovic, Pedja and Nicolelis, Miguel and O'Brien, Richard and Oliva, Aude and Orban, Gergo and Peng, Hanchuan and Perlman, Eric and Picciotto, Marina and Poo, Mu-Ming and Poline, Jean-Baptiste and Pouget, Alexandre and Raghavachari, Sridhar and Roskams, Jane and Schaffer, Alyssa Picchini and Sejnowski, Terry and Sommer, Friedrich T. and Spruston, Nelson and Swanson, Larry and Toga, Arthur and Vogelstein, R. Jacob and Zador, Anthony and Huganir, Richard and Miller, Michael I.},
	author+an = {1=highlight},
	year = {2016},
	keywords = {other},
	url = {https://f1000research.com/articles/5-2873/v1},
	volume = {5},
	pages = {2873},
	booktitle = {F1000Research},
	doi = {10.12688/f1000research.10025.1},
	abstract = {The next grand challenges for science and society are in the brain sciences.  A collection of 60+ scientists from around the world, together with 15+ observers from national, private, and foundations, spent two days together discussing the top challenges that we could solve as a global community in the next decade.  We settled on three challenges, spanning anatomy, physiology, and medicine.  Addressing all three challenges requires novel computational infrastructure.  The group proposed the advent of The International Brain Station (TIBS), to address these challenges, and launch brain sciences to the next level of understanding.},
	issn = {2046-1402}
},

@article{lee2017,
	title = {Network dependence testing via diffusion maps and distance-based correlations},
	author = {Lee, Youjin and Shen, Cencheng and Priebe, Carey E and Vogelstein, Joshua T},
	author+an = {4=highlight;1=trainee;2=trainee},
	year = {2019},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1093/biomet/asz045},
	month = {9},
	journal = {Biometrika},
	doi = {10.1093/biomet/asz045},
	abstract = {Deciphering the associations between network connectivity and nodal attributes is one of the core problems in network science. The dependency structure and high dimensionality of networks pose unique challenges to traditional dependency tests in terms of theoretical guarantees and empirical performance. We propose an approach to test network dependence via diffusion maps and distance-based correlations. We prove that the new method yields a consistent test statistic under mild distributional assumptions on the graph structure, and demonstrate that it is able to efficiently identify the most informative graph embedding with respect to the diffusion time. The methodology is illustrated on both simulated and real data.},
	issn = {0006-3444},
	eprint = {1703.10136},
	archiveprefix = {arXiv},
	arxivid = {1703.10136}
},

@article{powell2021ten,
	title = {Ten Rules for Conducting Retrospective Pharmacoepidemiological Analyses: Example COVID-19 Study},
	author = {Powell, Michael and Koenecke, Allison and Byrd, James and Nishimura, Akihiko and Konig, Maximilian and Xiong, Ruoxuan and Mahmood, Sadiqa and Mucaj, Veraand Bettegowda, Chetan and Rose, Liam and Tamang, Suzanne and Sacarny, Adam and Caffo, Brian and Athey, Susan and Stuart, Elizabeth and Vogelstein, Joshua},
	author+an = {1=trainee;15=highlight},
	year = {2021},
	keywords = {peer-reviewed},
	url = {https://www.frontiersin.org/articles/10.3389/fphar.2021.700776/full},
	month = {7},
	pages = {1799},
	journal = {Frontiers in Pharmacology},
	doi = {10.3389/fphar.2021.700776},
	publisher = {Frontiers}
},

@article{Lyzinski2014a,
	title = {Graph Matching: Relax at Your Own Risk},
	author = {Lyzinski, Vince and Fishkind, Donniell E. and Fiori, Marcelo and Vogelstein, Joshua T. and Priebe, Carey E. and Sapiro, Guillermo},
	author+an = {4=highlight},
	year = {2016},
	keywords = {peer-reviewed},
	url = {http://doi.org/10.1109/TPAMI.2015.2424894},
	month = {1},
	volume = {38},
	pages = {60–73},
	number = {1},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	doi = {10.1109/TPAMI.2015.2424894},
	isbn = {1405.3133},
	abstract = {Graph matching - aligning a pair of graphs to minimize their edge disagreements - has received wide-spread attention from both theoretical and applied communities over the past several decades, including combinatorics, computer vision, and connectomics. Its attention can be partially attributed to its computational difficulty. Although many heuristics have previously been proposed in the literature to approximately solve graph matching, very few have any theoretical support for their performance. A common technique is to relax the discrete problem to a continuous problem, therefore enabling practitioners to bring gradient-descent-type algorithms to bear. We prove that an indefinite relaxation (when solved exactly) almost always discovers the optimal permutation, while a common convex relaxation almost always fails to discover the optimal permutation. These theoretical results suggest that initializing the indefinite algorithm with the convex optimum might yield improved practical performance. Indeed, experimental results illuminate and corroborate these theoretical findings, demonstrating that excellent results are achieved in both benchmark and real data problems by amalgamating the two approaches.},
	issn = {01628828},
	eprint = {1405.3133},
	archiveprefix = {arXiv},
	arxivid = {1405.3133},
	pmid = {26656578}
},

@article{Lyzinski2015,
	title = {Spectral clustering for divide-and-conquer graph matching},
	author = {Lyzinski, Vince and Sussman, Daniel L. and Fishkind, Donniell E. and Pao, Henry and Chen, Li and Vogelstein, Joshua T. and Park, Youngser and Priebe, Carey E.},
	author+an = {6=highlight},
	year = {2015},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1016/j.parco.2015.03.004},
	volume = {47},
	pages = {70–87},
	journal = {Parallel Computing},
	doi = {10.1016/j.parco.2015.03.004},
	abstract = {Abstract We present a parallelized bijective graph matching algorithm that leverages seeds and is designed to match very large graphs. Our algorithm combines spectral graph embedding with existing state-of-the-art seeded graph matching procedures. We justify our approach by proving that modestly correlated, large stochastic block model random graphs are correctly matched utilizing very few seeds through our divide-and-conquer procedure. We also demonstrate the effectiveness of our approach in matching very large graphs in simulated and real data examples, showing up to a factor of 8 improvement in runtime with minimal sacrifice in accuracy.},
	issn = {01678191},
	eprint = {1310.1297},
	archiveprefix = {arXiv},
	arxivid = {1310.1297}
},

@article{Shen201741,
	title = {Manifold matching using shortest-path distance and joint neighborhood selection},
	author = {Shen, Cencheng and Vogelstein, Joshua T. and Priebe, Carey E.},
	author+an = {1=trainee;2=highlight},
	year = {2017},
	keywords = {peer-reviewed},
	url = {http://www.sciencedirect.com/science/article/pii/S016786551730106X},
	volume = {92},
	pages = {41–48},
	journal = {Pattern Recognition Letters},
	doi = {10.1016/j.patrec.2017.04.005},
	abstract = {Matching datasets of multiple modalities has become an important task in data analysis. Existing methods often rely on the embedding and transformation of each single modality without utilizing any correspondence information, which often results in sub-optimal matching performance. In this paper, we propose a nonlinear manifold matching algorithm using shortest-path distance and joint neighborhood selection. Specifically, a joint nearest-neighbor graph is built for all modalities. Then the shortest-path distance within each modality is calculated from the joint neighborhood graph, followed by embedding into and matching in a common low-dimensional Euclidean space. Compared to existing algorithms, our approach exhibits superior performance for matching disparate datasets of multiple modalities.},
	issn = {01678655},
	eprint = {1412.4098},
	archiveprefix = {arXiv},
	arxivid = {1412.4098}
},

@article{shen2016discovering,
	title = {Discovering and deciphering relationships across disparate data modalities},
	author = {Vogelstein, Joshua T. and Bridgeford, Eric W. and Wang, Qing and Priebe, Carey E. and Maggioni, Mauro and Shen, Cencheng},
	author+an = {1=highlight;2=trainee;6=trainee},
	year = {2019},
	keywords = {peer-reviewed},
	url = {https://elifesciences.org/articles/41690},
	month = {1},
	volume = {8},
	journal = {eLife},
	doi = {10.7554/eLife.41690},
	abstract = {Understanding the relationships between different properties of data, such as whether a genome or connectome has information about disease status, is increasingly important. While existing approaches can test whether two properties are related, they may require unfeasibly large sample sizes and often are not interpretable. Our approach, 'Multiscale Graph Correlation' (MGC), is a dependence test that juxtaposes disparate data science techniques, including k-nearest neighbors, kernel methods, and multiscale analysis. Other methods may require double or triple the number of samples to achieve the same statistical power as MGC in a benchmark suite including high-dimensional and nonlinear relationships, with dimensionality ranging from 1 to 1000. Moreover, MGC uniquely characterizes the latent geometry underlying the relationship, while maintaining computational efficiency. In real data, including brain imaging and cancer genetics, MGC detects the presence of a dependency and provides guidance for the next experiments to conduct.},
	issn = {2050084X},
	eprint = {1609.05148},
	archiveprefix = {arXiv},
	arxivid = {1609.05148}
},

@article{Hartung2022baltimore,
	title = {The Baltimore Declaration toward the exploration of organoid intelligence},
	author = {Hartung, Thomas and Smirnova, Lena and Pantoja, Itzy E. M. and Akwaboah, Akwasi and Din, Dowlette-Mary A. E. and Berlinicke, Cindy and Boyd, J L. and Caffo, Brian S. and Cappiello, Ben and Cohen-Karni, Tzahi and Curley, Lowry and Etienne-Cummings, Ralph and Dastgheyb, Raha and Gracias, David H. and Gilbert, Frederic and Habela, Christa W. and Han, Fang and Harris, Tim and Herrmann, Kathrin and Hill, Eric J. and Huang, Qi and Jabbour, Rabih E. and Johnson, Erik C. and Kagan, Brett J. and Krall, Caroline and Levchenko, Andre and Locke, Paul and Maertens, Alexandra and Metea, Monica and Muotri, Alysson R. and Parri, Rheinallt and Paulhamus, Barton L. and Plotkin, Jesse D. and Roach, Paul and Romero, July C. and Schwamborn, Jens C. and Sille, Fenna and Szalay, Alexander and Tsaioun, Katya and Tornero, Daniel and Vogelstein, Joshua T. and Wahlin, Karl and Zack, Donald J.},
	author+an = {41=highlight},
	year = {2022},
	keywords = {peer-reviewed},
	journal = {Frontiers in Science}
},

@article{Shen2018,
	title = {From Distance Correlation to Multiscale Graph Correlation},
	author = {Shen, Cencheng and Priebe, Carey E and Vogelstein, Joshua T},
	author+an = {3=highlight;1=trainee},
	year = {2018},
	keywords = {peer-reviewed},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2018.1543125},
	month = {8},
	journal = {Journal of the American Statistical Association}
},

@article{Vogelstein2015b,
	title = {Shuffled Graph Classification: Theory and Connectome Applications},
	author = {Vogelstein, Joshua T. and Priebe, Carey E.},
	author+an = {1=highlight},
	year = {2015},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1007/s00357-015-9170-6},
	volume = {32},
	pages = {3–20},
	number = {1},
	journal = {Journal of Classification},
	doi = {10.1007/s00357-015-9170-6},
	isbn = {0176-4268},
	abstract = {We develop a formalism to address statistical pattern recognition of graph valued data. Of particular interest is the case of all graphs having the same number of uniquely labeled vertices. When the vertex labels are latent, such graphs are called shuffled graphs. Our formalism provides insight to trivially answer a number of open statistical questions including: (i) under what conditions does shuffling the vertices degrade classification performance and (ii) do universally consistent graph classifiers exist? The answers to these questions lead to practical heuristic algorithms with state-of-the-art finite sample performance, in agreement with our theoretical asymptotics. Applying these methods to classify sex and autism in two different human connectome classification tasks yields successful classification results in both applications.},
	issn = {14321343},
	eprint = {1112.5506},
	archiveprefix = {arXiv},
	arxivid = {1112.5506},
	pmid = {102201978}
},

@article{perry2020mvlearn,
	title = {mvlearn: Multiview Machine Learning in Python},
	author = {Ronan Perry and Gavin Mischler and Richard Guo and Theodore Lee and Alexander Chang and Arman Koul and Cameron Franz and Hugo Richard and Iain Carmichael and Pierre Ablin and Alexandre Gramfort and Joshua T. Vogelstein},
	author+an = {1=trainee; 12=highlight},
	year = {2021},
	keywords = {peer-reviewed},
	url = {http://jmlr.org/papers/v22/20-1370.html},
	month = {5},
	volume = {22},
	pages = {1-7},
	number = {109},
	journal = {Journal of Machine Learning Research}
},

@article{Vogelstein2009,
	title = {Spike inference from calcium imaging using sequential Monte Carlo methods},
	author = {Vogelstein, Joshua T. and Watson, Brendon O. and Packer, Adam M. and Yuste, Rafael and Jedynak, Bruno and Paninski, Liam},
	author+an = {1=highlight},
	year = {2009},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1016/j.bpj.2008.08.005},
	volume = {97},
	pages = {636–655},
	number = {2},
	journal = {Biophysical Journal},
	doi = {10.1016/j.bpj.2008.08.005},
	isbn = {0006-3495},
	abstract = {As recent advances in calcium sensing technologies facilitate simultaneously imaging action potentials in neuronal populations, complementary analytical tools must also be developed to maximize the utility of this experimental paradigm. Although the observations here are fluorescence movies, the signals of interest - spike trains and/or time varying intracellular calcium concentrations - are hidden. Inferring these hidden signals is often problematic due to noise, nonlinearities, slow imaging rate, and unknown biophysical parameters. We overcome these difficulties by developing sequential Monte Carlo methods (particle filters) based on biophysical models of spiking, calcium dynamics, and fluorescence. We show that even in simple cases, the particle filters outperform the optimal linear (i.e., Wiener) filter, both by obtaining better estimates and by providing error bars. We then relax a number of our model assumptions to incorporate nonlinear saturation of the fluorescence signal, as well external stimulus and spike history dependence (e.g., refractoriness) of the spike trains. Using both simulations and in vitro fluorescence observations, we demonstrate temporal superresolution by inferring when within a frame each spike occurs. Furthermore, the model parameters may be estimated using expectation maximization with only a very limited amount of data (e.g., ∼5-10 s or 5-40 spikes), without the requirement of any simultaneous electrophysiology or imaging experiments. © 2009 by the Biophysical Society.},
	issn = {15420086},
	pmid = {19619479}
},

@article{networkinference2019,
	title = {Inference for Multiple Heterogenous Networks with a Common Invariant Subspace},
	author = {Arroyo, Jesús and Athreya, Avanti and Cape, Joshua and Chen, Guodong and Priebe, Carey E. and Vogelstein, Joshua T.},
	author+an = {1=trainee;6=highlight},
	year = {2021},
	keywords = {peer-reviewed},
	url = {http://jmlr.org/papers/v22/19-558.html},
	volume = {22},
	pages = {1-49},
	number = {142},
	journal = {Journal of Machine Learning Research}
},

@article{spline2021,
	title = {Fitting Splines to Axonal Arbors Quantifies Relationship between Branch Order and Geometry},
	author = {Athey, Thomas L and Teneggi, Jacopo and Vogelstein, Joshua T and Tward, Daniel and Mueller, Ulrich and Miller, Michael I},
	author+an = {1=trainee;2=trainee;3=highlight},
	year = {2021},
	keywords = {peer-reviewed},
	url = {https://www.frontiersin.org/articles/10.3389/fninf.2021.704627/full? utm_source=Email_to_authors_ utm_medium=Email utm_content=T1_11.5e1_author utm_campaign=Email_publication field= journalName=Frontiers_in_Neuroinformatics id=704627},
	month = {6},
	journal = {Frontiers in Neuroinformatics}
},

@article{lawrence2021standardizing,
	title = {Standardizing human brain parcellations},
	author = {Lawrence, Ross M and Bridgeford, Eric W and Myers, Patrick E and Arvapalli, Ganesh C and Ramachandran, Sandhya C and Pisner, Derek A and Frank, Paige F and Lemmer, Allison D and Nikolaidis, Aki and Vogelstein, Joshua T},
	author+an = {1=trainee; 2=trainee; 10=highlight},
	year = {2021},
	keywords = {peer-reviewed},
	url = {https://www.nature.com/articles/s41597-021-00849-3},
	volume = {8},
	pages = {1–9},
	number = {1},
	journal = {Scientific data},
	publisher = {Nature Publishing Group}
},

@article{Zheng2016b,
	title = {Semi-external memory sparse matrix multiplication for billion-node graphs},
	author = {Zheng, Da and Mhembere, Disa and Lyzinski, Vince and Vogelstein, Joshua T. and Priebe, Carey E. and Burns, Randal},
	author+an = {1=trainee;2=trainee;4=highlight},
	year = {2017},
	keywords = {peer-reviewed},
	url = {https://ieeexplore.ieee.org/abstract/document/7593270},
	volume = {28},
	pages = {1470–1483},
	number = {5},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	doi = {10.1109/TPDS.2016.2618791},
	abstract = {Sparse matrix multiplication is traditionally performed in memory and scales to large matrices using the distributed memory of multiple nodes. In contrast, we scale sparse matrix multiplication beyond memory capacity by implementing sparse matrix dense matrix multiplication (SpMM) in a semi-external memory (SEM) fashion; i.e., we keep the sparse matrix on commodity SSDs and dense matrices in memory. Our SEM-SpMM incorporates many in-memory optimizations for large power-law graphs. It outperforms the in-memory implementations of Trilinos and Intel MKL and scales to billion-node graphs, far beyond the limitations of memory. Furthermore, on a single large parallel machine, our SEM-SpMM operates as fast as the distributed implementations of Trilinos using five times as much processing power. We also run our implementation in memory (IM-SpMM) to quantify the overhead of keeping data on SSDs. SEM-SpMM achieves almost 100 percent performance of IM-SpMM on graphs when the dense matrix has more than four columns; it achieves at least 65 percent performance of IM-SpMM on all inputs. We apply our SpMM to three important data analysis tasks - PageRank, eigensolving, and non-negative matrix factorization - and show that our SEM implementations significantly advance the state of the art.},
	issn = {10459219},
	eprint = {1602.02864},
	archiveprefix = {arXiv},
	arxivid = {1602.02864},
	publisher = {ieeexplore.ieee.org}
},

@article{Weiler2014,
	title = {Synaptic molecular imaging in spared and deprived columns of mouse barrel cortex with array tomography},
	author = {Weiler, Nicholas C. and Collman, Forrest and Vogelstein, Joshua T. and Burns, Randal and Smith, Stephen J.},
	author+an = {3=highlight},
	year = {2014},
	keywords = {peer-reviewed},
	url = {http://www.nature.com/articles/sdata201446},
	volume = {1},
	journal = {Scientific Data},
	doi = {10.1038/sdata.2014.46},
	abstract = {A major question in neuroscience is how diverse subsets of synaptic connections in neural circuits are affected by experience dependent plasticity to form the basis for behavioral learning and memory. Differences in protein expression patterns at individual synapses could constitute a key to understanding both synaptic diversity and the effects of plasticity at different synapse populations. Our approach to this question leverages the immunohistochemical multiplexing capability of array tomography (ATomo) and the columnar organization of mouse barrel cortex to create a dataset comprising high resolution volumetric images of spared and deprived cortical whisker barrels stained for over a dozen synaptic molecules each. These dataset has been made available through the Open Connectome Project for interactive online viewing, and may also be downloaded for offline analysis using web, Matlab, and other interfaces.},
	issn = {20524463},
	publisher = {Nature Publishing Group},
	pmid = {25977797}
},

@article{Wang2019,
	title = {Joint Embedding of Graphs},
	author = {Wang, Shangsi and Arroyo, Jesús and Vogelstein, Joshua T and Priebe, Carey E},
	author+an = {3=highlight;1=trainee;2=trainee},
	year = {2021},
	keywords = {peer-reviewed},
	url = {https://ieeexplore.ieee.org/document/8889404},
	month = {4},
	volume = {43},
	journal = {Transactions on Pattern Analysis and Machine Intelligence}
},

@article{wang2017selected,
	title = {Selected reaction monitoring approach for validating peptide biomarkers},
	author = {Wang, Qing and Zhang, Ming and Tomita, Tyler and Vogelstein, Joshua T. and Zhou, Shibin and Papadopoulos, Nickolas and Kinzler, Kenneth W. and Vogelstein, Bert},
	author+an = {3=trainee;4=highlight},
	year = {2017},
	keywords = {peer-reviewed},
	url = {http://www.pnas.org/content/114/51/13519.short},
	volume = {114},
	pages = {13519–13524},
	number = {51},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	doi = {10.1073/pnas.1712731114},
	abstract = {We here describe a selected reaction monitoring (SRM)-based approach for the discovery and validation of peptide biomarkers for cancer. The first stage of this approach is the direct identification of candidate peptides through comparison of proteolytic peptides derived from the plasma of cancer patients or healthy individuals. Several hundred candidate peptides were identified through this method, providing challenges for choosing and validating the small number of peptides that might prove diagnostically useful. To accomplish this validation, we used 2D chromatography coupled with SRM of candidate peptides. We applied this approach, called sequential analysis of fractionated eluates by SRM (SAFE-SRM), to plasma from cancer patients and discovered two peptides encoded by the peptidyl-prolyl cis-trans isomerase A (PPIA) gene whose abundance was increased in the plasma of ovarian cancer patients. At optimal thresholds, elevated levels of at least one of these two peptides was detected in 43 (68.3},
	issn = {10916490},
	publisher = {National Academy of Sciences}
},

@article{shenChiSquareTestDistance2021,
	title = {The Chi-Square Test of Distance Correlation},
	author = {Shen, Cencheng and Panda, Sambit and Vogelstein, Joshua T.},
	author+an = {1=trainee;2=trainee;3=highlight},
	year = {2021},
	keywords = {peer-reviewed},
	url = {https://www.tandfonline.com/doi/full/10.1080/10618600.2021.1938585},
	month = {6},
	volume = {0},
	pages = {1–21},
	number = {ja},
	journal = {Journal of Computational and Graphical Statistics},
	doi = {10.1080/10618600.2021.1938585},
	abstract = {Distance correlation has gained much recent attention in the data science community: the sample statistic is straightforward to compute and asymptotically equals zero if and only if independence, making it an ideal choice to discover any type of dependency structure given sufficient sample size. One major bottleneck is the testing process: because the null distribution of distance correlation depends on the underlying random variables and metric choice, it typically requires a permutation test to estimate the null and compute the p-value, which is very costly for large amount of data. To overcome the difficulty, in this paper we propose a chi-square test for distance correlation. Method-wise, the chi-square test is non-parametric, extremely fast, and applicable to bias-corrected distance correlation using any strong negative type metric or characteristic kernel. The test exhibits a similar testing power as the standard permutation test, and can be utilized for K-sample and partial testing. Theory-wise, we show that the underlying chi-square distribution well approximates and dominates the limiting null distribution in upper tail, prove the chi-square test can be valid and universally consistent for testing independence, and establish a testing power inequality with respect to the permutation test.},
	issn = {1061-8600},
	publisher = {Taylor Francis},
	copyright = {All rights reserved},
	annotation = {_eprint: https://doi.org/10.1080/10618600.2021.1938585}
},

@article{Vogelstein2021May,
	title = {Supervised dimensionality reduction for big data},
	author = {Vogelstein, Joshua T. and Bridgeford, Eric W. and Tang, Minh and Zheng, Da and Douville, Christopher and Burns, Randal and Maggioni, Mauro},
	author+an = {1=highlight},
	year = {2021},
	keywords = {peer-reviewed},
	month = {5},
	volume = {12},
	pages = {1-9},
	number = {2872},
	journal = {Nature Communications},
	doi = {10.1038/s41467-021-23102-2},
	issn = {2041-1723},
	publisher = {Nature Publishing Group}
},

@article{koenecke2021alpha,
	title = {"Alpha-1 adrenergic receptor antagonists to prevent hyperinflammation and death from lower respiratory tract infection",journal=Elife},
	author = {Koenecke, Allison and Powell, Michael and Xiong, Ruoxuan and Shen, Zhu and Fischer, Nicole and Huq, Sakibul and Khalafallah, Adham M. and Trevisan, Marco and Sparen, Pr and Carrero, Juan J and Nishimura, Akihiko and Caffo, Brian and Stuart, Elizabeth A. and Bai, Renyuan and Staedtke, Verena and Thomas, David L. and Papadopoulos, Nickolas and Kinzler, Kenneth W. and Vogelstein, Bert and Zhou, Shibin and Bettegowda, Chetan and Konig, Maximilian F. and Mensh, Brett and Vogelstein, Joshua T. and Athey, Susan},
	author+an = {2=trainee;24=highlight},
	year = {2021},
	keywords = {peer-reviewed},
	url = {https://elifesciences.org/articles/61700},
	month = {6},
	volume = {10},
	pages = {e61700},
	doi = {10.7554/eLife.61700},
	publisher = {eLife Sciences Publications Limited}
},

@article{hildebrand2017whole,
	title = {Whole-brain serial-section electron microscopy in larval zebrafish},
	author = {Hildebrand, David Grant Colburn and Cicconet, Marcelo and Torres, Russel Miguel and Choi, Woohyuk and Quan, Tran Minh and Moon, Jungmin and Wetzel, Arthur Willis and Scott Champion, Andrew and Graham, Brett Jesse and Randlett, Owen and Plummer, George Scott and Portugues, Ruben and Bianco, Isaac Henry and Saalfeld, Stephan and Baden, Alexander David and Lillaney, Kunal and Burns, Randal and Vogelstein, Joshua Tzvi and Schier, Alexander Franz and Lee, Wei Chung Allen and Jeong, Won Ki and Lichtman, Jeff William and Engert, Florian},
	author+an = {15=trainee;16=trainee;18=highlight},
	year = {2017},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1038/nature22356},
	volume = {545},
	pages = {345–349},
	number = {7654},
	journal = {Nature},
	doi = {10.1038/nature22356},
	abstract = {High-resolution serial-section electron microscopy (ssEM) makes it possible to investigate the dense meshwork of axons, dendrites, synapses that form neuronal circuits. However, the imaging scale required to comprehensively reconstruct these structures is more than ten orders of magnitude smaller than the spatial extents occupied by networks of interconnected neurons, some of which span nearly the entire brain. Difficulties in generating and handling data for large volumes at nanoscale resolution have thus restricted vertebrate studies to fragments of circuits. These efforts were recently transformed by advances in computing, sample handling, imaging techniques, but high-resolution examination of entire brains remains a challenge. Here, we present ssEM data for the complete brain of a larval zebrafish (Danio rerio) at 5.5 days post-fertilization. Our approach utilizes multiple rounds of targeted imaging at different scales to reduce acquisition time and data management requirements. The resulting dataset can be analysed to reconstruct neuronal processes, permitting us to survey all myelinated axons (the projectome). These reconstructions enable precise investigations of neuronal morphology, which reveal remarkable bilateral symmetry in myelinated reticulospinal and lateral line afferent axons. We further set the stage for whole-brain structure-function comparisons by co-registering functional reference atlases and in vivo two-photon fluorescence microscopy data from the same specimen. All obtained images and reconstructions are provided as an open-access resource.},
	issn = {14764687},
	publisher = {Nature Publishing Group}
},

@article{Durante2016,
	title = {Nonparametric Bayes Modeling of Populations of Networks},
	author = {Durante, Daniele and Dunson, David B. and Vogelstein, Joshua T.},
	author+an = {3=highlight},
	year = {2017},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1080/01621459.2016.1219260},
	month = {7},
	volume = {112},
	pages = {1516–1530},
	number = {520},
	journal = {Journal of the American Statistical Association},
	doi = {10.1080/01621459.2016.1219260},
	abstract = {Replicated network data are increasingly available in many research fields. For example, in connectomic applications, interconnections among brain regions are collected for each patient under study, motivating statistical models which can flexibly characterize the probabilistic generative mechanism underlying these network-valued data. Available models for a single network are not designed specifically for inference on the entire probability mass function of a network-valued random variable and therefore lack flexibility in characterizing the distribution of relevant topological structures. We propose a flexible Bayesian nonparametric approach for modeling the population distribution of network-valued data. The joint distribution of the edges is defined via a mixture model that reduces dimensionality and efficiently incorporates network information within each mixture component by leveraging latent space representations. The formulation leads to an efficient Gibbs sampler and provides simple and coherent strategies for inference and goodness-of-fit assessments. We provide theoretical results on the flexibility of our model and illustrate improved performance—compared to state-of-the-art models—in simulations and application to human brain networks. Supplementary materials for this article are available online.},
	issn = {1537274X},
	eprint = {1406.7851},
	archiveprefix = {arXiv},
	arxivid = {1406.7851},
	publisher = {Taylor and Francis}
},

@article{Priebe2015,
	title = {Statistical Inference on Errorfully Observed Graphs},
	author = {Priebe, Carey E. and Sussman, Daniel L. and Tang, Minh and Vogelstein, Joshua T.},
	author+an = {4=highlight},
	year = {2015},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1080/10618600.2014.951049},
	month = {8},
	volume = {24},
	pages = {930–953},
	number = {4},
	journal = {Journal of Computational and Graphical Statistics},
	doi = {10.1080/10618600.2014.951049},
	abstract = {Statistical inference on graphs is a burgeoning field in the applied and theoretical statistics communities, as well as throughout the wider world of science, engineering, business, etc. In many applications, we are faced with the reality of errorfully observed graphs. That is, the existence of an edge between two vertices is based on some imperfect assessment. In this article, we consider a graph G = (V, E). We wish to perform an inference task—the inference task considered here is “vertex classification,” that is, given a vertex v with unknown label Y(v), we want to infer the label for v based on the graph G and the given labels for some set of vertices in G not containing v. However, we do not observe G; rather, for each potential edge (Formula presented.) we observe an “edge feature” that we use to classify uv as edge/not-edge. Thus, we errorfully observe G when we observe the graph (Formula presented.) as the edges in (Formula presented.) arise from the classifications of the “edge features,” and are expected to be errorful. Moreover, we face a quantity/quality trade-off regarding the edge features we observe—more informative edge features are more expensive, and hence the number of potential edges that can be assessed decreases with the quality of the edge features. We studied this problem by formulating a quantity/quality trade-off for a simple class of random graphs model, namely, the stochastic blockmodel. We then consider a simple but optimal vertex classifier for classifying v and we derive the optimal quantity/quality operating point for subsequent graph inference in the face of this trade-off. The optimal operating points for the quantity/quality trade-off are surprising and illustrate the issue that methods for intermediate tasks should be chosen to maximize performance for the ultimate inference task. Finally, we investigate the quantity/quality tradeoff for errorful observations of the C. elegans connectome graph.},
	issn = {15372715},
	eprint = {1211.3601},
	archiveprefix = {arXiv},
	arxivid = {1211.3601},
	publisher = {Taylor and Francis}
},

@article{Koutra2016,
	title = {DeltaCon: Principled Massive-Graph Similarity Function with Attribution},
	author = {Koutra, Danai and Shah, Neil and Vogelstein, Joshua T. and Gallagher, Brian and Faloutsos, Christos},
	author+an = {3=highlight},
	year = {2016},
	keywords = {peer-reviewed},
	url = {http://doi.acm.org/10.1145/2824443},
	month = {2},
	address = {New York, NY, USA},
	volume = {10},
	number = {3},
	journal = {ACM Transactions on Knowledge Discovery from Data},
	doi = {10.1145/2824443},
	abstract = {How much has a network changed since yesterday? How different is the wiring of Bob's brain (a left-handed male) and Alice's brain (a right-handed female), and how is it different? Graph similarity with given node correspondence, i.e., the detection of changes in the connectivity of graphs, arises in numerous settings. In this work, we formally state the axioms and desired properties of the graph similarity functions, and evaluate when state-of-the-art methods fail to detect crucial connectivity changes in graphs. We propose DELTACON, a principled, intuitive, and scalable algorithm that assesses the similarity between two graphs on the same nodes (e.g., employees of a company, customers of a mobile carrier). In conjunction, we propose DELTACON-ATTR, a related approach that enables attribution of change or dissimilarity to responsible nodes and edges. Experiments on various synthetic and real graphs showcase the advantages of our method over existing similarity measures. Finally, we employ DELTACON and DELTACON-ATTR on real applications: (a) we classify people to groups of high and low creativity based on their brain connectivity graphs, (b) do temporal anomaly detection in the who-emails-whom Enron graph and find the top culprits for the changes in the temporal corporate email graph, and (c) recover pairs of test-retest large brain scans (∼17M edges, up to 90M edges) for 21 subjects.},
	issn = {1556-4681},
	publisher = {ACM},
	acmid = {2824443},
	articleno = {28},
	issue_date = {February 2016}
},

@article{priebe2018two,
	title = {On a two-truths phenomenon in spectral graph clustering},
	author = {Priebe, Carey E. and Park, Youngser and Vogelstein, Joshua T. and Conroy, John M. and Lyzinski, Vince and Tang, Minh and Athreya, Avanti and Cape, Joshua and Bridgeford, Eric},
	author+an = {3=highlight;9=trainee},
	year = {2019},
	keywords = {peer-reviewed},
	url = {https://www.pnas.org/content/early/2019/03/07/1814462116.short},
	month = {2},
	volume = {116},
	pages = {5995–6000},
	number = {13},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	doi = {10.1073/pnas.1814462116},
	abstract = {Clustering is concerned with coherently grouping observations without any explicit concept of true groupings. Spectral graph clustering-clustering the vertices of a graph based on their spectral embedding-is commonly approached via K-means (or, more generally, Gaussian mixture model) clustering composed with either Laplacian spectral embedding (LSE) or adjacency spectral embedding (ASE). Recent theoretical results provide deeper understanding of the problem and solutions and lead us to a "two-truths" LSE vs. ASE spectral graph clustering phenomenon convincingly illustrated here via a diffusion MRI connectome dataset: The different embedding methods yield different clustering results, with LSE capturing left hemisphere/right hemisphere affinity structure and ASE capturing gray matter/white matter core-periphery structure.},
	issn = {10916490},
	eprint = {1808.07801},
	archiveprefix = {arXiv},
	arxivid = {1808.07801}
},

@article{Raag2016,
	title = {Factors affecting characterization and localization of interindividual differences in functional connectivity using MRI},
	author = {Airan, Raag D. and Vogelstein, Joshua T. and Pillai, Jay J. and Caffo, Brian and Pekar, James J. and Sair, Haris I.},
	author+an = {2=highlight},
	year = {2016},
	keywords = {peer-reviewed},
	url = {http://dx.doi.org/10.1002/hbm.23150},
	volume = {37},
	pages = {1986–1997},
	number = {5},
	journal = {Human Brain Mapping},
	doi = {10.1002/hbm.23150},
	abstract = {Much recent attention has been paid to quantifying anatomic and functional neuroimaging on the individual subject level. For optimal individual subject characterization, specific acquisition and analysis features need to be identified that maximize interindividual variability while concomitantly minimizing intra-subject variability. We delineate the effect of various acquisition parameters (length of acquisition, sampling frequency) and analysis methods (time course extraction, region of interest parcellation, and thresholding of connectivity-derived network graphs) on characterizing individual subject differentiation. We utilize a non-parametric statistical metric that quantifies the degree to which a parameter set allows this individual subject differentiation by both maximizing interindividual variance and minimizing intra-individual variance. We apply this metric to analysis of four publicly available test-retest resting-state fMRI (rs-fMRI) data sets. We find that for the question of maximizing individual differentiation, (i) for increasing sampling, there is a relative tradeoff between increased sampling frequency and increased acquisition time; (ii) for the sizes of the interrogated data sets, only 3-4 min of acquisition time was sufficient to maximally differentiate each subject with an algorithm that utilized no a priori information regarding subject identification; and (iii) brain regions that most contribute to this individual subject characterization lie in the default mode, attention, and executive control networks. These findings may guide optimal rs-fMRI experiment design and may elucidate the neural bases for subject-to-subject differences.},
	issn = {10970193},
	pmid = {27012314}
},

@article{Roberts2012,
	title = {The predictive capacity of personal genome sequencing},
	author = {Roberts, Nicholas J and Vogelstein, Joshua T and Parmigiani, Giovanni and Kinzler, Kenneth W and Vogelstein, Bert and Velculescu, Victor E},
	author+an = {2=highlight},
	year = {2012},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1126/scitranslmed.3003380},
	volume = {4},
	journal = {Science Translational Medicine},
	doi = {10.1126/scitranslmed.3003380},
	isbn = {1946-6242 (Electronic)1̊946-6234 (Linking)},
	abstract = {New DNA sequencing methods will soon make it possible to identify all germline variants in any individual at a reasonable cost. However, the ability of whole-genome sequencing to predict predisposition to common diseases in the general population is unknown. To estimate this predictive capacity, we use the concept of a "genometype." A specific genometype represents the genomes in the population conferring a specific level of genetic risk for a specified disease. Using this concept, we estimated the maximum capacity of whole-genome sequencing to identify individuals at clinically significant risk for 24 different diseases. Our estimates were derived from the analysis of large numbers of monozygotic twin pairs; twins of a pair share the same genometype and therefore identical genetic risk factors. Our analyses indicate that (i) for 23 of the 24 diseases, most of the individuals will receive negative test results; (ii) these negative test results will, in general, not be very informative, because the risk of developing 19 of the 24 diseases in those who test negative will still be, at minimum, 50 to 80},
	issn = {19466234},
	pmid = {22472521}
},

@article{Roncal2015b,
	title = {An automated images-to-graphs framework for high resolution connectomics},
	author = {Gray Roncal, William R and Kleissas, Dean M and Vogelstein, Joshua T and Manavalan, Priya and Lillaney, Kunal and Pekala, Michael and Burns, Randal and Vogelstein, R Jacob and Priebe, Carey E and Chevillet, Mark A and Hager, Gregory D},
	author+an = {3=highlight;1=trainee;4=trainee;5=trainee},
	year = {2015},
	keywords = {peer-reviewed},
	url = {http://journal.frontiersin.org/article/10.3389/fninf.2015.00020},
	volume = {9},
	journal = {Frontiers in Neuroinformatics},
	doi = {10.3389/fninf.2015.00020},
	isbn = {1662-5196},
	abstract = {Reconstructing a map of neuronal connectivity is a critical challenge in contemporary neuroscience. Recent advances in high-throughput serial section electron microscopy (EM) have produced massive 3D image volumes of nanoscale brain tissue for the first time. The resolution of EM allows for individual neurons and their synaptic connections to be directly observed. Recovering neuronal networks by manually tracing each neuronal process at this scale is unmanageable, and therefore researchers are developing automated image processing modules. Thus far, state-of-the-art algorithms focus only on the solution to a particular task (e.g., neuron segmentation or synapse identification). In this manuscript we present the first fully-automated images-to-graphs pipeline (i.e., a pipeline that begins with an imaged volume of neural tissue and produces a brain graph without any human interaction). To evaluate overall performance and select the best parameters and methods, we also develop a metric to assess the quality of the output graphs. We evaluate a set of algorithms and parameters, searching possible operating points to identify the best available brain graph for our assessment metric. Finally, we deploy a reference end-to-end version of the pipeline on a large, publicly available data set. This provides a baseline result and framework for community analysis and future algorithm development and testing. All code and data derivatives have been made publicly available in support of eventually unlocking new biofidelic computational primitives and understanding of neuropathologies.},
	issn = {1662-5196},
	pmid = {26321942}
},

@article{Mishchenko2011,
	title = {A Bayesian approach for inferring neuronal conectivity from calcium fluorescent imaging data},
	author = {Mishchencko, Yuriy and Vogelstein, Joshua T and Paninski, Liam},
	author+an = {2=highlight},
	year = {2011},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1214/09-AOAS303},
	volume = {5},
	journal = {The annals of applied statistics},
	doi = {10.1214/09-AOAS303},
	isbn = {1932-6157},
	abstract = {Deducing the structure of neural circuits is one of the central problems of modern neuroscience. Recently-introduced calcium fluorescent imaging methods permit experimentalists to observe network activity in large popu lations of neurons, but these techniques provide only indirect observations of neural spike trains, with limited time resolution and signal quality. In this work we present a Bayesian approach for inferring neural circuitry given this type of imaging data. We model the network activity in terms of a collec tion of coupled hidden Markov chains, with each chain corresponding to a single neuron in the network and the coupling between the chains reflecting the network's connectivity matrix. We derive a Monte Carlo Expectation Maximization algorithm for fitting the model parameters; to obtain the suf ficient statistics in a computationally-efficient manner, we introduce a spe cialized blockwise-Gibbs algorithm for sampling from the joint activity of all observed neurons given the observed fluorescence data. We perform large scale simulations of randomly connected neuronal networks with biophysi cally realistic parameters and find that the proposed methods can accurately infer the connectivity in these networks given reasonable experimental and computational constraints. In addition, the estimation accuracy may be im proved significantly by incorporating prior knowledge about the sparseness of connectivity in the network, via standard L penalization methods.},
	issn = {19326157},
	publisher = {Institute of Mathematical Statistics},
	pmid = {1000164123}
},

@article{Priebe2013,
	title = {Optimizing the quantity/quality trade-off in connectome inference},
	author = {Priebe, Carey E. and Vogelstein, Joshua and Bock, Davi},
	author+an = {2=highlight},
	year = {2013},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1080/03610926.2011.630768},
	volume = {42},
	pages = {3455–3462},
	number = {19},
	journal = {Communications in Statistics - Theory and Methods},
	doi = {10.1080/03610926.2011.630768},
	abstract = {We demonstrate a meaningful prospective power analysis for an (admittedly idealized) illustrative connectome inference task. Modeling neurons as vertices and synapses as edges in a simple random graph model, we optimize the trade-off between the number of (putative) edges identified and the accuracy of the edge identification procedure. We conclude that explicit analysis of the quantity/quality trade-off is imperative for optimal neuroscientific experimental design. In particular, identifying edges faster/more cheaply, but with more error, can yield superior inferential performance. Copyright © Taylor Francis Group, LLC.},
	issn = {03610926},
	eprint = {1108.6271},
	archiveprefix = {arXiv},
	arxivid = {1108.6271},
	publisher = {Taylor and Francis}
},

@article{simhal2017probabilistic,
	title = {Probabilistic fluorescence-based synapse detection},
	author = {Simhal, Anish K. and Aguerrebere, Cecilia and Collman, Forrest and Vogelstein, Joshua T. and Micheva, Kristina D. and Weinberg, Richard J. and Smith, Stephen J. and Sapiro, Guillermo},
	author+an = {4=highlight},
	year = {2017},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1371/journal.pcbi.1005493},
	volume = {13},
	number = {4},
	journal = {PLoS Computational Biology},
	doi = {10.1371/journal.pcbi.1005493},
	abstract = {Deeper exploration of the brain's vast synaptic networks will require new tools for high-throughput structural and molecular profiling of the diverse populations of synapses that compose those networks. Fluorescence microscopy (FM) and electron microscopy (EM) offer complementary advantages and disadvantages for single-synapse analysis. FM combines exquisite molecular discrimination capacities with high speed and low cost, but rigorous discrimination between synaptic and non-synaptic fluorescence signals is challenging. In contrast, EM remains the gold standard for reliable identification of a synapse, but offers only limited molecular discrimination and is slow and costly. To develop and test single-synapse image analysis methods, we have used datasets from conjugate array tomography (cAT), which provides voxel-conjugate FM and EM (annotated) images of the same individual synapses. We report a novel unsupervised probabilistic method for detection of synapses from multiplex FM (muxFM) image data, and evaluate this method both by comparison to EM gold standard annotated data and by examining its capacity to reproduce known important features of cortical synapse distributions. The proposed probabilistic model-based synapse detector accepts molecular-morphological synapse models as user queries, and delivers a volumetric map of the probability that each voxel represents part of a synapse. Taking human annotation of cAT EM data as ground truth, we show that our algorithm detects synapses from muxFM data alone as successfully as human annotators seeing only the muxFM data, and accurately reproduces known architectural features of cortical synapse distributions. This approach opens the door to data-driven discovery of new synapse types and their density. We suggest that our probabilistic synapse detector will also be useful for analysis of standard confocal and super-resolution FM images, where EM cross-validation is not practical.},
	publisher = {Public Library of Science},
	pmid = {28414801}
},

@article{klein2019,
	title = {Thermal sensors improve wrist-worn position tracking},
	author = {Son, Jake J. and Clucas, Jon C. and White, Curt and Krishnakumar, Anirudh and Vogelstein, Joshua T. and Milham, Michael P. and Klein, Arno},
	author+an = {5=highlight},
	year = {2019},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1038/s41746-019-0092-2},
	month = {2},
	volume = {2},
	number = {1},
	journal = {npj digital medicine},
	doi = {10.1038/s41746-019-0092-2},
	abstract = {Wearable devices provide a means of tracking hand position in relation to the head, but have mostly relied on wrist-worn inertial measurement unit sensors and proximity sensors, which are inadequate for identifying specific locations. This limits their utility for accurate and precise monitoring of behaviors or providing feedback to guide behaviors. A potential clinical application is monitoring body-focused repetitive behaviors (BFRBs), recurrent, injurious behaviors directed toward the body, such as nail biting and hair pulling, which are often misdiagnosed and undertreated. Here, we demonstrate that including thermal sensors achieves higher accuracy in position tracking when compared against inertial measurement unit and proximity sensor data alone. Our Tingle device distinguished between behaviors from six locations on the head across 39 adult participants, with high AUROC values (best was back of the head: median (1.0), median absolute deviation (0.0); worst was on the cheek: median (0.93), median absolute deviation (0.09)). This study presents preliminary evidence of the advantage of including thermal sensors for position tracking and the Tingle wearable device's potential use in a wide variety of settings, including BFRB diagnosis and management.},
	issn = {2398-6352}
},

@article{Vogelstein2015,
	title = {Fast Approximate Quadratic programming for graph matching},
	author = {Vogelstein, Joshua T. and Conroy, John M. and Lyzinski, Vince and Podrazik, Louis J. and Kratzer, Steven G. and Harley, Eric T. and Fishkind, Donniell E. and Vogelstein, R. Jacob and Priebe, Carey E.},
	author+an = {1=highlight},
	year = {2015},
	keywords = {peer-reviewed},
	url = {http://dx.doi.org/10.1371/journal.pone.0121002},
	volume = {10},
	number = {4},
	journal = {PLoS ONE},
	doi = {10.1371/journal.pone.0121002},
	abstract = {Quadratic assignment problems arise in a wide variety of domains, spanning operations research, graph theory, computer vision, and neuroscience, to name a few. The graph matching problem is a special case of the quadratic assignment problem, and graph matching is increasingly important as graph-valued data is becoming more prominent. With the aim of efficiently and accurately matching the large graphs common in big data, we present our graph matching algorithm, the Fast Approximate Quadratic assignment algorithm. We empirically demonstrate that our algorithm is faster and achieves a lower objective value on over 80},
	issn = {19326203},
	pmid = {25886624}
},

@article{Durante2017,
	title = {Rejoinder: Nonparametric Bayes Modeling of Populations of Networks},
	author = {Durante, Daniele and Dunson, David B. and Vogelstein, Joshua T.},
	author+an = {3=highlight},
	year = {2017},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1080/01621459.2017.1395643},
	month = {8},
	volume = {112},
	journal = {Journal of the American Statistical Association},
	doi = {10.1080/01621459.2017.1395643},
	issn = {0162-1459},
	publisher = {Taylor and Francis}
},

@article{Fishkind2013,
	title = {Consistent adjacency-spectral partitioning for the stochastic block model when the model parameters are unknown},
	author = {Fishkind, Donniell E. and Sussman, Daniel L. and Tang, Minh and Vogelstein, Joshua T. and Priebe, Carey E.},
	author+an = {4=highlight},
	year = {2012},
	keywords = {peer-reviewed},
	url = {http://arxiv.org/abs/1205.0309},
	month = {9},
	volume = {34},
	pages = {23–39},
	number = {1},
	journal = {SIAM Journal on Matrix Analysis and Applications},
	doi = {10.1137/120875600},
	abstract = {For random graphs distributed according to a stochastic block model, we consider the inferential task of partitioning vertices into blocks using spectral techniques. Spectral partitioning using the normalized Laplacian and the adjacency matrix have both been shown to be consistent as the number of vertices tend to infinity. Importantly, both procedures require that the number of blocks and the rank of the communication probability matrix be known, even as the rest of the parameters may be unknown. In this paper, we prove that the (suitably modified) adjacency-spectral partitioning procedure, requiring only an upper bound on the rank of the communication probability matrix, is consistent. Indeed, this result demonstrates a robustness to model mis-specification; an overestimate of the rank may impose a moderate performance penalty, but the procedure is still consistent. Furthermore, we extend this procedure to the setting where adjacencies may have multiple modalities and we allow for either directed or undirected graphs.},
	issn = {0895-4798},
	eprint = {1205.0309},
	archiveprefix = {arXiv},
	arxivid = {1205.0309},
	publisher = {Society for Industrial and Applied Mathematics}
},

@article{graspy2019,
	title = {GraSPy: Graph Statistics in Python},
	author = {Chung, Jaewon and Pedigo, Benjamin D. and Bridgeford, Eric W. and Varjavand, Bijan K. and Vogelstein, Joshua T.},
	author+an = {5=highlight;1=trainee;2=trainee;3=trainee;4=trainee},
	year = {2019},
	keywords = {peer-reviewed},
	url = {http://jmlr.org/papers/v20/19-490.html},
	month = {4},
	volume = {20},
	pages = {1–7},
	number = {158},
	journal = {Journal of Machine Learning Research},
	eprint = {https://arxiv.org/abs/1904.05329}
},

@article{Gray2012,
	title = {Magnetic Resonance Connectome Automated Pipeline: An Overview},
	author = {Gray, William R. and Bogovic, John A. and Vogelstein, Joshua T. and Landman, Bennett A. and Prince, Jerry L. and Vogelstein, R. Jacob},
	author+an = {3=highlight;1=trainee},
	year = {2012},
	keywords = {peer-reviewed},
	url = {http://ieeexplore.ieee.org/document/6173097/},
	month = {3},
	volume = {3},
	pages = {42–48},
	number = {2},
	journal = {IEEE Pulse},
	doi = {10.1109/MPUL.2011.2181023},
	abstract = {This article presents a novel, tightly integrated pipeline for estimating a connectome. The pipeline utilizes magnetic resonance (MR) imaging (MRI) data to produce a high-level estimate of the structural connectivity in the human brain. The MR connectome automated pipeline (MRCAP) is efficient, and its modular construction allows researchers to modify algorithms to meet their specific requirements. The pipeline has been validated, and more than 200 connectomes have been processed and analyzed to date. © 2012 IEEE.},
	issn = {21542287}
},

@article{harris2015resource,
	title = {A resource from 3D electron microscopy of hippocampal neuropil for user training and tool development},
	author = {Harris, Kristen M. and Spacek, Josef and Bell, Maria Elizabeth and Parker, Patrick H. and Lindsey, Laurence F. and Baden, Alexander D. and Vogelstein, Joshua T. and Burns, Randal},
	author+an = {7=highlight},
	year = {2015},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1038/sdata.2015.46},
	volume = {2},
	journal = {Scientific Data},
	doi = {10.1038/sdata.2015.46},
	isbn = {2052-4463 (Electronic) 2052-4463 (Linking)},
	abstract = {Resurgent interest in synaptic circuitry and plasticity has emphasized the importance of 3D reconstruction from serial section electron microscopy (3DEM). Three volumes of hippocampal CA1 neuropil from adult rat were imaged at X-Y resolution of ∼2 nm on serial sections of ∼50-60 nm thickness. These are the first densely reconstructed hippocampal volumes. All axons, dendrites, glia, and synapses were reconstructed in a cube (∼10 μm 3) surrounding a large dendritic spine, a cylinder (∼43 μm 3) surrounding an oblique dendritic segment (3.4 μm long), and a parallelepiped (∼178 μm 3) surrounding an apical dendritic segment (4.9 μm long). The data provide standards for identifying ultrastructural objects in 4DEM, realistic reconstructions for modeling biophysical properties of synaptic transmission, and a test bed for enhancing reconstruction tools. Representative synapses are quantified from varying section planes, and microtubules, polyribosomes, smooth endoplasmic reticulum, and endosomes are identified and reconstructed in a subset of dendrites. The original images, traces, and Reconstruct software and files are freely available and visualized at the Open Connectome Project (Data Citation 1).},
	issn = {20524463},
	publisher = {Nature Publishing Group},
	pmid = {26347348}
},

@article{Hofer2011,
	title = {Differential connectivity and response dynamics of excitatory and inhibitory neurons in visual cortex},
	author = {Hofer, Sonja B. and Ko, Ho and Pichler, Bruno and Vogelstein, Joshua and Ros, Hana and Zeng, Hongkui and Lein, Ed and Lesica, Nicholas A. and Mrsic-Flogel, Thomas D.},
	author+an = {4=highlight},
	year = {2011},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1038/nn.2876},
	volume = {14},
	pages = {1045–1052},
	number = {8},
	journal = {Nature Neuroscience},
	doi = {10.1038/nn.2876},
	isbn = {1546-1726 (Electronic)1̊097-6256 (Linking)},
	abstract = {Neuronal responses during sensory processing are influenced by both the organization of intracortical connections and the statistical features of sensory stimuli. How these intrinsic and extrinsic factors govern the activity of excitatory and inhibitory populations is unclear. Using two-photon calcium imaging in vivo and intracellular recordings in vitro, we investigated the dependencies between synaptic connectivity, feature selectivity and network activity in pyramidal cells and fast-spiking parvalbumin-expressing (PV) interneurons in mouse visual cortex. In pyramidal cell populations, patterns of neuronal correlations were largely stimulus-dependent, indicating that their responses were not strongly dominated by functionally biased recurrent connectivity. By contrast, visual stimulation only weakly modified co-activation patterns of fast-spiking PV cells, consistent with the observation that these broadly tuned interneurons received very dense and strong synaptic input from nearby pyramidal cells with diverse feature selectivities. Therefore, feedforward and recurrent network influences determine the activity of excitatory and inhibitory ensembles in fundamentally different ways.},
	issn = {10976256},
	publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	pmid = {21765421},
	shorttitle = {Nat Neurosci}
},

@article{Paninski2010,
	title = {A new look at state-space models for neural data},
	author = {Paninski, Liam and Ahmadian, Yashar and Ferreira, Daniel Gil and Koyama, Shinsuke and Rahnama Rad, Kamiar and Vidne, Michael and Vogelstein, Joshua and Wu, Wei},
	author+an = {7=highlight},
	year = {2009},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1007/s10827-009-0179-x},
	volume = {29},
	pages = {107–126},
	number = {1-2},
	journal = {Journal of Computational Neuroscience},
	doi = {10.1007/s10827-009-0179-x},
	isbn = {0929-5313},
	abstract = {State space methods have proven indispensable in neural data analysis. However, common methods for performing inference in state-space models with non-Gaussian observations rely on certain approximations which are not always accurate. Here we review direct optimization methods that avoid these approximations, but that nonetheless retain the computational efficiency of the approximate methods. We discuss a variety of examples, applying these direct optimization techniques to problems in spike train smoothing, stimulus decoding, parameter estimation, and inference of synaptic properties. Along the way, we point out connections to some related standard statistical methods, including spline smoothing and isotonic regression. Finally, we note that the computational methods reviewed here do not in fact depend on the state-space setting at all; instead, the key property we are exploiting involves the bandedness of certain matrices. We close by discussing some applications of this more general point of view, including Markov chain Monte Carlo methods for neural decoding and efficient estimation of spatially-varying firing rates. © 2009 Springer Science+Business Media, LLC.},
	issn = {09295313},
	pmid = {19649698}
},

@article{kasthuri2015saturated,
	title = {Saturated Reconstruction of a Volume of Neocortex},
	author = {Kasthuri, Narayanan and Hayworth, Kenneth Jeffrey and Berger, Daniel Raimund and Schalek, Richard Lee and Conchello, José Angel and Knowles-Barley, Seymour and Lee, Dongil and Vázquez-Reina, Amelio and Kaynig, Verena and Jones, Thouis Raymond and Roberts, Mike and Morgan, Josh Lyskowski and Tapia, Juan Carlos and Seung, H. Sebastian and Roncal, William Gray and Vogelstein, Joshua Tzvi and Burns, Randal and Sussman, Daniel Lewis and Priebe, Carey Eldin and Pfister, Hanspeter and Lichtman, Jeff William},
	author+an = {16=highlight},
	year = {2015},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1016/j.cell.2015.06.054},
	volume = {162},
	pages = {648–661},
	number = {3},
	journal = {Cell},
	doi = {10.1016/j.cell.2015.06.054},
	isbn = {1097-4172 (Electronic)0̊092-8674 (Linking)},
	abstract = {We describe automated technologies to probe the structure of neural tissue at nanometer resolution and use them to generate a saturated reconstruction of a sub-volume of mouse neocortex in which all cellular objects (axons, dendrites, and glia) and many sub-cellular components (synapses, synaptic vesicles, spines, spine apparati, postsynaptic densities, and mitochondria) are rendered and itemized in a database. We explore these data to study physical properties of brain tissue. For example, by tracing the trajectories of all excitatory axons and noting their juxtapositions, both synaptic and non-synaptic, with every dendritic spine we refute the idea that physical proximity is sufficient to predict synaptic connectivity (the so-called Peters' rule). This online minable database provides general access to the intrinsic complexity of the neocortex and enables further data-driven inquiries. Video Abstract},
	issn = {10974172},
	publisher = {Elsevier},
	pmid = {26232230}
},

@article{dyer2017quantifying,
	title = {Quantifying Mesoscale Neuroanatomy Using X-Ray Microtomography},
	author = {Dyer, Eva L. and Roncal, William Gray and Fernandes, Hugo L. and Gürsoy, Doga and De Andrade, Vincent and Vescovi, Rafael and Fezzaa, Kamel and Xiao, Xianghui and Vogelstein, Joshua T. and Jacobsen, Chris and Körding, Konrad P. and Kasthuri, Narayanan},
	author+an = {2=trainee;9=highlight},
	year = {2017},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1523/ENEURO.0195-17.2017},
	month = {9},
	volume = {4},
	journal = {eNeuro},
	doi = {10.1523/ENEURO.0195-17.2017},
	isbn = {978-1-4799-2390-8},
	abstract = {Methods for resolving the 3D microstructure of the brain typically start by thinly slicing and staining the brain, and then imaging each individual section with visible light photons or electrons. In contrast, X-rays can be used to image thick samples, providing a rapid approach for producing large 3D brain maps without sectioning. Here we demonstrate the use of synchrotron X-ray microtomography (μCT) for producing mesoscale (1∼μ m^3) resolution brain maps from millimeter-scale volumes of mouse brain. We introduce a pipeline for μCT-based brain mapping that combines methods for sample preparation, imaging, automated segmentation of image volumes into cells and blood vessels, and statistical analysis of the resulting brain structures. Our results demonstrate that X-ray tomography promises rapid quantification of large brain volumes, complementing other brain mapping and connectomics efforts.},
	issn = {2373-2822},
	eprint = {1604.03629},
	publisher = {Society for Neuroscience},
	pmid = {29085899}
},

@article{Greenspan1997,
	title = {Loss of FHIT expression in cervical carcinoma cell lines and primary tumors},
	author = {Greenspan, David L. and Connolly, Denise C. and Wu, Rong and Lei, Rachel Y. and Vogelstein, Joshua T.C. and Kim, Young Tak and Mok, Jung Eun and Muñoz, Nubia and Bosch, F. Xavier and Shah, Keerti and Cho, Kathleen R.},
	author+an = {5=highlight},
	year = {1997},
	keywords = {peer-reviewed},
	url = {http://cancerres.aacrjournals.org/content/57/21/4692},
	month = {11},
	volume = {57},
	journal = {Cancer Research},
	abstract = {Allelic deletions involving the short arm of chromosome 3 (3p13-21.1) have been observed frequently in cervical carcinomas. Recently, a candidate tumor suppressor gene, FHIT (Fragile Histidine Triad), was cloned and mapped to this chromosomal region (3p14.2). Abnormal FHIT transcripts have been identified previously in a variety of tumor cell lines and primary carcinomas, although their significance and the molecular mechanisms underlying their origin remain incompletely defined. In addition, integration of human papillomavirus DNA has been identified at a fragile site (FRA3B) within the FHIT locus in cervical cancer. These observations motivated us to evaluate FHIT mRNA and protein expression in cervical cancer cell lines, primary cervical carcinomas, and normal tissues. Transcripts of the expected size and sequence were the predominant species identified by reverse transcription (RT)-PCR in cultured keratinocytes and all normal tissues evaluated. In contrast, aberrant FHIT transcripts were readily demonstrated in 6 of 7 cervical carcinoma cell lines and 17 of 25 (68},
	issn = {00085472},
	pmid = {9354423}
},

@article{vogelstein2014discovery,
	title = {Discovery of brainwide neural-behavioral maps via multiscale unsupervised structure learning},
	author = {Vogelstein, Joshua T. and Park, Youngser and Ohyama, Tomoko and Kerr, Rex A. and Truman, James W. and Priebe, Carey E. and Zlatic, Marta},
	author+an = {1=highlight},
	year = {2014},
	keywords = {peer-reviewed},
	url = {https://science.sciencemag.org/content/344/6182/386},
	volume = {344},
	pages = {386–392},
	number = {6182},
	journal = {Science},
	doi = {10.1126/science.1250298},
	abstract = {A single nervous system can generatemany distinctmotor patterns. Identifying which neurons and circuits control which behaviors has been a laborious piecemeal process, usually for one observer-defined behavior at a time. We present a fundamentally different approach to neuron-behavior mapping. We optogenetically activated 1054 identified neuron lines in Drosophila larvae and tracked the behavioral responses from 37,780 animals. Application of multiscale unsupervised structure learning methods to the behavioral data enabled us to identify 29 discrete, statistically distinguishable, observer-unbiased behavioral phenotypes. Mapping the neural lines to the behavior(s) they evoke provides a behavioral reference atlas for neuron subsets covering a large fraction of larval neurons. This atlas is a starting point for connectivity- and activity-mapping studies to further investigate the mechanisms by which neurons mediate diverse behaviors.},
	issn = {10959203},
	publisher = {American Association for the Advancement of Science},
	pmid = {24674869}
},

@article{Vogelstein2010,
	title = {Fast non-negative deconvolution for spike train inference from population calcium imaging},
	author = {Vogelstein, Joshua T and Packer, Adam M and Machado, Tim A and Sippy, Tanya and Babadi, Baktash and Yuste, Rafael and Paninski, Liam},
	author+an = {1=highlight},
	year = {2009},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1152/jn.01073.2009},
	volume = {104},
	journal = {Journal of Neurophysiology},
	doi = {10.1152/jn.01073.2009},
	isbn = {0022-3077},
	abstract = {Calcium imaging for observing spiking activity from large populations of neurons are quickly gaining popularity. While the raw data are fluorescence movies, the underlying spike trains are of interest. This work presents a fast non-negative deconvolution filter to infer the approximately most likely spike train for each neuron, given the fluorescence observations. This algorithm outperforms optimal linear deconvolution (Wiener filtering) on both simulated and biological data. The performance gains come from restricting the inferred spike trains to be positive (using an interior-point method), unlike the Wiener filter. The algorithm is fast enough that even when imaging over 100 neurons, inference can be performed on the set of all observed traces faster than real-time. Performing optimal spatial filtering on the images further refines the estimates. Importantly, all the parameters required to perform the inference can be estimated using only the fluorescence data, obviating the need to perform joint electrophysiological and imaging calibration experiments.},
	issn = {0022-3077},
	eprint = {0912.1637},
	archiveprefix = {arXiv},
	arxivid = {0912.1637},
	pmid = {20554834}
},

@article{Vogelstein2011b,
	title = {Are mental properties supervenient on brain properties?},
	author = {Vogelstein, Joshua T. and Vogelstein, R. Jacob and Priebe, Carey E.},
	author+an = {1=highlight},
	year = {2011},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1038/srep00100},
	volume = {1},
	journal = {Scientific Reports},
	doi = {10.1038/srep00100},
	isbn = {2045-2322},
	abstract = {The "mind-brain supervenience" conjecture suggests that all mental properties are derived from the physical properties of the brain. To address the question of whether the mind supervenes on the brain, we frame a supervenience hypothesis in rigorous statistical terms. Specifically, we propose a modified version of supervenience (called ϵ-supervenience) that is amenable to experimental investigation and statistical analysis. To illustrate this approach, we perform a thought experiment that illustrates how the probabilistic theory of pattern recognition can be used to make a one-sided determination of ϵ-supervenience. The physical property of the brain employed in this analysis is the graph describing brain connectivity (i.e., the brain-graph or connectome). ϵ-supervenience allows us to determine whether a particular mental property can be inferred from one's connectome to within any given positive misclassification rate, regardless of the relationship between the two. This may provide further motivation for cross-disciplinary research between neuroscientists and statisticians.},
	issn = {20452322},
	publisher = {Nature Publishing Group},
	pmid = {22355618}
},

@article{NENNING2020117232,
	title = {Joint embedding: A scalable alignment to compare individuals in a connectivity space},
	author = {Karl-Heinz Nenning and Ting Xu and Ernst Schwartz and Jesus Arroyo and Adelheid Woehrer and Alexandre R. Franco and Joshua T. Vogelstein and Daniel S. Margulies and Hesheng Liu and Jonathan Smallwood and Michael P. Milham and Georg Langs},
	author+an = {4=trainee;7=highlight},
	year = {2020},
	keywords = {peer-reviewed},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811920307187},
	month = {11},
	volume = {222},
	pages = {117232},
	journal = {NeuroImage},
	doi = {https://doi.org/10.1016/j.neuroimage.2020.117232},
	abstract = {A common coordinate space enabling comparison across individuals is vital to understanding human brain organization and individual differences. By leveraging dimensionality reduction algorithms, high-dimensional fMRI data can be represented in a low-dimensional space to characterize individual features. Such a representative space encodes the functional architecture of individuals and enables the observation of functional changes across time. However, determining comparable functional features across individuals in resting-state fMRI in a way that simultaneously preserves individual-specific connectivity structure can be challenging. In this work we propose scalable joint embedding to simultaneously embed multiple individual brain connectomes within a common space that allows individual representations across datasets to be aligned. Using Human Connectome Project data, we evaluated the joint embedding approach by comparing it to the previously established orthonormal alignment model. Alignment using joint embedding substantially increased the similarity of functional representations across individuals while simultaneously capturing their distinct profiles, allowing individuals to be more discriminable from each other. Additionally, we demonstrated that the common space established using resting-state fMRI provides a better overlap of task-activation across participants. Finally, in a more challenging scenario - alignment across a lifespan cohort aged from 6 to 85 - joint embedding provided a better prediction of age (r2 = 0.65) than the prior alignment model. It facilitated the characterization of functional trajectories across lifespan. Overall, these analyses establish that joint embedding can simultaneously capture individual neural representations in a common connectivity space aligning functional data across participants and populations and preserve individual specificity.},
	issn = {1053-8119}
},

@article{bridgeford2021eliminating,
	title = {Eliminating accidental deviations to minimize generalization error and maximize replicability: Applications in connectomics and genomics},
	author = {Bridgeford, Eric W and Wang, Shangsi and Wang, Zeyi and Xu, Ting and Craddock, Cameron and Dey, Jayanta and Kiar, Gregory and Gray-Roncal, William and Colantuoni, Carlo and Douville, Christopher and others},
	author+an = {1=trainee; 6=trainee; 17=highlight},
	year = {2021},
	keywords = {peer-reviewed},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009279},
	volume = {17},
	pages = {e1009279},
	number = {9},
	journal = {PLoS computational biology},
	publisher = {Public Library of Science San Francisco, CA USA}
},

@article{XU2020117346,
	title = {Cross-species functional alignment reveals evolutionary hierarchy within the connectome},
	author = {Ting Xu and Karl-Heinz Nenning and Ernst Schwartz and Seok-Jun Hong and Joshua T. Vogelstein and Alexandros Goulas and Damien A. Fair and Charles E. Schroeder and Daniel S. Margulies and Jonny Smallwood and Michael P. Milham and Georg Langs},
	author+an = {5=highlight},
	year = {2020},
	keywords = {peer-reviewed},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811920308326},
	month = {12},
	volume = {223},
	pages = {117346},
	journal = {NeuroImage},
	doi = {https://doi.org/10.1016/j.neuroimage.2020.117346},
	abstract = {Evolution provides an important window into how cortical organization shapes function and vice versa. The complex mosaic of changes in brain morphology and functional organization that have shaped the mammalian cortex during evolution, complicates attempts to chart cortical differences across species. It limits our ability to fully appreciate how evolution has shaped our brain, especially in systems associated with unique human cognitive capabilities that lack anatomical homologues in other species. Here, we develop a function-based method for cross-species alignment that enables the quantification of homologous regions between humans and rhesus macaques, even when their location is decoupled from anatomical landmarks. Critically, we find cross-species similarity in functional organization reflects a gradient of evolutionary change that decreases from unimodal systems and culminates with the most pronounced changes in posterior regions of the default mode network (angular gyrus, posterior cingulate and middle temporal cortices). Our findings suggest that the establishment of the default mode network, as the apex of a cognitive hierarchy, has changed in a complex manner during human evolution – even within subnetworks},
	issn = {1053-8119}
},

@article{Chen2017,
	title = {An M-estimator for reduced-rank system identification},
	author = {Chen, Shaojie and Liu, Kai and Yang, Yuguang and Xu, Yuting and Lee, Seonjoo and Lindquist, Martin and Caffo, Brian S. and Vogelstein, Joshua T.},
	author+an = {1=trainee;8=highlight},
	year = {2017},
	keywords = {peer-reviewed},
	url = {https://www.sciencedirect.com/science/article/pii/S0167865516303671},
	month = {1},
	volume = {86},
	pages = {76–81},
	journal = {Pattern Recognition Letters},
	doi = {10.1016/J.PATREC.2016.12.012},
	abstract = {High-dimensional time-series data from a wide variety of domains, such as neuroscience, are being generated every day. Fitting statistical models to such data, to enable parameter estimation and time-series prediction, is an important computational primitive. Existing methods, however, are unable to cope with the high-dimensional nature of these data, due to both computational and statistical reasons. We mitigate both kinds of issues by proposing an M-estimator for Reduced-rank System IDentification (Mr. Sid). A combination of low-rank approximations, ℓ1 and ℓ2 penalties, and some numerical linear algebra tricks, yields an estimator that is computationally efficient and numerically stable. Simulations and real data examples demonstrate the usefulness of this approach in a variety of problems. In particular, we demonstrate that Mr. Sid can accurately estimate spatial filters, connectivity graphs, and time-courses from native resolution functional magnetic resonance imaging data. Mr. Sid therefore enables big time-series data to be analyzed using standard methods, readying the field for further generalizations including nonlinear and non-Gaussian state-space models.},
	issn = {0167-8655},
	publisher = {North-Holland}
},

@article{Binkiewicz2014,
	title = {Covariate-assisted spectral clustering},
	author = {Binkiewicz, Norbert and Vogelstein, Joshua T. and Rohe, Karl},
	author+an = {2=highlight},
	year = {2017},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1093/biomet/asx008},
	month = {3},
	volume = {104},
	pages = {361–377},
	number = {2},
	journal = {Biometrika},
	doi = {10.1093/biomet/asx008},
	abstract = {Biological and social systems consist of myriad interacting units. The interactions can be represented in the form of a graph or network. Measurements of these graphs can reveal the underlying structure of these interactions, which provides insight into the systems that generated the graphs. Moreover, in applications such as connectomics, social networks, and genomics, graph data are accompanied by contextualizing measures on each node. We utilize these node covariates to help uncover latent communities in a graph, using a modification of spectral clustering. Statistical guarantees are provided under a joint mixture model that we call the node-contextualized stochastic blockmodel, including a bound on the mis-clustering rate. The bound is used to derive conditions for achieving perfect clustering. For most simulated cases, covariate-assisted spectral clustering yields results superior to regularized spectral clustering without node covariates and to an adaptation of canonical correlation analysis. We apply our clustering method to large brain graphs derived from diffusion MRI data, using the node locations or neurological region membership as covariates. In both cases, covariate-assisted spectral clustering yields clusters that are easier to interpret neurologically.},
	issn = {14643510},
	eprint = {1411.2158},
	archiveprefix = {arXiv},
	arxivid = {1411.2158}
},

@article{burns2018community,
	title = {A Community-Developed Open-Source Computational Ecosystem for Big Neuro Data},
	author = {Vogelstein, Joshua T. and Perlman, Eric and Falk, Benjamin and Baden, Alex and Gray Roncal, William and Chandrashekhar, Vikram and Collman, Forrest and Seshamani, Sharmishtaa and Patsolic, Jesse L. and Lillaney, Kunal and Kazhdan, Michael and Hider, Robert and Pryor, Derek and Matelsky, Jordan and Gion, Timothy and Manavalan, Priya and Wester, Brock and Chevillet, Mark and Trautman, Eric T. and Khairy, Khaled and Bridgeford, Eric and Kleissas, Dean M. and Tward, Daniel J. and Crow, Ailey K. and Hsueh, Brian and Wright, Matthew A. and Miller, Michael I. and Smith, Stephen J. and Vogelstein, R. Jacob and Deisseroth, Karl and Burns, Randal},
	author+an = {1=highlight;6=trainee;21=trainee;4=trainee;10=trainee;16=trainee},
	year = {2018},
	keywords = {peer-reviewed},
	url = {https://www.nature.com/articles/s41592-018-0181-1},
	month = {8},
	volume = {15},
	pages = {846–847},
	number = {11},
	journal = {Nature Methods},
	doi = {10.1038/s41592-018-0181-1},
	abstract = {Big imaging data is becoming more prominent in brain sciences across spatiotemporal scales and phylogenies. We have developed a computational ecosystem that enables storage, visualization, and analysis of these data in the cloud, thusfar spanning 20+ publications and 100+ terabytes including nanoscale ultrastructure, microscale synaptogenetic diversity, and mesoscale whole brain connectivity, making NeuroData the largest and most diverse open repository of brain data.},
	issn = {15487105},
	eprint = {1804.02835},
	archiveprefix = {arXiv},
	arxivid = {1804.02835}
},

@article{Carlson2014,
	title = {Multichannel Electrophysiological Spike Sorting via Joint Dictionary Learning and Mixture Modeling},
	author = {Carlson, David E. and Vogelstein, Joshua T. and Wu, Qisong and Lian, Wenzhao and Zhou, Mingyuan and Stoetzner, Colin R. and Kipke, Daryl and Weber, Douglas and Dunson, David B. and Carin, Lawrence},
	author+an = {2=highlight},
	year = {2014},
	keywords = {peer-reviewed},
	url = {http://ieeexplore.ieee.org/document/6571240/},
	month = {1},
	volume = {61},
	pages = {41–54},
	number = {1},
	journal = {IEEE Transactions on Biomedical Engineering},
	doi = {10.1109/TBME.2013.2275751},
	abstract = {We propose a methodology for joint feature learning and clustering of multichannel extracellular electrophysiological data, across multiple recording periods for action potential detection and classification (sorting). Our methodology improves over the previous state of the art principally in four ways. First, via sharing information across channels, we can better distinguish between single-unit spikes and artifacts. Second, our proposed "focused mixture model" (FMM) deals with units appearing, disappearing, or reappearing over multiple recording days, an important consideration for any chronic experiment. Third, by jointly learning features and clusters, we improve performance over previous attempts that proceeded via a two-stage learning process. Fourth, by directly modeling spike rate, we improve the detection of sparsely firing neurons. Moreover, our Bayesian methodology seamlessly handles missing data. We present the state-of-the-art performance without requiring manually tuning hyperparameters, considering both a public dataset with partial ground truth and a new experimental dataset. © 2013 IEEE.},
	issn = {0018-9294},
	eprint = {1304.0542},
	archiveprefix = {arXiv},
	arxivid = {1304.0542}
},

@article{Biobank2020,
	title = {Different scalling of linear models and deep learning in UKBiobank brain images versus machine-learning datasets},
	author = {Schulz, Marc-Ander and Yeo, B.T. Thomas and Vogelstein, Joshua T. and Mourao-Miranda, Janaina and Kather, Jakob N. and Kording, Konrad and Richards, Blake and Bzdok, Danilo},
	author+an = {3=highlight},
	year = {2020},
	keywords = {peer-reviewed},
	month = {8},
	volume = {11},
	journal = {Nat Commun},
	doi = {10.1038/s41467-020-18037-z}
},

@article {Rose2021,
	title = {The association between Alpha-1 adrenergic receptor antagonists and in-hospital mortality from COVID-19},
	author = {Rose, Liam and Graham, Laura and Koenecke, Allison and Powell, Michael and Xiong, Ruoxuan and Shen, Zhu and Mench, Brett and Kinzler, Kenneth W and Bettegowda, Chetan and Vogelstein, Bert and others},
	author+an = {4=trainee; 12=highlight},
	year = {2021},
	keywords = {peer-reviewed},
	month = {3},
	volume = {8},
	journal = {Frontiers in Medicine},
	doi = {10.3389/fmed.2021.637647},
	URL = {https://www.frontiersin.org/articles/10.3389/fmed.2021.637647/full}
},

@article{Athreya2018,
	title = {Statistical Inference on Random Dot Product Graphs: a Survey},
	author = {Athreya, Avanti and Fishkind, Donniell E. and Tang, Minh and Priebe, Carey E. and Park, Youngser and Vogelstein, Joshua T. and Levin, Keith and Lyzinski, Vince and Qin, Yichen and Sussman, Daniel L},
	author+an = {6=highlight},
	year = {2018},
	keywords = {peer-reviewed},
	url = {http://jmlr.org/papers/v18/17-448.html},
	month = {5},
	volume = {18},
	pages = {1–92},
	journal = {Journal of Machine Learning Research},
	abstract = {The random dot product graph (RDPG) is an independent-edge random graph that is analytically tractable and, simultaneously, either encompasses or can successfully approximate},
	issn = {15337928},
	eprint = {1709.05454},
	archiveprefix = {arXiv},
	arxivid = {1709.05454}
},

@article{bagging2019,
	title = {Bagging Improves Reproducibility of Functional Parcellation of the Human Brain},
	author = {Nikolaidis, Aki and Heinsfeld, Anibal Solon and Xu, Ting and Bellec, Pierre and Vogelstein, Joshua T. and Milham, Michael},
	author+an = {5=highlight},
	year = {2020},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1016/j.neuroimage.2020.116678},
	month = {2},
	journal = {NeuroImage}
},

@article{HONG2020111,
	title = {Toward Neurosubtypes in Autism},
	author = {Hong, Seok-Jun and Vogelstein, Joshua T. and Gozzi, Alessandro and Bernhardt, Boris C. and Yeo, B.T. Thomas and Milham, Michael P. and Martino, Adriana Di},
	author+an = {2=highlight},
	year = {2020},
	keywords = {peer-reviewed},
	url = {http://www.sciencedirect.com/science/article/pii/S0006322320314979},
	month = {4},
	volume = {88},
	pages = {111 - 128},
	number = {1},
	journal = {Biological Psychiatry},
	doi = {https://doi.org/10.1016/j.biopsych.2020.03.022},
	abstract = {There is a consensus that substantial heterogeneity underlies the neurobiology of autism spectrum disorder (ASD). As such, it has become increasingly clear that a dissection of variation at the molecular, cellular, and brain network domains is a prerequisite for identifying biomarkers. Neuroimaging has been widely used to characterize atypical brain patterns in ASD, although findings have varied across studies. This is due, at least in part, to a failure to account for neurobiological heterogeneity. Here, we summarize emerging data-driven efforts to delineate more homogeneous ASD subgroups at the level of brain structure and function—that is, neurosubtyping. We break this pursuit into key methodological steps: the selection of diagnostic samples, neuroimaging features, algorithms, and validation approaches. Although preliminary and methodologically diverse, current studies generally agree that at least 2 to 4 distinct ASD neurosubtypes may exist. Their identification improved symptom prediction and diagnostic label accuracy above and beyond group average comparisons. Yet, this nascent literature has shed light onto challenges and gaps. These include 1) the need for wider and more deeply transdiagnostic samples collected while minimizing artifacts (e.g., head motion), 2) quantitative and unbiased methods for feature selection and multimodal fusion, 3) greater emphasis on algorithms’ ability to capture hybrid dimensional and categorical models of ASD, and 4) systematic independent replications and validations that integrate different units of analyses across multiple scales. Solutions aimed to address these challenges and gaps are discussed for future avenues leading toward a comprehensive understanding of the mechanisms underlying ASD heterogeneity},
	issn = {0006-3223},
	note = {Convergence and Heterogeneity in Psychopathology}
},

@article{francca2017kernel,
	title = {Kernel k-Groups via Hartigan's Method},
	author = {Franca, Guilherme and Rizzo, Maria and Vogelstein, Joshua T.},
	author+an = {3=highlight},
	year = {2020},
	keywords = {peer-reviewed},
	month = {5},
	volume = {PP},
	pages = {1-1},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	doi = {10.1109/TPAMI.2020.2998120}
},

@article{Tomita2018,
	title = {Sparse Projection Oblique Randomer Forests},
	author = {Tomita, Tyler M. and Browne, James and Shen, Cencheng and Chung, Jaewon and Patsolic, Jesse L. and Falk, Benjamin and Yim, Jason and Priebe, Carey E.  and Burns, Randal and Maggioni, Mauro and Vogelstein, Joshua T.},
	author+an = {1=trainee;2=trainee;4=trainee;11=highlight},
	year = {2020},
	keywords = {peer-reviewed},
	url = {http://arxiv.org/abs/1506.03410},
	month = {5},
	journal = {Journal of Machine Learninig Research}
},

@article{BigOpenBrain2020,
	title = {Toward Community-Driven Big Open Brain Science: Open Big Data and Tools for Structure, Function, and Genetics},
	author = {Charles, Adam S. and Falk, Benjamin and Turner, Nicholas and Pereira, Talmo D. and Tward, Daniel and Pedigo, Benjamin D. and Chung, Jaewon and Burns, Randal and Ghosh, Satrajit S. and Kebschull, Justus M. and Silversmith, William and Vogelstein, Joshua T.},
	author+an = {2=trainee; 6=trainee; 7=trainee; 12=highlight},
	year = {2020},
	keywords = {peer-reviewed},
	month = {7},
	volume = {43},
	pages = {441-464},
	number = {1},
	journal = {Annual Review of Neuroscience},
	doi = {10.1146/annurev-neuro-100119-110036},
	abstract = {As acquiring bigger data becomes easier in experimental brain science, computational and statistical brain science must achieve similar advances to fully capitalize on these data. Tackling these problems will benefit from a more explicit and concerted effort to work together. Specifically, brain science can be further democratized by harnessing the power of community-driven tools, which both are built by and benefit from many different people with different backgrounds and expertise. This perspective can be applied across modalities and scales and enables collaborations across previously siloed communities.},
	eprint = {https://doi.org/10.1146/annurev-neuro-100119-110036},
	URL = {https://doi.org/10.1146/annurev-neuro-100119-110036}
},

@article{Cytokine2020,
	title = {Preventing cytokine storm syndrome in COVID-19 using alpha-1 adrenergic receptor antagonists},
	author = {Maximilian F. Konig and Mike Powell and Verena Staedtke and Ren-Yuan Bai and David L. Thomas and Nicole Fischer and Sakibul Huq and Adham M. Khalafallah and Allison Koenecke and Ruoxuan Xiong and Brett Mensh and Nickolas Papadopoulos and Kenneth W. Kinzler and Bert Vogelstein and Joshua T. Vogelstein and Susan Athey and Shibin Zhou and Chetan Bettegowda},
	author+an = {2=trainee;15=highlight},
	year = {2020},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1172/JCI139642},
	month = {7},
	volume = {130},
	pages = {3345-3347},
	number = {7},
	journal = {The Journal of Clinical Investigation},
	doi = {10.1172/JCI139642},
	publisher = {The American Society for Clinical Investigation}
},

@article{geoforests2020,
	title = {Geodesic Forests},
	author = {Madhyastha, Meghana and Li, Gongkai and Strnadov-Neeley, Veronika and Browne, James and Vogelstein, Joshua T. and Burns, Randal and Priebe, Carey E.},
	author+an = {5=highlight},
	year = {2020},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1145/3394486.3403094},
	month = {8},
	address = {New York, NY, USA},
	pages = {513–523},
	booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	doi = {10.1145/3394486.3403094},
	isbn = {9781450379984},
	abstract = {Together with the curse of dimensionality, nonlinear dependencies in large data sets persist as major challenges in data mining tasks. A reliable way to accurately preserve nonlinear structure is to compute geodesic distances between data points. Manifold learning methods, such as Isomap, aim to preserve geodesic distances in a Riemannian manifold. However, as manifold learning algorithms operate on the ambient dimensionality of the data, the essential step of geodesic distance computation is sensitive to high-dimensional noise. Therefore, a direct application of these algorithms to high-dimensional, noisy data often yields unsatisfactory results and does not accurately capture nonlinear structure.We propose an unsupervised random forest approach called geodesic forests (GF) to geodesic distance estimation in linear and nonlinear manifolds with noise. GF operates on low-dimensional sparse linear combinations of features, rather than the full observed dimensionality. To choose the optimal split in a computationally efficient fashion, we developed Fast-BIC, a fast Bayesian Information Criterion statistic for Gaussian mixture models.We additionally propose geodesic precision and geodesic recall as novel evaluation metrics that quantify how well the geodesic distances of a latent manifold are preserved. Empirical results on simulated and real data demonstrate that GF is robust to high-dimensional noise, whereas other methods, such as Isomap, UMAP, and FLANN, quickly deteriorate in such settings. Notably, GF is able to estimate geodesic distances better than other approaches on a real connectome dataset},
	publisher = {Association for Computing Machinery},
	numpages = {11},
	location = {Virtual Event, CA, USA},
	series = {KDD '20}
},

@article{chung2022valid,
	title = {Valid two-sample graph testing via optimal transport Procrustes and multiscale graph correlation with applications in connectomics},
	author = {Chung, Jaewon and Varjavand, Bijan and Arroyo-Relión, Jesús and Alyakin, Anton and Agterberg, Joshua and Tang, Minh and Priebe, Carey E and Vogelstein, Joshua T},
	author+an = {1=trainee;2=trainee;3=trainee;4=trainee;8=highlight},
	year = {2022},
	keywords = {peer-reviewed},
	volume = {11},
	pages = {e429},
	number = {1},
	journal = {Stat},
	publisher = {Wiley Online Library}
},

@article{Cohen2018,
	title = {Detection and localization of surgically resectable cancers with a multi-analyte blood test},
	author = {Cohen, Joshua D. and Li, Lu and Wang, Yuxuan and Thoburn, Christopher and Afsari, Bahman and Danilova, Ludmila and Douville, Christopher and Javed, Ammar A. and Wong, Fay and Mattox, Austin and Hruban, Ralph H. and Wolfgang, Christopher L. and Goggins, Michael G. and Molin, Marco Dal and Wang, Tian Li and Roden, Richard and Klein, Alison P. and Ptak, Janine and Dobbyn, Lisa and Schaefer, Joy and Silliman, Natalie and Popoli, Maria and Vogelstein, Joshua T. and Browne, James D. and Schoen, Robert E. and Brand, Randall E. and Tie, Jeanne and Gibbs, Peter and Wong, Hui Li and Mansfield, Aaron S. and Jen, Jin and Hanash, Samir M. and Falconi, Massimo and Allen, Peter J. and Zhou, Shibin and Bettegowda, Chetan and Diaz, Luis A. and Tomasetti, Cristian and Kinzler, Kenneth W. and Vogelstein, Bert and Lennon, Anne Marie and Papadopoulos, Nickolas},
	author+an = {23=highlight;24=trainee},
	year = {2018},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1126/science.aar3247},
	month = {2},
	volume = {359},
	pages = {926–930},
	number = {6378},
	journal = {Science},
	doi = {10.1126/science.aar3247},
	abstract = {Earlier detection is key to reducing cancer deaths. Here, we describe a blood test that can detect eight common cancer types through assessment of the levels of circulating proteins and mutations in cell-free DNA. We applied this test, called CancerSEEK, to 1005 patients with nonmetastatic, clinically detected cancers of the ovary, liver, stomach, pancreas, esophagus, colorectum, lung, or breast. CancerSEEK tests were positive in a median of 70},
	issn = {10959203},
	publisher = {American Association for the Advancement of Science},
	pmid = {29348365}
},

@article{Chen2016b,
	title = {Robust Vertex Classification},
	author = {Chen, Li and Shen, Cencheng and Vogelstein, Joshua T. and Priebe, Carey E.},
	author+an = {3=highlight},
	year = {2016},
	keywords = {peer-reviewed},
	url = {http://dx.doi.org/10.1109/TPAMI.2015.2456913},
	month = {7},
	volume = {38},
	pages = {578–590},
	number = {3},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	doi = {10.1109/TPAMI.2015.2456913},
	abstract = {For random graphs distributed according to stochastic blockmodels, a special case of latent position graphs, adjacency spectral embedding followed by appropriate vertex classification is asymptotically Bayes optimal; but this approach requires knowledge of and critically depends on the model dimension. In this paper, we propose a sparse representation vertex classifier which does not require information about the model dimension. This classifier represents a test vertex as a sparse combination of the vertices in the training set and uses the recovered coefficients to classify the test vertex. We prove consistency of our proposed classifier for stochastic blockmodels, and demonstrate that the sparse representation classifier can predict vertex labels with higher accuracy than adjacency spectral embedding approaches via both simulation studies and real data experiments. Our results demonstrate the robustness and effectiveness of our proposed vertex classifier when the model dimension is unknown.},
	issn = {01628828}
},

@article{Chen2015,
	title = {A Joint Graph Inference Case Study: the C.elegans Chemical and Electrical Connectomes},
	author = {Chen, Li and Vogelstein, Joshua T and Lyzinski, Vince and Priebe, Carey E},
	author+an = {2=highlight},
	year = {2015},
	keywords = {peer-reviewed},
	url = {http://arxiv.org/abs/1507.08376},
	month = {7},
	volume = {5},
	journal = {Worm},
	doi = {10.1080/21624054.2016.1142041},
	abstract = {We investigate joint graph inference for the chemical and electrical connectomes of the Caenorhabditis elegans roundworm. The C.elegans connectomes consist of 253 non-isolated neurons with known functional attributes, and there are two types of synaptic connectomes, resulting in a pair of graphs. We formulate our joint graph inference from the perspectives of seeded graph matching and joint vertex classification. Our results suggest that connectomic inference should proceed in the joint space of the two connectomes, which has significant neuroscientific implications.},
	issn = {2162-4054},
	eprint = {1507.08376},
	pmid = {27386164}
},

@article{Vogelstein2013,
	title = {Graph classification using signal-subgraphs: Applications in statistical connectomics},
	author = {Vogelstein, Joshua T. and Roncal, William Gray and Vogelstein, R. Jacob and Priebe, Carey E.},
	author+an = {1=highlight;2=trainee},
	year = {2013},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1109/TPAMI.2012.235},
	volume = {35},
	pages = {1539–1551},
	number = {7},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	doi = {10.1109/TPAMI.2012.235},
	isbn = {0162-8828 VO - 35},
	abstract = {This manuscript considers the following graph classification question: Given a collection of graphs and associated classes, how can one predict the class of a newly observed graph? To address this question, we propose a statistical model for graph/class pairs. This model naturally leads to a set of estimators to identify the class-conditional signal, or signal-subgraph, defined as the collection of edges that are probabilistically different between the classes. The estimators admit classifiers which are asymptotically optimal and efficient, but which differ by their assumption about the coherency of the signal-subgraph (coherency is the extent to which the signal-edges stick together around a common subset of vertices). Via simulation, the best estimator is shown to be not just a function of the coherency of the model, but also the number of training samples. These estimators are employed to address a contemporary neuroscience question: Can we classify connectomes (brain-graphs) according to sex? The answer is yes, and significantly better than all benchmark algorithms considered. Synthetic data analysis demonstrates that even when the model is correct, given the relatively small number of training samples, the estimated signal-subgraph should be taken with a grain of salt. We conclude by discussing several possible extensions. © 1979-2012 IEEE.},
	issn = {01628828},
	eprint = {1108.1427},
	archiveprefix = {arXiv},
	arxivid = {1108.1427},
	publisher = {IEEE Computer Society},
	pmid = {23681985}
},

@ARTICLE{Li2022-gf,
	title = {Inpatient Administration of Alpha-1-Adrenergic Receptor Blocking Agents Reduces Mortality in Male COVID-19 Patients},
	author = {Li, Shilong and Jun, Tomi and Tyler, Jonathan and Schadt, Emilio and Kao, Yu-Han and Wang, Zichen and Konig, Maximilian F and Bettegowda, Chetan and Vogelstein, Joshua T and Papadopoulos, Nickolas and Parsons, Ramon E and Chen, Rong and Schadt, Eric E and Li, Li and Oh, William K},
	author+an = {9=highlight},
	year = {2022},
	keywords = {peer-reviewed},
	url = {https://www.frontiersin.org/articles/10.3389/fmed.2021.637647/full},
	month = {2},
	volume = {9},
	pages = {849222},
	journal = {Front. Med.}
},

@article{cho2020,
	title = {Impact of concatenating fMRI data on reliability for functional connectomics},
	author = {Chow, Jae Wook and Korchmaros, Annachiara and Vogelstein, Joshua T. and Milham, Michael P. and Xu, Ting},
	author+an = {3=highlight},
	year = {2020},
	keywords = {peer-reviewed},
	month = {11},
	journal = {Neuroimage},
	doi = {https://doi.org/10.1016/j.neuroimage.2020.117549}
},

@article{Sweeney2014,
	title = {A comparison of supervised machine learning algorithms and feature vectors for MS lesion segmentation using multimodal structural MRI},
	author = {Sweeney, Elizabeth M. and Vogelstein, Joshua T. and Cuzzocreo, Jennifer L. and Calabresi, Peter A. and Reich, Daniel S. and Crainiceanu, Ciprian M. and Shinohara, Russell T.},
	author+an = {2=highlight},
	year = {2014},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1371/journal.pone.0095753},
	volume = {9},
	number = {4},
	journal = {PLoS ONE},
	doi = {10.1371/journal.pone.0095753},
	isbn = {10.1371/journal.pone.0095753},
	abstract = {Machine learning is a popular method for mining and analyzing large collections of medical data. We focus on a particular problem from medical research, supervised multiple sclerosis (MS) lesion segmentation in structural magnetic resonance imaging (MRI). We examine the extent to which the choice of machine learning or classification algorithm and feature extraction function impacts the performance of lesion segmentation methods. As quantitative measures derived from structural MRI are important clinical tools for research into the pathophysiology and natural history of MS, the development of automated lesion segmentation methods is an active research field. Yet, little is known about what drives performance of these methods. We evaluate the performance of automated MS lesion segmentation methods, which consist of a supervised classification algorithm composed with a feature extraction function. These feature extraction functions act on the observed T1-weighted (T1-w), T2-weighted (T2-w) and fluid-attenuated inversion recovery (FLAIR) MRI voxel intensities. Each MRI study has a manual lesion segmentation that we use to train and validate the supervised classification algorithms. Our main finding is that the differences in predictive performance are due more to differences in the feature vectors, rather than the machine learning or classification algorithms. Features that incorporate information from neighboring voxels in the brain were found to increase performance substantially. For lesion segmentation, we conclude that it is better to use simple, interpretable, and fast algorithms, such as logistic regression, linear discriminant analysis, and quadratic discriminant analysis, and to develop the features to improve performance.},
	issn = {19326203},
	pmid = {24781953}
},

@article{Vogelstein2007,
	title = {Dynamically reconfigurable silicon array of spiking neurons with conductance-based synapses},
	author = {Vogelstein, R. Jacob and Mallik, Udayan and Vogelstein, Joshua T. and Cauwenberghs, Gert},
	author+an = {3=highlight},
	year = {2007},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1109/TNN.2006.883007},
	volume = {18},
	pages = {253–265},
	number = {1},
	journal = {IEEE Transactions on Neural Networks},
	doi = {10.1109/TNN.2006.883007},
	isbn = {0893-6080},
	abstract = {A mixed-signal very large scale integration (VLSI) chip for large scale emulation of spiking neural networks is presented. The chip contains 2400 silicon neurons with fully programmable and reconfigurable synaptic connectivity. Each neuron implements a discrete-time model of a single-compartment cell. The model allows for analog membrane dynamics and an arbitrary number of synaptic connections, each with tunable conductance and reversal potential. The array of silicon neurons functions as an address-event (AE) transceiver, with incoming and outgoing spikes communicated over an asynchronous event-driven digital bus. Address encoding and conflict resolution of spiking events are implemented via a randomized arbitration scheme that ensures balanced servicing of event requests across the array. Routing of events is implemented externally using dynamically programmable random-access memory that stores a postsynaptic address, the conductance, and the reversal potential of each synaptic connection. Here, we describe the silicon neuron circuits, present experimental data characterizing the 3 mm x 3 mm chip fabricated in 0.5-micron complementary metal-oxide-semiconductor (CMOS) technology, and demonstrate its utility by configuring the hardware to emulate a model of attractor dynamics and waves of neural activity during sleep in rat hippocampus.},
	issn = {10459227},
	pmid = {17278476}
},

@article{Vogelstein2003,
	title = {Accuracy of saccades to remembered targets as a function of body orientation in space},
	author = {Vogelstein, Joshua T. and Snyder, Lawrence H. and Angelaki, Dora E.},
	author+an = {1=highlight},
	year = {2003},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1152/jn.00141.2003},
	volume = {90},
	pages = {521–524},
	number = {1},
	journal = {Journal of Neurophysiology},
	doi = {10.1152/jn.00141.2003},
	isbn = {0022-3077 (Print)0̊022-3077 (Linking)},
	abstract = {A vertical asymmetry in memory-guided saccadic eye movements has been previously demonstrated in humans and in rhesus monkeys. In the upright orientation, saccades generally land several degrees above the target. The origin of this asymmetry has remained unknown. In this study, we investigated whether the asymmetry in memory saccades is dependent on body orientation in space. Thus animals performed memory saccades in four different body orientations: upright, left-side-down (LSD), right-side-down (RSD), and supine. Data in all three rhesus monkeys confirm previous observations regarding a significant upward vertical asymmetry. Saccade errors made from LSD and RSD postures were partitioned into components made along the axis of gravity and along the vertical body axis. Up/down asymmetry persisted only in body coordinates but not in gravity coordinates. However, this asymmetry was generally reduced in tilted positions. Therefore the upward bias seen in memory saccades is egocentric although orientation in space might play a modulatory role.},
	issn = {00223077},
	pmid = {12843314}
},

@article{Craddock2013,
	title = {Imaging human connectomes at the macroscale},
	author = {Craddock, R. Cameron and Jbabdi, Saad and Yan, Chao Gan and Vogelstein, Joshua T. and Castellanos, F. Xavier and Di Martino, Adriana and Kelly, Clare and Heberlein, Keith and Colcombe, Stan and Milham, Michael P.},
	author+an = {4=highlight},
	year = {2013},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1038/nmeth.2482},
	month = {3},
	volume = {10},
	pages = {524–539},
	number = {6},
	journal = {Nature Methods},
	doi = {10.1038/nmeth.2482},
	isbn = {1548-7105 (Electronic)1̊548-7091 (Linking)},
	abstract = {At macroscopic scales, the human connectome comprises anatomically distinct brain areas, the structural pathways connecting them and their functional interactions. Annotation of phenotypic associations with variation in the connectome and cataloging of neurophenotypes promise to transform our understanding of the human brain. In this Review, we provide a survey of magnetic resonance imaging-based measurements of functional and structural connectivity. We highlight emerging areas of development and inquiry and emphasize the importance of integrating structural and functional perspectives on brain architecture.},
	issn = {15487091},
	eprint = {NIHMS150003},
	publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	pmid = {23722212},
	shorttitle = {Nat Meth}
},

@article{tang2016law,
	title = {Connectome Smoothing via Low-rank Approximations},
	author = {Tang, Runze and Ketcha, Michael and Badea, Alexandra and Calabrese, Evan D and Margulies, Daniel S and Vogelstein, Joshua T and Priebe, Carey E and Sussman, Daniel L},
	author+an = {6=highlight},
	year = {2018},
	keywords = {peer-reviewed},
	url = {https://ieeexplore.ieee.org/document/8570772},
	month = {12},
	journal = {Transactions in Medical Imaging}
},

@article{Kiar2017,
	title = {Science in the cloud (SIC): A use case in MRI connectomics},
	author = {Kiar, Gregory and Gorgolewski, Krzysztof J. and Kleissas, Dean and Roncal, William Gray and Litt, Brian and Wandell, Brian and Poldrack, Russel A. and Wiener, Martin and Vogelstein, R. Jacob and Burns, Randal and Vogelstein, Joshua T.},
	author+an = {11=highlight;1=trainee},
	year = {2017},
	keywords = {peer-reviewed},
	url = {https://academic.oup.com/gigascience/article-lookup/doi/10.1093/gigascience/gix013},
	month = {5},
	volume = {6},
	pages = {1–10},
	number = {5},
	journal = {GigaScience},
	doi = {10.1093/gigascience/gix013},
	abstract = {Modern technologies are enabling scientists to collect extraordinary amounts of complex and sophisticated data across a huge range of scales like never before. With this onslaught of data, we can allow the focal point to shift from data collection to data analysis. Unfortunately, lack of standardized sharing mechanisms and practices often make reproducing or extending scientific results very difficult. With the creation of data organization structures and tools that drastically improve code portability, we now have the opportunity to design such a framework for communicating extensible scientific discoveries. Our proposed solution leverages these existing technologies and standards, and provides an accessible and extensible model for reproducible research, called 'science in the cloud' (SIC). Exploiting scientific containers, cloud computing, and cloud data services, we show the capability to compute in the cloud and run a web service that enables intimate interaction with the tools and data presented. We hope this model will inspire the community to produce reproducible and, importantly, extensible results that will enable us to collectively accelerate the rate at which scientific breakthroughs are discovered, replicated, and extended.},
	issn = {2047-217X},
	eprint = {1610.08484},
	archiveprefix = {arXiv},
	arxivid = {1610.08484},
	publisher = {Oxford University Press}
},

@article{connectalcoding,
	title = {Connectal Coding: Discovering the Structures Linking Cognitive Phenotypes to Individual Histories},
	author = {Vogelstein, Joshua T. and Bridgeford, Eric W. and Pedigo, Benjamin D. and Chung, Jaewon and Levin, Keith and Mensh, Brett and Priebe, Carey E.},
	author+an = {1=highlight;2=trainee;3=trainee;4=trainee},
	year = {2019},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1016/j.conb.2019.04.005},
	month = {4},
	volume = {55},
	pages = {199–212},
	journal = {Current Opinion in Neurobiology},
	doi = {10.1016/j.conb.2019.04.005},
	abstract = {Cognitive phenotypes characterize our memories, beliefs, skills, and preferences, and arise from our ancestral, developmental, and experiential histories. These histories are written into our brain structure through the building and modification of various brain circuits. Connectal coding, by way of analogy with neural coding, is the art, study, and practice of identifying the network structures that link cognitive phenomena to individual histories. We propose a formal statistical framework for connectal coding and demonstrate its utility in several applications spanning experimental modalities and phylogeny.},
	issn = {18736882}
},

@article{AStA2020,
	title = {The exact equivalence of distance and kernel methods in hypothesis testing},
	author = {Shen, Cencheng and Vogelstein, Joshua T.},
	author+an = {1=trainee;2=highlight},
	year = {2020},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1007/s10182-020-00378-1},
	month = {9},
	journal = {AStA Advances in Statistical Analysis},
	doi = {10.1007/s10182-020-00378-1}
},

@article{wang2018statistical,
	title = {On statistical tests of functional connectome fingerprinting},
	author = {Wang, Zeyi and Sair, Haris and Crainiceanu, Ciprian and Lindquist, Martin and Landman, Bennett A and Resnick, Susan and Vogelstein, Joshua T. and Caffo, Brian Scott},
	author+an = {1=trainee;7=highlight},
	year = {2020},
	keywords = {peer-reviewed},
	month = {8},
	journal = {The Canadian Journal of Statistics},
	doi = {https://doi.org/10.1002/cjs.11591}
},

@article{Dai2012,
	title = {Accurate prediction of AD patients using cortical thickness networks},
	author = {Dai, Dai and He, Huiguang and Vogelstein, Joshua T. and Hou, Zengguang},
	author+an = {3=highlight},
	year = {2012},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1007/s00138-012-0462-0},
	month = {10},
	volume = {24},
	pages = {1445–1457},
	number = {7},
	journal = {Machine Vision and Applications},
	doi = {10.1007/s00138-012-0462-0},
	isbn = {0932-8092},
	abstract = {It is widely believed that human brain is a complicated network and many neurological disorders such as Alzheimer's disease (AD) are related to abnormal changes of the brain network architecture. In this work, we present a kernel-based method to establish a network for each subject using mean cortical thickness, which we refer to hereafter as the individual's network. We construct individual networks for 83 subjects, including AD patients and normal controls (NC), which are taken from the Open Access Series of Imaging Studies database. The network edge features are used to make prediction of AD/NC through the sophisticated machine learning technology. As the number of edge features is much more than that of samples, feature selection is applied to avoid the adverse impact of high-dimensional data on the performance of classifier. We use a hybrid feature selection that combines filter and wrapper methods, and compare the performance of six different combinations of them. Finally, support vector machines are trained using the selected features. To obtain an unbiased evaluation of our method, we use a nested cross validation framework to choose the optimal hyper-parameters of classifier and evaluate the generalization of the method. We report the best accuracy of 90.4},
	issn = {09328092}
},

@Article{powell2022exploration,
	title = {Exploration of Residual Confounding in Analyses of Associations of Metformin Use and Outcomes in Adults With Type 2 Diabetes},
	author = {Powell, Mike and Clark, Callahan and Alyakin, Anton and Vogelstein, Joshua T and Hart, Brian},
	author+an = {4=highlight},
	year = {2022},
	keywords = {peer-reviewed},
	url = {https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2798322},
	volume = {5},
	pages = {e2241505–e2241505},
	number = {11},
	journal = {JAMA Network Open},
	publisher = {American Medical Association}
},

@article{HONG2020117322,
	title = {Toward a connectivity gradient-based framework for reproducible biomarker discovery},
	author = {Hong, Seok-Jun and Xu, Ting and Nikolaidis, Aki and Smallwood, Jonathan and Margulies, Daniel S. and Bernhardt, Boris and Vogelstein, Joshua T. and Milham, Michael P.},
	author+an = {7=highlight},
	year = {2020},
	keywords = {peer-reviewed},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811920308089},
	month = {12},
	volume = {223},
	pages = {117322},
	journal = {NeuroImage},
	doi = {https://doi.org/10.1016/j.neuroimage.2020.117322},
	issn = {1053-8119}
},

@article{bottleneck2021,
	title = {Removing the Reliability Bottleneck in Functional Magnetic Resonance Imaging Research to Achieve Clinical Utility},
	author = {Milham, Michael P. and Vogelstein, Joshua T. and Xu, Ting},
	author+an = {2=highlight},
	year = {2021},
	keywords = {peer-reviewed},
	url = {https://jamanetwork.com/journals/jamapsychiatry/article-abstract/2774875},
	month = {1},
	journal = {JAMA Psychiatry},
	doi = {10.1001/jamapsychiatry.2020.4272}
},

@article{deeplearning2020,
	title = {Different scaling of linear models and deep learning in UKBiobank brain images versus machine-learning datasets},
	author = {Schulz, Marc-Andre and Yeo, B.T. Thomas and Vogelstein, Joshua T. and Mourao-Miranada, Janaina and Kather, Jakob N. and Kording, Konrad and Richards, Blake and Bzdok, Danilo},
	author+an = {3=highlight},
	year = {2020},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1038/s41467-020-18037-z},
	month = {8},
	journal = {Nat Commun},
	doi = {10.1038/s41467-020-18037-z},
	abstract = {In recent years, deep learning has unlocked unprecedented success in various domains, especially in image, text, and speech processing. These breakthroughs may hold promise for neuroscience and especially for brain-imaging investigators who start to analyze thousands of participants. However, deep learning is only beneficial if the data have nonlinear relationships and if they are exploitable at currently available sample sizes. We systematically profiled the performance of deep models, kernel models, and linear models as a function of sample size on UK Biobank brain images against established machine learning references. On MNIST and Zalando Fashion, prediction accuracy consistently improved when escalating from linear models to shallow-nonlinear models, and further improved when switching to deep-nonlinear models. The more observations were available for model training, the greater the performance gain we saw. In contrast, using structural or functional brain scans, simple linear models performed on par with more complex, highly parameterized models in age/sex prediction across increasing sample sizes. In fact, linear models kept improving as the sample size approached 10,000 participants. Our results indicate that the increase in performance of linear models with additional data does not saturate at the limit of current feasibility. Yet, nonlinearities of common brain scans remain largely inaccessible to both kernel and deep learning methods at any examined scale.}
},

@article{JAMIA2020,
	title = {The National COVID Cohort Collaborative (N3C): Rationale, design, infrastructure, and deployment},
	author = {Haendel, Melissa A and Chute, Christopher G and Bennett, Tellen D and Eichmann, David A and Guinney, Justin and Kibbe, Warren A and Payne, Philip R O and Pfaff, Emily R and Robinson, Peter N and Saltz, Joel H and Spratt, Heidi and Suver, Christine and Wilbanks, John and Wilcox, Adam B and Williams, Andrew E and Wu, Chunlei and Blacketer, Clair and Bradford, Robert L and Cimino, James J and Clark, Marshall and Colmenares, Evan W and Francis, Patricia A and Gabriel, Davera and Graves, Alexis and Hemadri, Raju and Hong, Stephanie S and Hripscak, George and Jiao, Dazhi and Klann, Jeffrey G and Kostka, Kristin and Lee, Adam M and Lehmann, Harold P and Lingrey, Lora and Miller, Robert T and Morris, Michele and Murphy, Shawn N and Natarajan, Karthik and Palchuk, Matvey B and Sheikh, Usman and Solbrig, Harold and Visweswaran, Shyam and Walden, Anita and Walters, Kellie M and Weber, Griffin M and Zhang, Xiaohan Tanner and Zhu, Richard L and Amor, Benjamin and Girvin, Andrew T and Manna, Amin and Qureshi, Nabeel and Kurilla, Michael G and Michael, Sam G and Portilla, Lili M and Rutter, Joni L and Austin, Christopher P and Gersing, Ken R, the N3C Consortium},
	year = {2020},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1093/jamia/ocaa196},
	month = {10},
	journal = {Journal of the American Medical Informatics Association},
	doi = {10.1093/jamia/ocaa196},
	abstract = {"Coronavirus disease 2019 (COVID-19) poses societal challenges that require expeditious data and knowledge sharing. Though organizational clinical data are abundant, these are largely inaccessible to outside researchers. Statistical, machine learning, and causal analyses are most successful with large-scale data beyond what is available in any given organization. Here, we introduce the National COVID Cohort Collaborative (N3C), an open science community focused on analyzing patient-level data from many centers.The Clinical and Translational Science Award Program and scientific community created N3C to overcome technical, regulatory, policy, and governance barriers to sharing and harmonizing individual-level clinical data. We developed solutions to extract, aggregate, and harmonize data across organizations and data models, and created a secure data enclave to enable efficient, transparent, and reproducible collaborative analytics.Organized in inclusive workstreams, we created legal agreements and governance for organizations and researchers; data extraction scripts to identify and ingest positive, negative, and possible COVID-19 cases; a data quality assurance and harmonization pipeline to create a single harmonized dataset; population of the secure data enclave with data, machine learning, and statistical analytics tools; dissemination mechanisms; and a synthetic data pilot to democratize data access.The N3C has demonstrated that a multisite collaborative learning health network can overcome barriers to rapidly build a scalable infrastructure incorporating multiorganizational clinical data for COVID-19 analytics. We expect this effort to save lives by enabling rapid collaboration among clinicians, researchers, and data scientists to identify treatments and specialized care and thereby reduce the immediate and long-term impacts of COVID-19.", issn = 1527-974X},
	eprint = {https://academic.oup.com/jamia/advance-article-pdf/doi/10.1093/jamia/ocaa196/34927041/ocaa196.pdf},
	note = {ocaa196}
},

@article{CloudReg,
	title = {CloudReg: automatic terabyte-scale cross-modal brain volume registration},
	author = {Chandrashekhar, Vikram and Tward, Daniel J and Crowley, Devin and Crow, Ailey K and Wright, Matthew A and Hsueh, Brian Y and Gore, Felicity and Machado, Timothy A and Branch, Audrey and Rosenblum, Jared S and Deisseroth, Karl and Vogelstein, Joshua T},
	author+an = {1=trainee;12=highlight},
	year = {2021},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1038/s41592-021-01218-z},
	month = {7},
	journal = {Nature Methods},
	doi = {10.1038/s41592-021-01218-z},
	issn = {1548-7105},
	eprint = {https://www.nature.com/articles/s41592-021-01218-z.pdf}
},

@article{ViterBrain,
	title = {Hidden Markov modeling for maximum probability neuron reconstruction},
	author = {Athey, Thomas L and Tward, Daniel J and Mueller, Ulrich and Vogelstein Joshua T and Miller, Michael I},
	author+an = {1=trainee; 4=highlight},
	year = {2022},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1038/s42003-022-03320-0},
	month = {4},
	journal = {Communications Biology},
	doi = {10.1038/s42003-022-03320-0},
	issn = {5:388},
	eprint = {https://www.nature.com/articles/s42003-022-03320-0.pdf}
},

@article{WANG2020117274,
	title = {Variability and heritability of mouse brain structure: Microscopic MRI atlases and connectomes for diverse strains},
	author = {Wang, Nian and Anderson, Robert J and Ashbrook, David G and Gopalakrishnan, Vivek and Park, Youngser and Priebe, Carey E and Qi, Yi and Vogelstein, Joshua T and Williams, Robert W and Johnson, Allan G},
	author+an = {4=trainee;8=highlight},
	year = {2020},
	keywords = {peer-reviewed},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811920307606},
	month = {11},
	volume = {222},
	pages = {117274},
	journal = {NeuroImage (Cover Story)},
	doi = {https://doi.org/10.1016/j.neuroimage.2020.117274},
	abstract = {Genome-wide association studies have demonstrated significant links between human brain structure and common DNA variants. Similar studies with rodents have been challenging because of smaller brain volumes. Using high field MRI (9.4 T) and compressed sensing, we have achieved microscopic resolution and sufficiently high throughput for rodent population studies. We generated whole brain structural MRI and diffusion connectomes for four diverse isogenic lines of mice (C57BL/6J, DBA/2J, CAST/EiJ, and BTBR) at spatial resolution 20,000 times higher than human connectomes. We measured narrow sense heritability (h2) I.e. the fraction of variance explained by strains in a simple ANOVA model for volumes and scalar diffusion metrics, and estimates of residual technical error for 166 regions in each hemisphere and connectivity between the regions. Volumes of discrete brain regions had the highest mean heritability (0.71 ± 0.23 SD, n = 332), followed by fractional anisotropy (0.54 ± 0.26), radial diffusivity (0.34 ± 0.022), and axial diffusivity (0.28 ± 0.19). Connection profiles were statistically different in 280 of 322 nodes across all four strains. Nearly 150 of the connection profiles were statistically different between the C57BL/6J, DBA/2J, and CAST/EiJ lines. Microscopic whole brain MRI/DTI has allowed us to identify significant heritable phenotypes in brain volume, scalar DTI metrics, and quantitative connectomes.},
	issn = {1053-8119}
},

@Article{Kudithipudi2022,
	title = {Biological underpinnings for lifelong learning machines},
	author = {Kudithipudi, Dhireesha and Aguilar-Simon, Mario and Babb, Jonathan and Bazhenov, Maxim and Blackiston, Douglas and Bongard, Josh and Brna, Andrew P. and Chakravarthi Raja, Suraj and Cheney, Nick and Clune, Jeff and Daram, Anurag and Fusi, Stefano and Helfer, Peter and Kay, Leslie and Ketz, Nicholas and Kira, Zsolt and Kolouri, Soheil and Krichmar, Jeffrey L. and Kriegman, Sam and Levin, Michael and Madireddy, Sandeep and Manicka, Santosh and Marjaninejad, Ali and McNaughton, Bruce and Miikkulainen, Risto and Navratilova, Zaneta and Pandit, Tej and Parker, Alice and Pilly, Praveen K. and Risi, Sebastian and Sejnowski, Terrence J. and Soltoggio, Andrea and Soures, Nicholas and Tolias, Andreas S. and Urbina-Meléndez, Darío and Valero-Cuevas, Francisco J. and van de Ven, Gido M. and Vogelstein, Joshua T. and Wang, Felix and Weiss, Ron and Yanguas-Gil, Angel and Zou, Xinyun and Siegelmann, Hava},
	author+an = {38=highlight},
	year = {2022},
	keywords = {peer-reviewed},
	url = {https://doi.org/10.1038/s42256-022-00452-0},
	month = {Mar},
	volume = {4},
	pages = {196-210},
	number = {3},
	journal = {Nature Machine Intelligence},
	doi = {10.1038/s42256-022-00452-0},
	issn = {2522-5839},
	day = {01}
},

@ARTICLE{Poline2022-kq,
	title = {Is Neuroscience FAIR? A Call for Collaborative Standardisation of Neuroscience Data},
	author = {Poline, Jean-Baptiste and Kennedy, David N and Sommer, Friedrich T and Ascoli, Giorgio A and Van Essen, David C and Ferguson, Adam R and Grethe, Jeffrey S and Hawrylycz, Michael J and Thompson, Paul M and Poldrack, Russell A and Ghosh, Satrajit S and Keator, David B and Athey, Thomas L and Vogelstein, Joshua T and Mayberg, Helen S and Martone, Maryann E},
	author+an = {13=trainee; 14=highlight},
	year = {2022},
	keywords = {peer-reviewed},
	url = {https://link.springer.com/article/10.1007/s12021-021-09557-0},
	month = {1},
	journal = {Neuroinformatics}
},

@article{Banerjee2013,
	title = {Parallel inversion of huge covariance matrices},
	author = {Banerjee, Anjishnu and Vogelstein, Joshua and Dunson, David},
	author+an = {2=highlight},
	year = {2013},
	keywords = {tech},
	url = {http://arxiv.org/abs/1312.1869},
	volume = {1312.1869},
	journal = {arXiv},
	abstract = {An extremely common bottleneck encountered in statistical learning algorithms is inversion of huge covariance matrices, examples being in evaluating Gaussian likelihoods for a large number of data points. We propose general parallel algorithms for inverting positive definite matrices, which are nearly rank deficient. Such matrix inversions are needed in Gaussian process computations, among other settings, and remain a bottleneck even with the increasing literature on low rank approximations. We propose a general class of algorithms for parallelizing computations to dramatically speed up computation time by orders of magnitude exploiting multicore architectures. We implement our algorithm on a cloud computing platform, providing pseudo and actual code. The algorithm can be easily implemented on any multicore parallel computing resource. Some illustrations are provided to give a flavor for the gains and what becomes possible in freeing up this bottleneck.},
	eprint = {1312.1869},
	archiveprefix = {arXiv},
	arxivid = {1312.1869}
},

@article{graphyti2019,
	title = {Graphyti: A Semi-External Memory Graph Library for FlashGraph},
	author = {Mhembere, Disa and Zheng, Da and Vogelstein, Joshua T. and Priebe, Carey E. and Burns, Randal},
	author+an = {1=trainee;2=trainee;3=highlight},
	year = {2019},
	keywords = {tech},
	url = {https://arxiv.org/abs/1907.03335},
	month = {7},
	journal = {arXiv}
},

@article{kiar2017comprehensive,
	title = {A comprehensive cloud framework for accurate and reliable human connectome estimation and meganalysis},
	author = {Kiar, Gregory and Bridgeford, Eric and Chandrashekhar, Vikram and Mhembere, Disa and Burns, Randal and Roncal, William R Gray and Vogelstein, Joshua T},
	author+an = {1=trainee;2=trainee;3=trainee;4=trainee;6=trainee;7=highlight},
	year = {2017},
	keywords = {tech},
	url = {https://doi.org/10.1101/188706},
	month = {9},
	pages = {188706},
	journal = {bioRxiv}
},

@article{CloudRegTech,
	title = {CloudReg: automatic terabyte-scale cross-modal brain volume registration},
	author = {Chandrashekhar, Vikram and Tward, Daniel J and Crowley, Devin and Crow, Ailey K and Wright, Matthew A and Hsueh, Brian Y and Gore, Felicity and Machado, Timothy A and Branch, Audrey and Rosenblum, Jared S and Deisseroth, Karl and Vogelstein, Joshua T},
	author+an = {1=trainee;12=highlight},
	year = {2021},
	keywords = {tech},
	url = {https://doi.org/10.1038/s41592-021-01218-z},
	month = {7},
	journal = {Nature Methods},
	doi = {10.1038/s41592-021-01218-z},
	issn = {1548-7105},
	eprint = {https://www.nature.com/articles/s41592-021-01218-z.pdf}
},

@article{kiar2018neurostorm,
	title = {NeuroStorm: Accelerating Brain Science Discovery in the Cloud},
	author = {Kiar, Gregory and Anderson, Robert J. and Baden, Alex and Badea, Alexandra and Bridgeford, Eric W. and Champion, Andrew and Chandrashekhar, Vikram and Collman, Forrest and Duderstadt, Brandon and Evans, Alan C. and Engert, Florian and Falk, Benjamin and Glatard, Tristan and Roncal, William R. Gray and Kennedy, David N. and Maitin-Shepard, Jeremy and Marren, Ryan A. and Nnaemeka, Onyeka and Perlman, Eric and Seshamani, Sharmishtaas and Trautman, Eric T. and Tward, Daniel J. and Valdés-Sosa, Pedro Antonio and Wang, Qing and Miller, Michael I. and Burns, Randal and Vogelstein, Joshua T.},
	author+an = {2=trainee;3=trainee;5=trainee;7=trainee;9=trainee;27=highlight},
	year = {2018},
	keywords = {tech},
	url = {http://arxiv.org/abs/1803.03367},
	month = {3},
	journal = {arXiv},
	abstract = {Neuroscientists are now able to acquire data at staggering rates across spatiotemporal scales. However, our ability to capitalize on existing datasets, tools, and intellectual capacities is hampered by technical challenges. The key barriers to accelerating scientific discovery correspond to the FAIR data principles: findability, global access to data, software interoperability, and reproducibility/re-usability. We conducted a hackathon dedicated to making strides in those steps. This manuscript is a technical report summarizing these achievements, and we hope serves as an example of the effectiveness of focused, deliberate hackathons towards the advancement of our quickly-evolving field.},
	eprint = {1803.03367},
	archiveprefix = {arXiv},
	arxivid = {1803.03367}
},

@article{vogelstein2020pvalues,
	title = {P-Values in a Post-Truth World},
	author = {Vogelstein, Joshua T.},
	author+an = {1=highlight},
	year = {2020},
	keywords = {tech},
	url = {https://arxiv.org/abs/2007.03611},
	month = {7},
	journal = {arXiv},
	eprint = {2007.03611},
	archivePrefix = {arXiv},
	primaryClass = {physics.soc-ph}
},

@article{wang2020statistical,
	title = {Statistical Analysis of Data Repeatability Measures},
	author = {Zeyi Wang and Eric Bridgeford and Shangsi Wang and Joshua T. Vogelstein and Brian Caffo},
	author+an = {2=trainee;4=highlight},
	year = {2020},
	keywords = {tech},
	url = {https://arxiv.org/abs/2005.11911},
	journal = {arXiv},
	eprint = {2005.11911},
	archivePrefix = {arXiv},
	primaryClass = {stat.AP}
},

@article{Kiar2018,
	title = {A High-Throughput Pipeline Identifies Robust Connectomes But Troublesome Variability},
	author = {Kiar, Gregory and Bridgeford, Eric and Roncal, Will Gray and (CoRR) and Chandrashekhar, Vikram and Mhembere, Disa and Ryman, Sephira and Zuo, Xi-Nian and Marguiles, Daniel S and Craddock, R Cameron and Priebe, Carey E and Jung, Rex and Calhoun, Vince and Caffo, Brian and Burns, Randal and Milham, Michael P and Vogelstein, Joshua},
	author+an = {1=trainee;2=trainee;3=trainee;5=trainee;6=trainee;17=highlight},
	year = {2018},
	keywords = {tech},
	url = {https://doi.org/10.1101/188706},
	month = {4},
	journal = {bioRxiv},
	doi = {10.1101/188706},
	abstract = {Modern scientific discovery depends on collecting large heterogeneous datasets with many sources of variability, and applying domain-specific pipelines from which one can draw insight or clinical utility. For example, macroscale connectomics studies require complex pipelines to process raw functional or diffusion data and estimate connectomes. Individual studies tend to customize pipelines to their needs, raising concerns about their reproducibility, and adding to a longer list of factors that may differ across studies (including sampling, experimental design, and data acquisition protocols), resulting in failures to replicate. Mitigating these issues requires multi-study datasets and the development of pipelines that can be applied across them. We developed NeuroData's MRI to Graphs (NDMG) pipeline using several functional and diffusion studies, including the Consortium for Reliability and Reproducibility, to estimate connectomes. Without any manual intervention or parameter tuning, NDMG ran on 25 different studies (∼6,000 scans) from 15 sites, with each scan resulting in a biologically plausible connectome (as assessed by multiple quality assurance metrics at each processing stage). For each study, the connectomes from NDMG are more similar within than across individuals, indicating that NDMG is preserving biological variability. Moreover, the connectomes exhibit near perfect consistency for certain connectional properties across every scan, individual, study, site, and modality; these include stronger ipsilateral than contralateral connections and stronger homotopic than heterotopic connections. Yet, the magnitude of the differences varied across individuals and studies - much more so when pooling data across sites, even after controlling for study, site, and basic demographic variables (i.e., age, sex, and ethnicity). This indicates that other experimental variables (possibly those not measured or reported) are contributing to this variability, which if not accounted for can limit the value of aggregate datasets, as well as expectations regarding the accuracy of findings and likelihood of replication. We, therefore, provide a set of principles to guide the development of pipelines capable of pooling data across studies while maintaining biological variability and minimizing measurement error. This open science approach provides us with an opportunity to understand and eventually mitigate spurious results for both past and future studies.},
	publisher = {Cold Spring Harbor Laboratory}
},

@article{Statconnect2020,
	title = {Statistical Connectomics},
	author = {Jaewon Chung and Eric Bridgeford and Jesus Arroyo and Benjamin D. Pedigo and Ali Saad-Eldin and Vivek Gopalakrishnan and Liang Xiang and Carey E. Priebe and Joshua Vogelstein},
	author+an = {1=trainee; 2=trainee; 3=trainee; 4=trainee; 5=trainee; 6=trainee; 9=highlight},
	year = {2020},
	keywords = {tech},
	url = {https://osf.io/ek4n3},
	month = {10},
	journal = {arXiv}
},

@article{Kazhdan2013,
	title = {Gradient-Domain Processing for Large EM Image Stacks},
	author = {Kazhdan, Michael and Burns, Randal and Kasthuri, Bobby and Lichtman, Jeff and Vogelstein, Jacob and Vogelstein, Joshua},
	author+an = {6=highlight},
	year = {2013},
	keywords = {tech},
	url = {http://arxiv.org/abs/1310.0041},
	month = {9},
	journal = {arXiv},
	abstract = {We propose a new gradient-domain technique for processing registered EM image stacks to remove the inter-image discontinuities while preserving intra-image detail. To this end, we process the image stack by first performing anisotropic diffusion to smooth the data along the slice axis and then solving a screened-Poisson equation within each slice to re-introduce the detail. The final image stack is both continuous across the slice axis (facilitating the tracking of information between slices) and maintains sharp details within each slice (supporting automatic feature detection). To support this editing, we describe the implementation of the first multigrid solver designed for efficient gradient domain processing of large, out-of-core, voxel grids.},
	eprint = {1310.0041},
	archiveprefix = {arXiv},
	arxivid = {1310.0041}
},

@article{Zheng2016c,
	title = {An SSD-based eigensolver for spectral analysis on billion-node graphs},
	author = {Zheng, Da and Burns, Randal and Vogelstein, Joshua and Priebe, Carey E. and Szalay, Alexander S.},
	author+an = {1=trainee;3=highlight},
	year = {2016},
	keywords = {tech},
	url = {http://arxiv.org/abs/1602.01421},
	journal = {arXiv},
	abstract = {Many eigensolvers such as ARPACK and Anasazi have been developed to compute eigenvalues of a large sparse matrix. These eigensolvers are limited by the capacity of RAM. They run in memory of a single machine for smaller eigenvalue problems and require the distributed memory for larger problems. In contrast, we develop an SSD-based eigensolver framework called FlashEigen, which extends Anasazi eigensolvers to SSDs, to compute eigenvalues of a graph with hundreds of millions or even billions of vertices in a single machine. FlashEigen performs sparse matrix multiplication in a semi-external memory fashion, i.e., we keep the sparse matrix on SSDs and the dense matrix in memory. We store the entire vector subspace on SSDs and reduce I/O to improve performance through caching the most recent dense matrix. Our result shows that FlashEigen is able to achieve 40},
	eprint = {1602.01421},
	archiveprefix = {arXiv},
	arxivid = {1602.01421}
},

@article{Priebe2017,
	title = {Semiparametric spectral modeling of the Drosophila connectome},
	author = {Priebe, Carey E. and Park, Youngser and Tang, Minh and Athreya, Avanti and Lyzinski, Vince and Vogelstein, Joshua T. and Qin, Yichen and Cocanougher, Ben and Eichler, Katharina and Zlatic, Marta and Cardona, Albert},
	author+an = {6=highlight},
	year = {2017},
	keywords = {tech},
	url = {http://arxiv.org/abs/1705.03297},
	journal = {arXiv},
	abstract = {We present semiparametric spectral modeling of the complete larval Drosophila mushroom body connectome. Motivated by a thorough exploratory data analysis of the network via Gaussian mixture modeling (GMM) in the adjacency spectral embedding (ASE) representation space, we introduce the latent structure model (LSM) for network modeling and inference. LSM is a generalization of the stochastic block model (SBM) and a special case of the random dot product graph (RDPG) latent position model, and is amenable to semiparametric GMM in the ASE representation space. The resulting connectome code derived via semiparametric GMM composed with ASE captures latent connectome structure and elucidates biologically relevant neuronal properties.},
	eprint = {1705.03297},
	archiveprefix = {arXiv},
	arxivid = {1705.03297}
},

@article{mhembere2019,
	title = {clusterNOR: A NUMA-Optimized Clustering Framework},
	author = {Mhembere, Dia and Zheng, Da and Priebe, Carey E and Vogelstein, Joshua T and Burns, Randal},
	author+an = {1=trainee;2=trainee;4=highlight},
	year = {2019},
	keywords = {tech},
	url = {https://arxiv.org/abs/1902.09527},
	month = {2},
	journal = {arxiv}
},

@article{Zheng2016,
	title = {FlashR: R-Programmed Parallel and Scalable Machine Learning using SSDs},
	author = {Zheng, Da and Mhembere, Disa and Vogelstein, Joshua T. and Priebe, Carey E. and Burns, Randal},
	author+an = {1=trainee;2=trainee;3=highlight},
	year = {2017},
	keywords = {tech},
	url = {http://arxiv.org/abs/1604.06414},
	journal = {CoRR, abs/1604.06414},
	abstract = {R is one of the most popular programming languages for statistics and machine learning, but the R framework is relatively slow and unable to scale to large datasets. The general approach for speeding up an implementation in R is to implement the algorithms in C or FORTRAN and provide an R wrapper. FlashR takes a different approach: it executes R code in parallel and scales the code beyond memory capacity by utilizing solid-state drives (SSDs) automatically. It provides a small number of generalized operations (GenOps) upon which we reimplement a large number of matrix functions in the R base package. As such, FlashR parallelizes and scales existing R code with little/no modification. To reduce data movement between CPU and SSDs, FlashR evaluates matrix operations lazily, fuses operations at runtime, and uses cache-aware, two-level matrix partitioning. We evaluate FlashR on a variety of machine learning and statistics algorithms on inputs of up to four billion data points. FlashR out-of-core tracks closely the performance of FlashR in-memory. The R code for machine learning algorithms executed in FlashR outperforms the in-memory execution of H2O and Spark MLlib by a factor of 2-10 and outperforms Revolution R Open by more than an order of magnitude.},
	eprint = {1604.06414},
	archiveprefix = {arXiv},
	arxivid = {1604.06414}
},

@article {Priebe2020Vote,
	title = {Modern Machine Learning: Partition Vote},
	author = {Priebe, Carey E. and Vogelstein, Joshua T. and Engert, Florian and White, Christopher M.},
	author+an = {2=highlight},
	year = {2020},
	keywords = {tech},
	month = {5},
	journal = {bioRxiv},
	doi = {10.1101/2020.04.29.068460},
	abstract = {We present modern machine learning, focusing on the state-of-the-art classification methods of decision forests and deep networks, as partition and vote schemes. This illustrative presentation allows for both a unified basic understanding of how these methods work from the perspective of classical statistical pattern recognition as well as useful basic insight into their relationship with each other … and with brain functioning.Competing Interest StatementThe authors have declared no competing interest.},
	eprint = {https://www.biorxiv.org/content/early/2020/05/17/2020.04.29.068460.full.pdf},
	publisher = {Cold Spring Harbor Laboratory},
	URL = {https://www.biorxiv.org/content/early/2020/05/17/2020.04.29.068460}
},

@article{helm2020partitionbased,
	title = {A partition-based similarity for classification distributions},
	author = {Helm, Hayden S. and Mehta, Ronak D. and Duderstadt, Brandon and Yang, Weiwei and White, Christoper M. and Geisa, Ali and Vogelstein, Joshua T. and Priebe, Carey E.},
	author+an = {1=trainee; 2=trainee; 6=trainee; 7=highlight},
	year = {2020},
	keywords = {tech},
	url = {https://arxiv.org/abs/2011.06557},
	month = {11},
	journal = {arXiv},
	eprint = {2011.06557}
},

@article{sinha2014automatic,
	title = {Automatic Annotation of Axoplasmic Reticula in Pursuit of Connectomes},
	author = {Sinha, A and Roncal, WG and Kasthuri, N},
	year = {2014},
	keywords = {tech},
	url = {http://arxiv.org/abs/1404.4800},
	journal = {arXiv},
	eprint = {arXiv:1404.4800},
	archiveprefix = {arXiv},
	arxivid = {arXiv:1404.4800}
},

@article{Greenberg479055,
	title = {Accurate action potential inference from a calcium sensor protein through biophysical modeling},
	author = {Greenberg, David S and Wallace, Damian J and Voit, Kay-Michael and Wuertenberger, Silvia and Czubayko, Uwe and Monsees, Arne and Handa, Takashi and Vogelstein, Joshua T and Seifert, Reinhard and Groemping, Yvonne and Kerr, Jason ND},
	author+an = {8=highlight},
	year = {2018},
	keywords = {tech},
	url = {https://doi.org/10.1101/479055},
	month = {11},
	journal = {bioRxiv},
	doi = {10.1101/479055},
	abstract = {Multiphoton imaging of genetically encoded calcium indicators is routinely used to report activity from populations of spatially resolved neurons in vivo. However, since the relationship between fluorescence and action potentials (APs) is nonlinear and varies over neurons, quantitatively inferring AP discharge is problematic. To address this we developed a biophysical model of calcium binding kinetics for the indicator GCaMP6s that accurately describes AP-evoked fluorescence changes in vivo. The model's physical interpretation allowed the same parameters to describe GCaMP6s binding kinetics for both in vitro binding assays and in vivo imaging. Using this model, we developed an algorithm to infer APs from fluorescence and measured its accuracy with cell-attached electrical recordings. This approach consistently inferred more accurate AP counts and times than alternative methods for firing rates from 0 to >20 Hz, while requiring less training data. These results demonstrate the utility of quantitative, biophysically grounded models for complex biological data.},
	eprint = {https://www.biorxiv.org/content/early/2018/11/29/479055.full.pdf},
	publisher = {Cold Spring Harbor Laboratory}
},

@article{Tang2017,
	title = {Robust Estimation from Multiple Graphs under Gross Error Contamination},
	author = {Tang, Runze and Tang, Minh and Vogelstein, Joshua T and Priebe, Carey E},
	author+an = {3=highlight},
	year = {2017},
	keywords = {tech},
	url = {https://arxiv.org/abs/1707.03487},
	month = {7},
	journal = {arXiv},
	abstract = {Estimation of graph parameters based on a collection ofgraphs is essential for a wide range of graph inferencetasks. In practice, weighted graphs are generally observedwith edge contamination. We consider a weighted latentposition graph model contaminated via an edge weight grosserror model and propose an estimation methodology based onrobust Lq estimation followed by low-rank adjacency spectraldecomposition. We demonstrate that, under appropriateconditions, our estimator both maintains Lq robustness andwins the bias-variance tradeoff by exploiting low-rank graphstructure. We illustrate the improvement offered by ourestimator via both simulations and a human connectome dataexperiment.},
	eprint = {arXiv}
},

@article{vertex2019,
	title = {Vertex Classification on Weighted Networks},
	author = {Helm, Hayden and Vogelstein, Joshua V. and Priebe, Carey E.},
	author+an = {1=trainee;2=highlight},
	year = {2019},
	keywords = {tech},
	url = {https://arxiv.org/abs/1906.02881},
	month = {6},
	journal = {arXiv}
},

@article{zheng2016flashmatrix,
	title = {Flashmatrix: parallel, scalable data analysis with generalized matrix operations using commodity ssds},
	author = {Zheng, Da and Mhembere, Disa and Vogelstein, Joshua T and Priebe, Carey E and Burns, R},
	author+an = {3=highlight},
	year = {2016},
	keywords = {tech},
	url = {https://arxiv.org/abs/1604.06414},
	volume = {9},
	pages = {30},
	journal = {arXiv}
},

@article{golland2020new,
	title = {A New Age of Computing and the Brain},
	author = {Polina Golland and Jack Gallant and Greg Hager and Hanspeter Pfister and Christos Papadimitriou and Stefan Schaal and Joshua T. Vogelstein},
	author+an = {7=highlight},
	year = {2020},
	keywords = {tech},
	url = {https://arxiv.org/abs/2004.12926},
	month = {4},
	journal = {arXiv},
	eprint = {2004.12926},
	archivePrefix = {arXiv},
	primaryClass = {cs.CY}
},

@article{Hayden2020,
	title = {Learning to rank via combining representations},
	author = {Helm, Hayden S. and Basu, Amitabh and Athreya, Avanti and Park, Youngser and Vogelstein, Joshua T. and Winding, Michael and Zlatic, Marta and Cardona, Albert and Bourke, Patrick and Larson, Jonathan and White, Chris and Priebe, Carey E.},
	author+an = {1=trainee; 5=highlight},
	year = {2020},
	keywords = {tech},
	url = {https://arxiv.org/abs/2005.10700},
	month = {5},
	journal = {arXiv},
	eprint = {2005.10700},
	archiveprefix = {arXiv},
	arxivid = {2005.10700}
},

@article{xiong2021federated,
	title = {Federated Causal Inference in Heterogeneous Observational Data},
	author = {Xiong, Ruoxuan and Koenecke, Allison and Powell, Michael and Shen, Zhu and Vogelstein, Joshua T and Athey, Susan},
	author+an = {3=trainee; 5=highlight},
	year = {2023},
  month = {8},
	keywords = {peer-reviewed},
	journal = {Statistics in Medicine},
  doi = {10.1002/sim.9868},
  pmid = {37553084}
},

@article{athey2023brainline,
	title = {BrainLine: An Open Pipeline for Connectivity Analysis of Heterogeneous Whole-Brain Fluorescence Volumes},
	author = {Athey, Thomas L and Wright, Matthew A and Pavlovic, Marija and Chandrashekhar, Vikram and Deisseroth, Karl and Miller, Michael I and Vogelstein, Joshua T},
	author+an = {1=trainee; 4=trainee; 7=highlight},
	year = {2023},
  	month = {7},
	keywords = {tech},
	url = {https://link.springer.com/article/10.1007/s12021-023-09638-2},
	journal = {Neuroinformatics}
},

@inproceedings{wang2023polarity,
  title={Polarity is all you need to learn and transfer faster}, 
  author={Wang, Qingyang and Michael A. Powell and Ali Geisa and Eric W. Bridgeford and Joshua T. Vogelstein},
  booktitle = {Proceedings of the 40th International Conference on Machine Learning},
  publisher = {PMLR},
  year={2023},
  abstract={Natural intelligences (NIs) thrive in a dynamic world - they learn quickly, sometimes with only a few samples. In contrast, artificial intelligences (AIs) typically learn with a prohibitive number of training samples and computational power. What design principle difference between NI and AI could contribute to such a discrepancy? Here, we investigate the role of weight polarity: development processes initialize NIs with advantageous polarity configurations; as NIs grow and learn, synapse magnitudes update, yet polarities are largely kept unchanged. We demonstrate with simulation and image classification tasks that if weight polarities are adequately set a priori, then networks learn with less time and data. We also explicitly illustrate situations in which a priori setting the weight polarities is disadvantageous for networks. Our work illustrates the value of weight polarities from the perspective of statistical and computational efficiency during learning.},
  arxiv={2303.17589},
  author+an = {1=trainee;2=trainee;3=trainee;4=trainee;5=highlight},
  keywords={conference}
  },

@inproceedings{Wang_2023_ICCV,
    author    = {Wang, Qingyang and Powell, Mike A. and Geisa, Ali and Bridgeford, Eric and Priebe, Carey E. and Vogelstein, Joshua T.},
    title     = {Why do networks have inhibitory/negative connections?},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2023},
    pages     = {22551-22559},
    abstract={Why do brains have inhibitory connections? Why do deep networks have negative weights? We believe representing functions is the primary role of both (i) the brain in natural intelligence, and (ii) deep networks in artificial intelligence. Our answer to why there are inhibitory/negative weights is: to learn more functions. We prove that, in the absence of negative weights, neural networks with non-decreasing activation functions are not universal approximators. While this may be an intuitive result to some, to the best of our knowledge, there is no formal theory, in either machine learning or neuroscience, that demonstrates why negative weights are crucial in the context of representation capacity. Further, we provide insights on the geometric properties of the representation space that non-negative deep networks cannot represent. We expect these insights will yield a deeper understanding of more sophisticated inductive priors imposed on the distribution of weights that lead to more efficient biological and machine learning.},
    arxiv={2208.03211v8},
    author+an = {1=trainee;2=trainee;3=trainee;4=trainee;6=highlight},
    keywords={conference}
},

@article{de2023value,
  title={The value of out-of-distribution data},
  author={De Silva, Ashwin and Ramesh, Rahul and Priebe, Carey and Chaudhari, Pratik and Vogelstein, Joshua T},
  author+an = {1=trainee; 5=highlight},
  year={2023},
  month={7},
  url = {https://proceedings.mlr.press/v202/de-silva23a.html},
  journal={International Conference on Machine Learning},
  keywords={conference}
},

@article{chung2023heritability,
  title     = {The Heritability of Human Connectomes: a Causal Modeling Analysis},
  author    = {Chung, Jaewon and Bridgeford, Eric W and Powell, Michael and Pisner, Derek and Vogelstein, Joshua T},
  journal   = {bioRxiv},
  year      = {2023},
  publisher = {Cold Spring Harbor Laboratory}
}
